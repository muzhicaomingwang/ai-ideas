#!/usr/bin/env python3
"""
CFO Daily Token Consumption Report Generator

ç”¨é€”ï¼šè‡ªåŠ¨ç”Ÿæˆæ¯æ—¥ Claude Code å’Œ CodeX çš„ Token æ¶ˆè€—æŠ¥å‘Š
"""

import json
import os
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Optional

# Token å®šä»·è¡¨ï¼ˆUSD per 1M tokensï¼‰
PRICING = {
    "claude_code": {
        "sonnet_4_5": {"input": 3.0, "output": 15.0},
        "opus_4_5": {"input": 15.0, "output": 75.0},
        "haiku": {"input": 0.25, "output": 1.25},
    },
    "codex": {
        "cursor_pro": {"monthly": 20.0},
        "github_copilot": {"monthly": 10.0},
        "openai_api": {"gpt4_input": 30.0, "gpt4_output": 60.0},
    }
}

def calculate_cost(tokens_input: int, tokens_output: int, model_pricing: Dict[str, float]) -> float:
    """è®¡ç®— token æˆæœ¬"""
    cost_input = (tokens_input / 1_000_000) * model_pricing["input"]
    cost_output = (tokens_output / 1_000_000) * model_pricing["output"]
    return round(cost_input + cost_output, 4)

def parse_claude_code_logs(log_file: Path) -> Dict[str, Any]:
    """
    è§£æ Claude Code æ—¥å¿—æ–‡ä»¶

    æ ¼å¼ç¤ºä¾‹ï¼š
    Token usage: 71727/200000; 128273 remaining
    """
    # TODO: å®ç°æ—¥å¿—è§£æé€»è¾‘
    # è¿™é‡Œè¿”å›ç¤ºä¾‹æ•°æ®
    return {
        "sonnet_4_5": {
            "input_tokens": 71727,
            "output_tokens": 15000,
            "sessions": 3
        },
        "haiku": {
            "input_tokens": 5000,
            "output_tokens": 1000,
            "sessions": 2
        }
    }

def parse_codex_usage(service: str = "cursor_pro") -> Dict[str, Any]:
    """
    è§£æ CodeX ä½¿ç”¨æ•°æ®

    TODO: å®ç° Cursor API æˆ–æœ¬åœ°é…ç½®æ–‡ä»¶è§£æ
    """
    return {
        "service": service,
        "fast_requests_used": 45,
        "slow_requests_used": 120,
        "monthly_cost_usd": PRICING["codex"][service]["monthly"]
    }

def generate_daily_report(date: str, output_dir: Path, notes: str = "") -> Path:
    """
    ç”Ÿæˆæ¯æ—¥ Token æ¶ˆè€—æŠ¥å‘Š

    Args:
        date: YYYY-MM-DD æ ¼å¼çš„æ—¥æœŸ
        output_dir: æŠ¥å‘Šè¾“å‡ºç›®å½•
        notes: å½“æ—¥ä¸»è¦å·¥ä½œå†…å®¹å¤‡æ³¨

    Returns:
        ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    """
    # è§£æ Claude Code æ¶ˆè€—
    claude_data = parse_claude_code_logs(Path("~/.claude/logs"))

    # è®¡ç®— Claude Code æˆæœ¬
    claude_cost = {}
    claude_total = 0
    for model, data in claude_data.items():
        cost = calculate_cost(
            data["input_tokens"],
            data["output_tokens"],
            PRICING["claude_code"][model]
        )
        claude_cost[model] = {**data, "cost_usd": cost}
        claude_total += cost

    # è§£æ CodeX æ¶ˆè€—
    codex_data = parse_codex_usage()
    codex_daily_cost = codex_data["monthly_cost_usd"] / 30

    # æ€»æˆæœ¬
    total_cost = claude_total + codex_daily_cost

    # ç”Ÿæˆæ•°æ®ç»“æ„
    report_data = {
        "date": date,
        "claude_code": {
            **claude_cost,
            "total_cost_usd": round(claude_total, 2)
        },
        "codex": {
            **codex_data,
            "daily_amortized_cost_usd": round(codex_daily_cost, 2)
        },
        "total_daily_cost_usd": round(total_cost, 2),
        "notes": notes
    }

    # ä¿å­˜ JSON
    json_file = output_dir / "token-logs" / f"{date[:7]}.json"
    json_file.parent.mkdir(parents=True, exist_ok=True)

    # è¯»å–æˆ–åˆ›å»ºæœˆåº¦æ—¥å¿—æ–‡ä»¶
    if json_file.exists():
        with open(json_file, 'r', encoding='utf-8') as f:
            monthly_data = json.load(f)
    else:
        monthly_data = {}

    monthly_data[date] = report_data

    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(monthly_data, f, indent=2, ensure_ascii=False)

    # ç”Ÿæˆ Markdown æŠ¥å‘Š
    md_file = output_dir / "reports" / "daily" / f"{date}.md"
    md_file.parent.mkdir(parents=True, exist_ok=True)

    markdown = generate_markdown_report(report_data)
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write(markdown)

    print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆ:")
    print(f"   JSON: {json_file}")
    print(f"   Markdown: {md_file}")
    print(f"   ä»Šæ—¥æ€»æˆæœ¬: ${total_cost:.2f}")

    return md_file

def generate_markdown_report(data: Dict[str, Any]) -> str:
    """ç”Ÿæˆ Markdown æ ¼å¼çš„æŠ¥å‘Š"""

    # Claude Code è¡¨æ ¼
    claude_rows = []
    for model in ["sonnet_4_5", "opus_4_5", "haiku"]:
        if model in data["claude_code"]:
            d = data["claude_code"][model]
            model_name = model.replace("_", " ").title()
            claude_rows.append(
                f"| {model_name} | {d['input_tokens']:,} | {d['output_tokens']:,} | "
                f"{d['sessions']} | ${d['cost_usd']:.2f} |"
            )

    # æ€»è®¡è¡Œ
    total_input = sum(
        data["claude_code"][m]["input_tokens"]
        for m in data["claude_code"] if m != "total_cost_usd"
    )
    total_output = sum(
        data["claude_code"][m]["output_tokens"]
        for m in data["claude_code"] if m != "total_cost_usd"
    )
    total_sessions = sum(
        data["claude_code"][m]["sessions"]
        for m in data["claude_code"] if m != "total_cost_usd"
    )

    claude_rows.append(
        f"| **åˆè®¡** | **{total_input:,}** | **{total_output:,}** | "
        f"**{total_sessions}** | **${data['claude_code']['total_cost_usd']:.2f}** |"
    )

    claude_table = "\n".join(claude_rows)

    # CodeX ä¿¡æ¯
    codex = data["codex"]

    markdown = f"""# Daily AI Token Consumption Report

**æ—¥æœŸ**: {data['date']}

---

## 1. Claude Code æ¶ˆè€—

| æ¨¡å‹ | è¾“å…¥Token | è¾“å‡ºToken | ä¼šè¯æ•° | æˆæœ¬(USD) |
|------|----------|----------|--------|----------|
{claude_table}

---

## 2. CodeX æ¶ˆè€—

| æœåŠ¡ | å¿«é€Ÿè¯·æ±‚ | æ…¢é€Ÿè¯·æ±‚ | æœˆè´¹ | æ—¥å‡æˆæœ¬(USD) |
|------|---------|---------|------|--------------|
| {codex['service'].replace('_', ' ').title()} | {codex.get('fast_requests_used', 'N/A')}/500 | {codex.get('slow_requests_used', 'N/A')} | ${codex['monthly_cost_usd']:.2f} | ${codex['daily_amortized_cost_usd']:.2f} |

---

## 3. æ€»è®¡

- **ä»Šæ—¥æ€»æˆæœ¬**: ${data['total_daily_cost_usd']:.2f}
- **æœ¬æœˆç´¯è®¡**: *(éœ€è¦ä»æœˆåº¦æ—¥å¿—è®¡ç®—)*
- **é¢„è®¡æœˆæˆæœ¬**: ${data['total_daily_cost_usd'] * 30:.2f}

---

## 4. ä¸»è¦å·¥ä½œå†…å®¹

{data['notes'] if data['notes'] else "*(æœªå¡«å†™)*"}

---

## 5. æˆæœ¬åˆ†æ

### æ•ˆç‡æŒ‡æ ‡
- Token å•ä»·ï¼ˆåŠ æƒå¹³å‡ï¼‰: ${(data['claude_code']['total_cost_usd'] / (total_input + total_output) * 1_000_000):.4f} / 1M tokens
- ä¼šè¯å¹³å‡æˆæœ¬: ${(data['total_daily_cost_usd'] / total_sessions):.2f} / session

### æˆæœ¬çŠ¶æ€
"""

    # æˆæœ¬é¢„è­¦
    daily_cost = data['total_daily_cost_usd']
    if daily_cost < 3:
        markdown += "ğŸŸ¢ **æ­£å¸¸èŒƒå›´** - æ—¥æˆæœ¬åœ¨é¢„ç®—å†…\n"
    elif daily_cost < 10:
        markdown += "ğŸŸ¡ **éœ€è¦å…³æ³¨** - æ—¥æˆæœ¬åé«˜ï¼Œå»ºè®®æ£€æŸ¥ä½¿ç”¨æ¨¡å¼\n"
    else:
        markdown += "ğŸ”´ **è¶…é¢„ç®—** - æ—¥æˆæœ¬è¶…æ ‡ï¼Œéœ€è¦ç«‹å³ä¼˜åŒ–ç­–ç•¥\n"

    markdown += f"""
### ä¼˜åŒ–å»ºè®®
1. ç®€å•ä»»åŠ¡ä¼˜å…ˆä½¿ç”¨ Haikuï¼ˆæˆæœ¬é™ä½ 90%ï¼‰
2. å‡å°‘ä¸å¿…è¦çš„ä¸Šä¸‹æ–‡é•¿åº¦
3. æ‰¹é‡å¤„ç†ç›¸ä¼¼ä»»åŠ¡

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

    return markdown

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="ç”Ÿæˆæ¯æ—¥ Token æ¶ˆè€—æŠ¥å‘Š")
    parser.add_argument(
        "--date",
        default=datetime.now().strftime("%Y-%m-%d"),
        help="æ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä¸ºä»Šå¤©"
    )
    parser.add_argument(
        "--output-dir",
        default="docs/finance",
        help="æŠ¥å‘Šè¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--notes",
        default="",
        help="å½“æ—¥ä¸»è¦å·¥ä½œå†…å®¹å¤‡æ³¨"
    )

    args = parser.parse_args()

    output_dir = Path(args.output_dir)
    generate_daily_report(args.date, output_dir, args.notes)

if __name__ == "__main__":
    main()
