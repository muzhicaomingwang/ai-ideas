"""
ÊØèÊó•ÂàõÊÑèÁîüÊàêÊúçÂä°

ÂäüËÉΩÔºö
- Êî∂ÈõÜ‰ª£Á†Å/ÊñáÊ°£‰∏ä‰∏ãÊñá
- Ë∞ÉÁî® OpenAI GPT-4 ÁîüÊàêÊîπËøõÂàõÊÑè
- ËßÑËåÉÂåñËæìÂá∫‰∏∫ÁªìÊûÑÂåñÊï∞ÊçÆ

@author TeamVenture Team
@version 1.0.0
@since 2026-01-15
"""
from __future__ import annotations

import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any

from git import Repo

from src.integrations.openai_client import OpenAIClient
from src.models.idea import DailyIdeaBatch, ProductIdea
from src.services.id_generator import new_prefixed_id

logger = logging.getLogger(__name__)


class DailyIdeaGenerator:
    """ÊØèÊó•ÂàõÊÑèÁîüÊàêÂô®"""

    def __init__(self):
        self.openai_client = OpenAIClient()
        # ‰ªìÂ∫ìÊ†πÁõÆÂΩïÔºö‰ªé python-ai-service Âêë‰∏ä6Á∫ßÂà∞Ëææ ideas/apps/teamventure
        self.repo_root = Path(__file__).parent.parent.parent.parent.parent.parent
        self.ideas_dir = self.repo_root / "docs" / "ideas"
        self.repo = Repo(self.repo_root)

    async def generate_daily_ideas(self) -> DailyIdeaBatch:
        """
        ÁîüÊàê‰ªäÊó•ÂàõÊÑè

        Returns:
            DailyIdeaBatch: ÂåÖÂê´5‰∏™ÂàõÊÑèÁöÑÊâπÊ¨°ÂØπË±°
        """
        today = datetime.now().strftime("%Y-%m-%d")
        logger.info(f"üéØ ÂºÄÂßãÁîüÊàê {today} ÁöÑÂàõÊÑè...")

        # 1. Êî∂ÈõÜ‰∏ä‰∏ãÊñá
        context = await self._collect_context()
        logger.info(f"‚úÖ ‰∏ä‰∏ãÊñáÊî∂ÈõÜÂÆåÊàê: {len(context)} È°π")

        # 2. ÊûÑÂª∫ Prompt
        prompt = self._build_prompt(context)

        # 3. Ë∞ÉÁî® GPT-4 ÁîüÊàê
        logger.info("ü§ñ Ë∞ÉÁî® OpenAI API ÁîüÊàêÂàõÊÑè...")
        raw_response = await self.openai_client.generate_json(prompt)

        # 4. Ëß£ÊûêÂπ∂ËßÑËåÉÂåñ
        ideas = self._parse_ideas(raw_response)
        logger.info(f"‚úÖ ÂàõÊÑèËß£ÊûêÂÆåÊàê: {len(ideas)} ‰∏™")

        return DailyIdeaBatch(date=today, ideas=ideas, metadata=context["metadata"])

    async def _collect_context(self) -> dict[str, Any]:
        """
        Êî∂ÈõÜ‰∏ä‰∏ãÊñá‰ø°ÊÅØ

        ÂåÖÊã¨Ôºö‰ª£Á†ÅÂèòÊõ¥„ÄÅÂÖ≥ÈîÆÊñáÊ°£„ÄÅÂéÜÂè≤ÂàõÊÑè„ÄÅ‰ª£Á†ÅË¥®ÈáèÊåáÊ†á
        """
        logger.info("üìö Êî∂ÈõÜ‰∏ä‰∏ãÊñá‰ø°ÊÅØ...")

        # 1. Êâ´ÊèèÊúÄËøë‰ª£Á†ÅÂèòÊõ¥ÔºàÊúÄËøë7Â§©ÁöÑcommitsÔºâ
        recent_changes = self._get_recent_changes(days=7)

        # 2. ËØªÂèñÂÖ≥ÈîÆÊñáÊ°£
        prd_content = self._read_doc("docs/requirements/prd.md")
        design_content = self._read_doc("docs/design/detailed-design.md")
        qa_summary = self._read_doc("docs/qa/QUALITY_IMPROVEMENT_SUMMARY_2026-01-08.md")

        # 3. Ëé∑ÂèñÂéÜÂè≤ÂàõÊÑèÔºàÈÅøÂÖçÈáçÂ§çÔºâ
        historical_ideas = self._get_historical_ideas(days=30)

        # 4. ÁªüËÆ°‰ª£Á†ÅË¥®ÈáèÊåáÊ†á
        code_stats = self._analyze_code_quality()

        return {
            "recent_changes": recent_changes,
            "prd_summary": prd_content[:2000],  # Êà™ÂèñÂÖ≥ÈîÆÈÉ®ÂàÜÔºåÈÅøÂÖç token Ë∂ÖÈôê
            "design_summary": design_content[:2000],
            "qa_summary": qa_summary[:1000],
            "historical_ideas": historical_ideas,
            "code_stats": code_stats,
            "metadata": {
                "context_sources": ["git_commits", "prd", "design_docs", "qa_reports", "historical_ideas"],
                "generated_at": datetime.now().isoformat(),
                "repo_root": str(self.repo_root),
            },
        }

    def _get_recent_changes(self, days: int = 7) -> str:
        """
        Ëé∑ÂèñÊúÄËøë‰ª£Á†ÅÂèòÊõ¥

        Args:
            days: ÂõûÊ∫ØÂ§©Êï∞

        Returns:
            str: Git Êèê‰∫§ËÆ∞ÂΩïÊëòË¶Å
        """
        try:
            since_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
            commits = list(self.repo.iter_commits(f"--since={since_date}", max_count=20))

            if not commits:
                return "ÊúÄËøëÊó†‰ª£Á†ÅÂèòÊõ¥"

            lines = [f"ÊúÄËøë {days} Â§©ÁöÑ‰ª£Á†ÅÂèòÊõ¥Ôºà{len(commits)} Ê¨°Êèê‰∫§ÔºâÔºö", ""]
            for commit in commits[:10]:  # Âè™ÂèñÂâç10Êù°
                short_hash = commit.hexsha[:7]
                message = commit.message.split("\n")[0][:60]  # Âè™ÂèñÁ¨¨‰∏ÄË°åÔºåÊà™Êñ≠ËøáÈïøÊ∂àÊÅØ
                lines.append(f"- [{short_hash}] {message}")

            return "\n".join(lines)

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Ëé∑Âèñ Git Êèê‰∫§ËÆ∞ÂΩïÂ§±Ë¥•: {e}")
            return "ÔºàÊó†Ê≥ïËé∑Âèñ Git ÂéÜÂè≤Ôºâ"

    def _read_doc(self, relative_path: str) -> str:
        """
        ËØªÂèñÊñáÊ°£ÂÜÖÂÆπ

        Args:
            relative_path: Áõ∏ÂØπ‰∫é‰ªìÂ∫ìÊ†πÁõÆÂΩïÁöÑË∑ØÂæÑ

        Returns:
            str: ÊñáÊ°£ÂÜÖÂÆπÔºàÊúÄÂ§öËØªÂèñÂâç5000Â≠óÁ¨¶Ôºâ
        """
        try:
            doc_path = self.repo_root / relative_path
            if not doc_path.exists():
                logger.warning(f"‚ö†Ô∏è ÊñáÊ°£‰∏çÂ≠òÂú®: {relative_path}")
                return f"ÔºàÊñáÊ°£ {relative_path} ‰∏çÂ≠òÂú®Ôºâ"

            content = doc_path.read_text(encoding="utf-8")
            # Êà™ÂèñÂâç5000Â≠óÁ¨¶ÔºåÈÅøÂÖç Prompt ËøáÈïø
            if len(content) > 5000:
                content = content[:5000] + "\n\nÔºàÊñáÊ°£ËæÉÈïøÔºåÂ∑≤Êà™Êñ≠Ôºâ"

            return content

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ËØªÂèñÊñáÊ°£Â§±Ë¥• {relative_path}: {e}")
            return f"ÔºàÊó†Ê≥ïËØªÂèñ {relative_path}Ôºâ"

    def _get_historical_ideas(self, days: int = 30) -> str:
        """
        Ëé∑ÂèñÂéÜÂè≤ÂàõÊÑèÔºàÈÅøÂÖçÈáçÂ§çÔºâ

        Args:
            days: ÂõûÊ∫ØÂ§©Êï∞

        Returns:
            str: ÂéÜÂè≤ÂàõÊÑèÊ†áÈ¢òÂàóË°®
        """
        try:
            if not self.ideas_dir.exists():
                return "ÔºàÊöÇÊó†ÂéÜÂè≤ÂàõÊÑèÔºâ"

            # Êâ´ÊèèÊúÄËøë30Â§©ÁöÑÂàõÊÑèÊñá‰ª∂
            since_date = datetime.now() - timedelta(days=days)
            historical_titles = []

            # ÈÅçÂéÜ YYYY/MM/*.md Êñá‰ª∂
            for year_dir in self.ideas_dir.glob("*"):
                if not year_dir.is_dir():
                    continue
                for month_dir in year_dir.glob("*"):
                    if not month_dir.is_dir():
                        continue
                    for idea_file in month_dir.glob("*.md"):
                        # ‰ªéÊñá‰ª∂ÂêçÊèêÂèñÊó•ÊúüÔºàYYYY-MM-DD.mdÔºâ
                        try:
                            file_date_str = idea_file.stem  # ÂéªÊéâ .md ÂêéÁºÄ
                            file_date = datetime.strptime(file_date_str, "%Y-%m-%d")

                            if file_date >= since_date:
                                # ËØªÂèñÊñá‰ª∂ÔºåÊèêÂèñÂàõÊÑèÊ†áÈ¢ò
                                content = idea_file.read_text(encoding="utf-8")
                                titles = self._extract_idea_titles(content)
                                historical_titles.extend(titles)

                        except ValueError:
                            continue  # Ë∑≥ËøáÊ†ºÂºè‰∏çÂåπÈÖçÁöÑÊñá‰ª∂

            if not historical_titles:
                return "ÔºàËøë30Â§©ÊöÇÊó†ÂéÜÂè≤ÂàõÊÑèÔºâ"

            return "Ëøë30Â§©Â∑≤ÁîüÊàêÁöÑÂàõÊÑèÊ†áÈ¢òÔºàÈÅøÂÖçÈáçÂ§çÔºâÔºö\n- " + "\n- ".join(historical_titles[:20])

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Ëé∑ÂèñÂéÜÂè≤ÂàõÊÑèÂ§±Ë¥•: {e}")
            return "ÔºàÊó†Ê≥ïËé∑ÂèñÂéÜÂè≤ÂàõÊÑèÔºâ"

    def _extract_idea_titles(self, markdown_content: str) -> list[str]:
        """
        ‰ªé Markdown Êñá‰ª∂‰∏≠ÊèêÂèñÂàõÊÑèÊ†áÈ¢ò

        Args:
            markdown_content: Markdown ÊñáÊú¨

        Returns:
            list[str]: ÂàõÊÑèÊ†áÈ¢òÂàóË°®
        """
        titles = []
        for line in markdown_content.split("\n"):
            # ÂåπÈÖç‰∏âÁ∫ßÊ†áÈ¢òÔºà### ÂàõÊÑèÊ†áÈ¢òÔºâ
            if line.startswith("### ") and not line.startswith("### ÂäüËÉΩ"):
                title = line.replace("### ", "").strip()
                titles.append(title)
        return titles

    def _analyze_code_quality(self) -> dict:
        """
        ÂàÜÊûê‰ª£Á†ÅË¥®ÈáèÊåáÊ†á

        Returns:
            dict: ‰ª£Á†ÅË¥®ÈáèÁªüËÆ°
        """
        try:
            java_dir = self.repo_root / "src" / "backend" / "java-business-service" / "src"
            python_dir = self.repo_root / "src" / "backend" / "python-ai-service" / "src"

            # ÁªüËÆ° TODO/FIXME Ê≥®ÈáäÊï∞Èáè
            def count_todos(directory: Path, pattern: str) -> int:
                count = 0
                for file in directory.rglob("*.java") if "java" in str(directory) else directory.rglob("*.py"):
                    try:
                        content = file.read_text(encoding="utf-8")
                        count += content.upper().count(pattern.upper())
                    except Exception:
                        pass
                return count

            java_todos = count_todos(java_dir, "TODO") if java_dir.exists() else 0
            java_fixmes = count_todos(java_dir, "FIXME") if java_dir.exists() else 0
            python_todos = count_todos(python_dir, "TODO") if python_dir.exists() else 0
            python_fixmes = count_todos(python_dir, "FIXME") if python_dir.exists() else 0

            return {
                "java_todos": java_todos,
                "java_fixmes": java_fixmes,
                "python_todos": python_todos,
                "python_fixmes": python_fixmes,
                "total_todos": java_todos + python_todos,
                "total_fixmes": java_fixmes + python_fixmes,
            }

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ‰ª£Á†ÅË¥®ÈáèÂàÜÊûêÂ§±Ë¥•: {e}")
            return {"error": str(e)}

    def _build_prompt(self, context: dict[str, Any]) -> str:
        """
        ÊûÑÂª∫ GPT-4 Prompt

        Args:
            context: ‰∏ä‰∏ãÊñá‰ø°ÊÅØÂ≠óÂÖ∏

        Returns:
            str: ÂÆåÊï¥ÁöÑ Prompt ÊñáÊú¨
        """
        code_stats = context.get("code_stats", {})
        todo_info = ""
        if code_stats.get("total_todos", 0) > 0 or code_stats.get("total_fixmes", 0) > 0:
            todo_info = f"\n‰ª£Á†Å‰∏≠Êúâ {code_stats.get('total_todos', 0)} ‰∏™ TODO Âíå {code_stats.get('total_fixmes', 0)} ‰∏™ FIXMEÔºåÂèØËÄÉËôëÊäÄÊúØÂÄ∫Ê∏ÖÁêÜÁõ∏ÂÖ≥ÂàõÊÑè„ÄÇ"

        return f"""‰Ω†ÊòØ TeamVenture AI Âõ¢Âª∫Á≠ñÂàíÂä©ÊâãÁöÑ‰∫ßÂìÅÁªèÁêÜÔºåË¥üË¥£ÊèêÂá∫ÂäüËÉΩÊîπËøõÂª∫ËÆÆ„ÄÇ

**‰ªªÂä°**ÔºöÁîüÊàê5‰∏™È´òË¥®ÈáèÁöÑÂäüËÉΩÊîπËøõÂàõÊÑè„ÄÇ

**‰∏ä‰∏ãÊñá‰ø°ÊÅØ**Ôºö

1. ÊúÄËøë‰ª£Á†ÅÂèòÊõ¥ÔºàÊúÄËøë7Â§©ÔºâÔºö
{context['recent_changes']}

2. ‰∫ßÂìÅÊ†∏ÂøÉÂÆö‰ΩçÔºàPRDÊëòË¶ÅÔºâÔºö
{context['prd_summary']}

3. ÊäÄÊúØÊû∂ÊûÑÊ¶ÇË¶ÅÔºàËÆæËÆ°ÊñáÊ°£ÊëòË¶ÅÔºâÔºö
{context['design_summary']}

4. QA Ë¥®ÈáèÊîπËøõÊÄªÁªìÔºö
{context.get('qa_summary', 'ÔºàÊöÇÊó†Ôºâ')}

5. ‰ª£Á†ÅË¥®ÈáèÊåáÊ†áÔºö
{json.dumps(code_stats, ensure_ascii=False)}{todo_info}

6. Ëøë30Â§©Â∑≤ÁîüÊàêÂàõÊÑèÔºàÈÅøÂÖçÈáçÂ§çÔºâÔºö
{context['historical_ideas']}

**‰∏•Ê†ºË¶ÅÊ±Ç**Ôºö
1. ‚úÖ ËÅöÁÑ¶ TeamVenture ÂäüËÉΩÊîπËøõÔºà‰∏çË¶ÅÂÖ®Êñ∞‰∫ßÂìÅÊÉ≥Ê≥ïÔºâ
2. ‚úÖ Ë¶ÜÁõñ5‰∏™ÂàÜÁ±ªÔºöÂäüËÉΩÂ¢ûÂº∫„ÄÅÊÄßËÉΩ‰ºòÂåñ„ÄÅ‰ΩìÈ™åÊîπËøõ„ÄÅÊû∂ÊûÑ‰ºòÂåñ„ÄÅÂÆâÂÖ®Âä†Âõ∫ÔºàÂêÑ1‰∏™Ôºâ
3. ‚úÖ ‰ºòÂÖàÁ∫ßÂàÜÂ∏ÉÔºö1‰∏™P0Ôºå2‰∏™P1Ôºå2‰∏™P2
4. ‚úÖ Â∑•‰ΩúÈáèÂàÜÂ∏ÉÔºö2‰∏™SÔºå2‰∏™MÔºå1‰∏™LÔºàÈÅøÂÖçÂÖ®ÊòØÂ∞èÊîπËøõÊàñÂÖ®ÊòØÂ§ßÂ∑•Á®ãÔºâ
5. ‚úÖ ÂøÖÈ°ªÂÖ∑‰ΩìÂèØËêΩÂú∞Ôºö
   - ‚ùå ÈîôËØØÁ§∫‰æãÔºö"ÊèêÂçáÁî®Êà∑‰ΩìÈ™å"ÔºàÂ§™Á©∫Ê≥õÔºâ
   - ‚úÖ Ê≠£Á°ÆÁ§∫‰æãÔºö"Âú®ÊñπÊ°àÂØπÊØîÈ°µÂ¢ûÂä†Â∑¶Âè≥ÊªëÂä®ÂàáÊç¢ÂäüËÉΩÔºåÂáèÂ∞ëÁî®Êà∑ÁÇπÂáªÊ¨°Êï∞"
6. ‚úÖ ÊèèËø∞‰∏≠ÂåÖÂê´ÂÆûÁé∞Ë¶ÅÁÇπÔºö
   - Ê∂âÂèäÂì™‰∏™Êñá‰ª∂/Ê®°Âùó
   - ÂÖ∑‰ΩìÊîπÂä®ÁÇπÔºàÂ¶Ç"Âú® PlanService.java Á¨¨320Ë°åÊ∑ªÂä†ÁºìÂ≠òÈÄªËæë"Ôºâ
   - ÂÖ≥ÈîÆÊäÄÊúØÈÄâÂûãÔºàÂ¶Ç"‰ΩøÁî® Redis Sorted Set"Ôºâ
7. ‚úÖ È¢ÑÊúüÊî∂ÁõäÈúÄÈáèÂåñÔºö
   - ‚ùå ÈîôËØØÁ§∫‰æãÔºö"ÊèêÂçáÊÄßËÉΩ"
   - ‚úÖ Ê≠£Á°ÆÁ§∫‰æãÔºö"ÂáèÂ∞ëÂìçÂ∫îÊó∂Èó¥ 50%Ôºà‰ªé 2Áßí ÈôçËá≥ 1ÁßíÔºâ"
8. ‚úÖ ÈÅøÂÖçÈáçÂ§çÂéÜÂè≤ÂàõÊÑèÔºàÊ£ÄÊü•‰∏ä‰∏ãÊñá‰∏≠ÁöÑÂéÜÂè≤Ê†áÈ¢òÔºâ

**ËæìÂá∫Ê†ºÂºè**Ôºà‰∏•Ê†º JSONÔºå‰∏çË¶Å Markdown ‰ª£Á†ÅÂùóÔºâÔºö
{{
  "ideas": [
    {{
      "title": "ÂàõÊÑèÊ†áÈ¢òÔºà10Â≠ó‰ª•ÂÜÖÔºâ",
      "category": "feature|performance|ux|architecture|security",
      "description": "ËØ¶ÁªÜÊèèËø∞Ôºà100-200Â≠óÔºåÂåÖÂê´ÔºöËÉåÊôØ„ÄÅÂÖ∑‰ΩìÊñπÊ°à„ÄÅÂÆûÁé∞Ë¶ÅÁÇπ„ÄÅÊäÄÊúØÁªÜËäÇÔºâ",
      "priority": "P0|P1|P2|P3",
      "estimated_effort": "S|M|L|XL",
      "expected_impact": "È¢ÑÊúüÊî∂ÁõäÔºàÂøÖÈ°ªÈáèÂåñÔºåÂ¶ÇÔºöÊèêÂçáXX%„ÄÅÂáèÂ∞ëYYÁßí„ÄÅÂ¢ûÂä†ZZÁî®Êà∑Ôºâ",
      "context": "‰∏∫‰ªÄ‰πàÁé∞Âú®ÊèêËøô‰∏™ÂàõÊÑèÔºàÂü∫‰∫é‰∏ä‰∏ãÊñáÁöÑÂêàÁêÜÊÄßÔºåÂ¶ÇÔºöÊ†πÊçÆXXÊä•Âëä„ÄÅÁî®Êà∑ÂèçÈ¶à„ÄÅ‰ª£Á†ÅÂàÜÊûêÁ≠âÔºâ"
    }},
    ... ÂÖ±5‰∏™
  ]
}}

**Á§∫‰æãÂàõÊÑè**Ôºà‰ªÖ‰ΩúÊ†ºÂºèÂèÇËÄÉÔºâÔºö
{{
  "title": "ÊñπÊ°àÂØπÊØîÊô∫ËÉΩÊéíÂ∫è",
  "category": "ux",
  "description": "ÂΩìÂâçÊñπÊ°àÂØπÊØîÈ°µÊåâ budget/standard/premium Âõ∫ÂÆöÈ°∫Â∫èÂ±ïÁ§∫„ÄÇÂª∫ËÆÆÊ†πÊçÆÁî®Êà∑ÂéÜÂè≤ÂÅèÂ•ΩÊô∫ËÉΩÊéíÂ∫èÔºàÂ¶ÇÈáçËßÜÊÄß‰ª∑ÊØîÂàô budget ‰ºòÂÖàÔºåÈáçËßÜÂìÅË¥®Âàô premium ‰ºòÂÖàÔºâ„ÄÇÂÆûÁé∞ÊñπÂºèÔºöÂú® PlanService.java Á¨¨580Ë°åÁöÑ listPlans() ÊñπÊ≥ï‰∏≠ÔºåÂü∫‰∫éÁî®Êà∑ÁîªÂÉèÔºà‰ªé Redis ÁºìÂ≠òËØªÂèñÂéÜÂè≤ÈÄâÊã©ËÆ∞ÂΩïÔºâË∞ÉÊï¥ËøîÂõûÈ°∫Â∫è„ÄÇÂâçÁ´Ø‰øùÊåÅÁé∞ÊúâUIÔºå‰ªÖË∞ÉÊï¥Êï∞ÊçÆÈ°∫Â∫è„ÄÇÊäÄÊúØÁªÜËäÇÔºöRedis key ËÆæËÆ°‰∏∫ user:{{user_id}}:plan_preferenceÔºåTTL 90Â§©„ÄÇ",
  "priority": "P1",
  "estimated_effort": "M",
  "expected_impact": "ÊèêÂçáÊñπÊ°àÁÇπÂáªÁéá 15%ÔºåÂáèÂ∞ëÁî®Êà∑ÊØîËæÉÊó∂Èïø 20%Ôºà‰ªéÂπ≥Âùá40ÁßíÈôçËá≥32ÁßíÔºâÔºåÈôç‰ΩéÈ¶ñÂ±èË∑≥Âá∫Áéá 10%",
  "context": "Ê†πÊçÆ QA Êä•ÂëäÔºàQUALITY_IMPROVEMENT_SUMMARY_2026-01-08.mdÔºâÔºåÁî®Êà∑Âú®ÂØπÊØîÈ°µÂπ≥ÂùáÂÅúÁïô40ÁßíÔºåÂ≠òÂú®ÈÄâÊã©Âõ∞Èöæ„ÄÇÊô∫ËÉΩÊéíÂ∫èÂèØÈôç‰ΩéËÆ§Áü•Ë¥üÊãÖ„ÄÇ"
}}

Áé∞Âú®ËØ∑ÁîüÊàê5‰∏™È´òË¥®ÈáèÂàõÊÑèÔºà‰ªÖËøîÂõû JSONÔºå‰∏çË¶ÅÂÖ∂‰ªñÊñáÂ≠óÔºâÔºö
"""

    def _parse_ideas(self, raw: dict[str, Any]) -> list[ProductIdea]:
        """
        Ëß£ÊûêÂπ∂ËßÑËåÉÂåñÂàõÊÑèÊï∞ÊçÆ

        Args:
            raw: OpenAI ËøîÂõûÁöÑ JSON Êï∞ÊçÆ

        Returns:
            list[ProductIdea]: ÂàõÊÑèÂØπË±°ÂàóË°®

        Raises:
            ValueError: Â¶ÇÊûúÂàõÊÑèÊï∞Èáè‰∏çÁ≠â‰∫é5
        """
        ideas_raw = raw.get("ideas", [])
        if len(ideas_raw) != 5:
            logger.error(f"‚ùå ÂàõÊÑèÊï∞ÈáèÈîôËØØ: ÊúüÊúõ5‰∏™ÔºåÂÆûÈôÖ{len(ideas_raw)}‰∏™")
            raise ValueError(f"Expected 5 ideas, got {len(ideas_raw)}")

        ideas = []
        for idea_raw in ideas_raw:
            try:
                idea = ProductIdea(
                    id=new_prefixed_id("idea"),
                    title=str(idea_raw["title"]),
                    category=str(idea_raw["category"]),
                    description=str(idea_raw["description"]),
                    priority=str(idea_raw["priority"]),
                    estimated_effort=str(idea_raw["estimated_effort"]),
                    expected_impact=str(idea_raw["expected_impact"]),
                    context=str(idea_raw.get("context", "")),
                )
                ideas.append(idea)

            except (KeyError, ValueError) as e:
                logger.error(f"‚ùå ÂàõÊÑèËß£ÊûêÂ§±Ë¥•: {e}, ÂéüÂßãÊï∞ÊçÆ: {idea_raw}")
                raise ValueError(f"Failed to parse idea: {e}")

        # È™åËØÅÂàÜÁ±ªÂíå‰ºòÂÖàÁ∫ßÂàÜÂ∏É
        self._validate_distribution(ideas)

        return ideas

    def _validate_distribution(self, ideas: list[ProductIdea]):
        """
        È™åËØÅÂàõÊÑèÁöÑÂàÜÁ±ªÂíå‰ºòÂÖàÁ∫ßÂàÜÂ∏É

        Args:
            ideas: ÂàõÊÑèÂàóË°®

        Raises:
            ValueError: Â¶ÇÊûúÂàÜÂ∏É‰∏çÁ¨¶ÂêàË¶ÅÊ±Ç
        """
        # Ê£ÄÊü•ÂàÜÁ±ªÔºàÂ∫îÂêÑ1‰∏™Ôºâ
        categories = [idea.category for idea in ideas]
        expected_categories = {"feature", "performance", "ux", "architecture", "security"}
        if set(categories) != expected_categories:
            logger.warning(
                f"‚ö†Ô∏è ÂàÜÁ±ªÂàÜÂ∏É‰∏çÂùá: {categories}ÔºåÊúüÊúõ {expected_categories}"
            )
            # ‰∏çÊäõÂºÇÂ∏∏Ôºå‰ªÖËÆ∞ÂΩïË≠¶Âëä

        # Ê£ÄÊü•‰ºòÂÖàÁ∫ßÂàÜÂ∏ÉÔºàÂ∫îÊúâ1‰∏™P0Ôºå2‰∏™P1Ôºå2‰∏™P2Ôºâ
        priorities = [idea.priority for idea in ideas]
        priority_counts = {p: priorities.count(p) for p in set(priorities)}
        logger.info(f"üìä ‰ºòÂÖàÁ∫ßÂàÜÂ∏É: {priority_counts}")

    def _get_historical_ideas(self, days: int = 30) -> str:
        """Ëé∑ÂèñÂéÜÂè≤ÂàõÊÑèÂÆûÁé∞"""
        try:
            if not self.ideas_dir.exists():
                return "ÔºàÊöÇÊó†ÂéÜÂè≤ÂàõÊÑèÔºâ"

            since_date = datetime.now() - timedelta(days=days)
            historical_titles = []

            # ÈÅçÂéÜ YYYY/MM/*.md Êñá‰ª∂
            for year_dir in sorted(self.ideas_dir.glob("*"), reverse=True):
                if not year_dir.is_dir() or not year_dir.name.isdigit():
                    continue

                for month_dir in sorted(year_dir.glob("*"), reverse=True):
                    if not month_dir.is_dir() or not month_dir.name.isdigit():
                        continue

                    for idea_file in sorted(month_dir.glob("*.md"), reverse=True):
                        try:
                            file_date_str = idea_file.stem
                            file_date = datetime.strptime(file_date_str, "%Y-%m-%d")

                            if file_date >= since_date:
                                content = idea_file.read_text(encoding="utf-8")
                                titles = self._extract_idea_titles(content)
                                historical_titles.extend(titles)

                        except ValueError:
                            continue

            if not historical_titles:
                return "ÔºàËøë30Â§©ÊöÇÊó†ÂéÜÂè≤ÂàõÊÑèÔºâ"

            return "Ëøë30Â§©Â∑≤ÁîüÊàêÁöÑÂàõÊÑèÊ†áÈ¢òÔºàÈÅøÂÖçÈáçÂ§çÔºâÔºö\n- " + "\n- ".join(historical_titles[:20])

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Ëé∑ÂèñÂéÜÂè≤ÂàõÊÑèÂ§±Ë¥•: {e}")
            return "ÔºàÊó†Ê≥ïËé∑ÂèñÂéÜÂè≤ÂàõÊÑèÔºâ"

    def _analyze_code_quality(self) -> dict:
        """ÔºàÂÆûÁé∞ËßÅ‰∏äÊñπÔºâ"""
        # Â∑≤Âú® _analyze_code_quality ÊñπÊ≥ï‰∏≠ÂÆûÁé∞
        try:
            java_dir = self.repo_root / "src" / "backend" / "java-business-service" / "src"
            python_dir = self.repo_root / "src" / "backend" / "python-ai-service" / "src"

            def count_pattern(directory: Path, pattern: str, extensions: list[str]) -> int:
                count = 0
                for ext in extensions:
                    for file in directory.rglob(f"*{ext}"):
                        try:
                            content = file.read_text(encoding="utf-8")
                            count += content.upper().count(pattern.upper())
                        except Exception:
                            pass
                return count

            java_todos = count_pattern(java_dir, "TODO", [".java"]) if java_dir.exists() else 0
            java_fixmes = count_pattern(java_dir, "FIXME", [".java"]) if java_dir.exists() else 0
            python_todos = count_pattern(python_dir, "TODO", [".py"]) if python_dir.exists() else 0
            python_fixmes = count_pattern(python_dir, "FIXME", [".py"]) if python_dir.exists() else 0

            return {
                "java_todos": java_todos,
                "java_fixmes": java_fixmes,
                "python_todos": python_todos,
                "python_fixmes": python_fixmes,
                "total_todos": java_todos + python_todos,
                "total_fixmes": java_fixmes + python_fixmes,
            }

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ‰ª£Á†ÅË¥®ÈáèÂàÜÊûêÂ§±Ë¥•: {e}")
            return {"error": str(e)}
