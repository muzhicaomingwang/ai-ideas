"""
åˆ›æ„ç”Ÿæˆå™¨æµ‹è¯•

æµ‹è¯•æ¯æ—¥åˆ›æ„ç”ŸæˆåŠŸèƒ½çš„æ ¸å¿ƒé€»è¾‘
"""
from __future__ import annotations

import pytest
from pathlib import Path

from src.services.idea_generator import DailyIdeaGenerator
from src.models.idea import ProductIdea, DailyIdeaBatch


@pytest.mark.asyncio
async def test_generate_daily_ideas():
    """æµ‹è¯•åˆ›æ„ç”Ÿæˆå®Œæ•´æµç¨‹"""
    generator = DailyIdeaGenerator()
    batch = await generator.generate_daily_ideas()

    # éªŒè¯æ‰¹æ¬¡ç»“æ„
    assert isinstance(batch, DailyIdeaBatch)
    assert batch.date is not None
    assert len(batch.ideas) == 5

    # éªŒè¯æ¯ä¸ªåˆ›æ„
    for idea in batch.ideas:
        assert isinstance(idea, ProductIdea)
        assert idea.id.startswith("idea_")
        assert idea.title
        assert idea.category in ["feature", "performance", "ux", "architecture", "security"]
        assert idea.priority in ["P0", "P1", "P2", "P3"]
        assert idea.estimated_effort in ["S", "M", "L", "XL"]
        assert idea.description
        assert idea.expected_impact


@pytest.mark.asyncio
async def test_context_collection():
    """æµ‹è¯•ä¸Šä¸‹æ–‡æ”¶é›†"""
    generator = DailyIdeaGenerator()
    context = await generator._collect_context()

    # éªŒè¯ä¸Šä¸‹æ–‡åŒ…å«å¿…è¦å­—æ®µ
    assert "recent_changes" in context
    assert "prd_summary" in context
    assert "design_summary" in context
    assert "historical_ideas" in context
    assert "code_stats" in context
    assert "metadata" in context

    # éªŒè¯å…ƒæ•°æ®
    metadata = context["metadata"]
    assert "context_sources" in metadata
    assert "generated_at" in metadata


def test_extract_idea_titles():
    """æµ‹è¯•ä» Markdown æå–åˆ›æ„æ ‡é¢˜"""
    generator = DailyIdeaGenerator()

    markdown_content = """
# TeamVenture æ¯æ—¥åˆ›æ„ - 2026-01-15

## ğŸš€ åŠŸèƒ½å¢å¼º

### æ–¹æ¡ˆå¯¹æ¯”æ™ºèƒ½æ’åº

**ä¼˜å…ˆçº§**: P1

### æ–°å¢æ´»åŠ¨ç±»å‹

**ä¼˜å…ˆçº§**: P2
"""

    titles = generator._extract_idea_titles(markdown_content)

    assert len(titles) == 2
    assert "æ–¹æ¡ˆå¯¹æ¯”æ™ºèƒ½æ’åº" in titles
    assert "æ–°å¢æ´»åŠ¨ç±»å‹" in titles


def test_analyze_code_quality():
    """æµ‹è¯•ä»£ç è´¨é‡åˆ†æ"""
    generator = DailyIdeaGenerator()
    stats = generator._analyze_code_quality()

    # éªŒè¯è¿”å›çš„ç»Ÿè®¡å­—æ®µ
    assert isinstance(stats, dict)

    # å¦‚æœæˆåŠŸï¼ˆæ— é”™è¯¯ï¼‰ï¼Œåº”åŒ…å«ç»Ÿè®¡å­—æ®µ
    if "error" not in stats:
        assert "total_todos" in stats
        assert "total_fixmes" in stats
        assert isinstance(stats["total_todos"], int)
        assert isinstance(stats["total_fixmes"], int)


def test_build_prompt():
    """æµ‹è¯• Prompt æ„å»º"""
    generator = DailyIdeaGenerator()

    mock_context = {
        "recent_changes": "æœ€è¿‘æ— ä»£ç å˜æ›´",
        "prd_summary": "PRD æ‘˜è¦å†…å®¹...",
        "design_summary": "è®¾è®¡æ–‡æ¡£æ‘˜è¦...",
        "qa_summary": "QA æŠ¥å‘Šæ‘˜è¦...",
        "historical_ideas": "ï¼ˆæš‚æ— å†å²åˆ›æ„ï¼‰",
        "code_stats": {"total_todos": 5, "total_fixmes": 2},
        "metadata": {},
    }

    prompt = generator._build_prompt(mock_context)

    # éªŒè¯ Prompt åŒ…å«å…³é”®å…ƒç´ 
    assert "TeamVenture" in prompt
    assert "5ä¸ªé«˜è´¨é‡çš„åŠŸèƒ½æ”¹è¿›åˆ›æ„" in prompt
    assert "feature|performance|ux|architecture|security" in prompt
    assert "P0|P1|P2|P3" in prompt
    assert mock_context["recent_changes"] in prompt
    assert mock_context["prd_summary"] in prompt


@pytest.mark.asyncio
async def test_parse_ideas():
    """æµ‹è¯•åˆ›æ„è§£æ"""
    generator = DailyIdeaGenerator()

    # Mock OpenAI å“åº”
    raw_response = {
        "ideas": [
            {
                "title": "æµ‹è¯•åˆ›æ„1",
                "category": "feature",
                "description": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•åˆ›æ„çš„è¯¦ç»†æè¿°",
                "priority": "P0",
                "estimated_effort": "S",
                "expected_impact": "æå‡10%",
                "context": "åŸºäºæµ‹è¯•éœ€æ±‚",
            },
            {
                "title": "æµ‹è¯•åˆ›æ„2",
                "category": "performance",
                "description": "æ€§èƒ½ä¼˜åŒ–æµ‹è¯•",
                "priority": "P1",
                "estimated_effort": "M",
                "expected_impact": "å‡å°‘å“åº”æ—¶é—´50%",
                "context": "æ€§èƒ½æµ‹è¯•å‘ç°",
            },
            {
                "title": "æµ‹è¯•åˆ›æ„3",
                "category": "ux",
                "description": "ç”¨æˆ·ä½“éªŒæ”¹è¿›",
                "priority": "P1",
                "estimated_effort": "M",
                "expected_impact": "æå‡æ»¡æ„åº¦15%",
                "context": "ç”¨æˆ·åé¦ˆ",
            },
            {
                "title": "æµ‹è¯•åˆ›æ„4",
                "category": "architecture",
                "description": "æ¶æ„é‡æ„",
                "priority": "P2",
                "estimated_effort": "L",
                "expected_impact": "é™ä½ç»´æŠ¤æˆæœ¬",
                "context": "æŠ€æœ¯å€ºåŠ¡æ¸…ç†",
            },
            {
                "title": "æµ‹è¯•åˆ›æ„5",
                "category": "security",
                "description": "å®‰å…¨åŠ å›º",
                "priority": "P2",
                "estimated_effort": "S",
                "expected_impact": "æ¶ˆé™¤å®‰å…¨éšæ‚£",
                "context": "å®‰å…¨å®¡è®¡",
            },
        ]
    }

    ideas = generator._parse_ideas(raw_response)

    assert len(ideas) == 5
    assert all(isinstance(idea, ProductIdea) for idea in ideas)
    assert ideas[0].title == "æµ‹è¯•åˆ›æ„1"
    assert ideas[0].category == "feature"


@pytest.mark.asyncio
async def test_parse_ideas_invalid_count():
    """æµ‹è¯•åˆ›æ„æ•°é‡é”™è¯¯æ—¶çš„å¼‚å¸¸å¤„ç†"""
    generator = DailyIdeaGenerator()

    # åªæœ‰4ä¸ªåˆ›æ„ï¼ˆåº”è¯¥æ˜¯5ä¸ªï¼‰
    invalid_response = {
        "ideas": [
            {
                "title": "åˆ›æ„1",
                "category": "feature",
                "description": "æè¿°",
                "priority": "P0",
                "estimated_effort": "S",
                "expected_impact": "æ”¶ç›Š",
                "context": "ä¸Šä¸‹æ–‡",
            },
            # ... åªæœ‰4ä¸ª
        ]
        * 4
    }

    with pytest.raises(ValueError, match="Expected 5 ideas"):
        generator._parse_ideas(invalid_response)
