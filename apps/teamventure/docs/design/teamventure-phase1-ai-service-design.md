# TeamVenture Phase 1 - Python AIæœåŠ¡è¯¦ç»†è®¾è®¡

> **ç‰ˆæœ¬**: v1.0
> **æ—¥æœŸ**: 2026-01-04
> **çŠ¶æ€**: æ­£å¼ç‰ˆæœ¬ï¼ˆåŸºäºå®é™…å®ç°åå‘å·¥ç¨‹ï¼‰
> **é‡è¦æ€§**: â­â­â­â­â­ æœ¬æ–‡æ¡£æè¿°AIæœåŠ¡çš„å®é™…æ¶æ„ä¸å®ç°

---

## ğŸ“‹ æ–‡æ¡£å¯¼èˆª

| ç« èŠ‚ | å†…å®¹ | é¡µç èŒƒå›´ |
|------|------|---------|
| ç¬¬1ç«  | æ•´ä½“æ¶æ„ä¸æŠ€æœ¯æ ˆ | 1-50 |
| ç¬¬2ç«  | LangGraphå·¥ä½œæµè®¾è®¡ | 51-150 |
| ç¬¬3ç«  | æ ¸å¿ƒæœåŠ¡æ¨¡å—è¯¦è§£ | 151-350 |
| ç¬¬4ç«  | LLMé›†æˆä¸Promptå·¥ç¨‹ | 351-500 |
| ç¬¬5ç«  | æ¶ˆæ¯é˜Ÿåˆ—é›†æˆ | 501-600 |
| ç¬¬6ç«  | æ•°æ®æ¨¡å‹ä¸éªŒè¯ | 601-700 |
| ç¬¬7ç«  | é”™è¯¯å¤„ç†ä¸ç›‘æ§ | 701-800 |
| ç¬¬8ç«  | éƒ¨ç½²ä¸é…ç½®ç®¡ç† | 801-900 |

---

## ç¬¬1ç«  æ•´ä½“æ¶æ„ä¸æŠ€æœ¯æ ˆ

### 1.1 æœåŠ¡å®šä½

TeamVenture Python AIæœåŠ¡æ˜¯æ•´ä¸ªç³»ç»Ÿçš„**æ™ºèƒ½æ ¸å¿ƒ**ï¼Œè´Ÿè´£ï¼š
1. **æ–¹æ¡ˆæ™ºèƒ½ç”Ÿæˆ**ï¼šåŸºäºç”¨æˆ·éœ€æ±‚ç”Ÿæˆ3å¥—å›¢å»ºæ–¹æ¡ˆï¼ˆç»æµå‹/æ ‡å‡†å‹/å“è´¨å‹ï¼‰
2. **ä¾›åº”å•†æ™ºèƒ½åŒ¹é…**ï¼šæ ¹æ®é¢„ç®—ã€åŸå¸‚ã€åå¥½åŒ¹é…åˆé€‚çš„ä¾›åº”å•†
3. **éœ€æ±‚ç†è§£ä¸è§£æ**ï¼šå°†ç»“æ„åŒ–è¾“å…¥è½¬æ¢ä¸ºAIå¯ç†è§£çš„ä¸Šä¸‹æ–‡
4. **å¼‚æ­¥ä»»åŠ¡å¤„ç†**ï¼šé€šè¿‡RabbitMQå®ç°ä¸JavaæœåŠ¡çš„è§£è€¦

**è®¾è®¡åŸåˆ™**:
- âœ… **å¯è¿è¡Œæ€§ä¼˜å…ˆ**ï¼šå³ä½¿æ²¡æœ‰OpenAI API Keyï¼Œä¹Ÿèƒ½é€šè¿‡stubæ¨¡å¼ç”Ÿæˆæ¼”ç¤ºæ–¹æ¡ˆ
- âœ… **è½»é‡çº§å®ç°**ï¼šä¸ä¾èµ–é‡å‹LangGraphæ¡†æ¶ï¼Œä½¿ç”¨ç®€æ´çš„Pythonå¼‚æ­¥æµç¨‹
- âœ… **å¿«é€Ÿå¤±è´¥**ï¼šé”™è¯¯æ˜ç¡®ä¼ é€’ï¼Œä¾¿äºè°ƒè¯•
- âœ… **å¯è§‚æµ‹æ€§**ï¼šå®Œæ•´çš„æ—¥å¿—è®°å½•ï¼Œæ”¯æŒPrometheusç›‘æ§

### 1.2 æŠ€æœ¯æ ˆ

| æŠ€æœ¯ | ç‰ˆæœ¬ | ç”¨é€” | é€‰å‹ç†ç”± |
|------|------|------|---------|
| **Python** | 3.11+ | ä¸»è¯­è¨€ | å¼‚æ­¥æ”¯æŒã€AIç”Ÿæ€å®Œå–„ |
| **FastAPI** | 0.109+ | Webæ¡†æ¶ | é«˜æ€§èƒ½ã€è‡ªåŠ¨æ–‡æ¡£ã€å¼‚æ­¥åŸç”Ÿ |
| **OpenAI SDK** | 1.x | LLMè°ƒç”¨ | å®˜æ–¹SDKã€ç¨³å®šå¯é  |
| **pydantic** | 2.x | æ•°æ®éªŒè¯ | ç±»å‹å®‰å…¨ã€è¿è¡Œæ—¶éªŒè¯ |
| **aio-pika** | 9.x | RabbitMQå®¢æˆ·ç«¯ | å¼‚æ­¥AMQPå®¢æˆ·ç«¯ |
| **httpx** | 0.27+ | HTTPå®¢æˆ·ç«¯ | å¼‚æ­¥HTTPè¯·æ±‚ï¼ˆè°ƒç”¨JavaæœåŠ¡ï¼‰ |
| **python-dotenv** | 1.0+ | é…ç½®ç®¡ç† | ç¯å¢ƒå˜é‡åŠ è½½ |
| **uvicorn** | 0.27+ | ASGIæœåŠ¡å™¨ | ç”Ÿäº§çº§ASGIæœåŠ¡å™¨ |

**ä¸ä½¿ç”¨çš„æŠ€æœ¯**ï¼ˆåˆ»æ„å†³ç­–ï¼‰:
- âŒ **LangGraphæ¡†æ¶æœ¬èº«**ï¼šè¿‡äºé‡å‹ï¼Œç®€å•åœºæ™¯ä¸éœ€è¦
- âŒ **LangChain Agent**ï¼šå½“å‰æµç¨‹å›ºå®šï¼Œä¸éœ€è¦åŠ¨æ€è§„åˆ’
- âŒ **Celery**ï¼šå·²æœ‰RabbitMQï¼Œæ— éœ€é¢å¤–ä»»åŠ¡é˜Ÿåˆ—æ¡†æ¶

### 1.3 ç³»ç»Ÿæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Python AI Service (FastAPI)                   â”‚
â”‚                        ç«¯å£: 8000                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                           â”‚                        â–²
         â”‚                           â”‚                        â”‚
         â”‚ HTTP                      â”‚ AMQP                   â”‚ HTTP
         â”‚ /health                   â”‚ Consumer               â”‚ /internal/plans/batch
         â”‚                           â”‚                        â”‚
         â”‚                           â–¼                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  User  â”‚              â”‚  RabbitMQ    â”‚        â”‚  Java Service  â”‚
    â”‚  (Dev) â”‚              â”‚  Exchange:   â”‚        â”‚  (Callback)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  plan.gen    â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚              â”‚
                            â”‚  Queue:      â”‚
                            â”‚  ai.gen.req  â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   å†…éƒ¨æµç¨‹ï¼ˆWorkflowï¼‰                            â”‚
â”‚                                                                   â”‚
â”‚   parse_requirements  â†’  match_suppliers  â†’  generate_three_plansâ”‚
â”‚         â†“                      â†“                       â†“          â”‚
â”‚   è®¡ç®—è¡ç”Ÿå­—æ®µ            ä¾›åº”å•†åŒ¹é…              OpenAI GPT-4     â”‚
â”‚   (duration_days, etc)   (æ¼”ç¤ºæ¨¡å¼/LLMå¢å¼º)    æˆ–stub fallback   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  OpenAI API  â”‚
                          â”‚  gpt-4-turbo â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.4 æœåŠ¡å…¥å£ä¸ç”Ÿå‘½å‘¨æœŸ

**ä¸»åº”ç”¨æ–‡ä»¶**: `src/main.py`

#### 1.4.1 FastAPIåº”ç”¨åˆå§‹åŒ–

```python
from fastapi import FastAPI
from src.services.mq_consumer import MQConsumer

app = FastAPI(
    title="TeamVenture AI Service",
    version="1.0.0",
    description="LangGraph-based plan generation service",
)

# å…¨å±€MQæ¶ˆè´¹è€…å®ä¾‹
mq_consumer: MQConsumer | None = None
```

**å…³é”®ç«¯ç‚¹**:
- `GET /` - æœåŠ¡ä¿¡æ¯
- `GET /health` - å¥åº·æ£€æŸ¥ï¼ˆKubernetes liveness probeï¼‰
- `POST /trigger-generation` - æ‰‹åŠ¨è§¦å‘ç”Ÿæˆï¼ˆå¼€å‘è°ƒè¯•ç”¨ï¼‰

#### 1.4.2 ç”Ÿå‘½å‘¨æœŸç®¡ç†

```python
@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨æ—¶è¿æ¥RabbitMQå¹¶å¼€å§‹æ¶ˆè´¹"""
    global mq_consumer
    mq_consumer = MQConsumer(
        rabbitmq_url=settings.rabbitmq_url,
        queue_name="ai.generation.request",
    )
    await mq_consumer.start()
    logger.info("MQ consumer started")

@app.on_event("shutdown")
async def shutdown_event():
    """ä¼˜é›…å…³é—­MQè¿æ¥"""
    if mq_consumer:
        await mq_consumer.stop()
    logger.info("MQ consumer stopped")
```

**å¯åŠ¨æµç¨‹**:
1. FastAPIåº”ç”¨åˆå§‹åŒ–
2. åŠ è½½ç¯å¢ƒå˜é‡é…ç½®ï¼ˆ`settings`ï¼‰
3. å»ºç«‹RabbitMQè¿æ¥
4. ç»‘å®šé˜Ÿåˆ— `ai.generation.request` åˆ° exchange `plan-generation`
5. å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯ï¼ˆæ¯æ¡æ¶ˆæ¯è§¦å‘workflowï¼‰
6. Uvicornç›‘å¬8000ç«¯å£ï¼Œæä¾›HTTPå¥åº·æ£€æŸ¥

---

## ç¬¬2ç«  LangGraphå·¥ä½œæµè®¾è®¡

### 2.1 å·¥ä½œæµæ¦‚è§ˆ

TeamVentureçš„æ–¹æ¡ˆç”Ÿæˆæµç¨‹è®¾è®¡ä¸º**ä¸‰é˜¶æ®µä¸²è¡ŒPipeline**ï¼š

```
ç”¨æˆ·è¯·æ±‚ (MQæ¶ˆæ¯)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: parse_requirements                     â”‚
â”‚  - è§£æç”¨æˆ·è¾“å…¥                                   â”‚
â”‚  - è®¡ç®—è¡ç”Ÿå­—æ®µ (duration_days, budget_per_person)â”‚
â”‚  - ç»“æ„åŒ–åå¥½æ•°æ®                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ (parsed_requirements)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2: match_suppliers                        â”‚
â”‚  - åŒ¹é…ä¾›åº”å•† (å½“å‰æ¼”ç¤ºæ¨¡å¼)                      â”‚
â”‚  - æœªæ¥: LLMå¢å¼ºçš„è¯­ä¹‰åŒ¹é…                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ (matched_suppliers)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 3: generate_three_plans                   â”‚
â”‚  - è°ƒç”¨OpenAI GPT-4ç”Ÿæˆ3å¥—æ–¹æ¡ˆ                    â”‚
â”‚  - æˆ–ä½¿ç”¨stub fallback (æ— API keyæ—¶)             â”‚
â”‚  - å½’ä¸€åŒ–è¾“å‡ºæ ¼å¼                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ (generated_plans)
å›è°ƒJavaæœåŠ¡ (/internal/plans/batch)
```

**è®¾è®¡ç‰¹ç‚¹**:
1. **è½»é‡çº§å®ç°**ï¼šæ²¡æœ‰ä½¿ç”¨LangGraphæ¡†æ¶æœ¬èº«ï¼Œè€Œæ˜¯ç”¨ç®€å•çš„å¼‚æ­¥å‡½æ•°ä¸²è”
2. **çŠ¶æ€ä¼ é€’**ï¼šé€šè¿‡`GenerationState` TypedDictä¼ é€’å„é˜¶æ®µäº§ç‰©
3. **é”™è¯¯å®¹é”™**ï¼šä»»ä½•é˜¶æ®µå¼‚å¸¸éƒ½ä¼šæ•è·å¹¶è®°å½•åˆ°`state["error"]`
4. **å¯è§‚æµ‹**ï¼šæ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰æ—¥å¿—è¾“å‡º

### 2.2 çŠ¶æ€æœºå®šä¹‰

**æ–‡ä»¶**: `src/langgraph/state.py`

```python
from typing import Any, Optional, TypedDict

class GenerationState(TypedDict, total=False):
    # è¾“å…¥
    plan_request_id: str          # æ–¹æ¡ˆè¯·æ±‚IDï¼ˆæ¥è‡ªJavaï¼‰
    user_id: str                   # ç”¨æˆ·ID
    user_inputs: dict[str, Any]    # åŸå§‹MQæ¶ˆæ¯

    # Stage 1è¾“å‡º
    parsed_requirements: dict[str, Any]

    # Stage 2è¾“å‡º
    matched_suppliers: list[dict[str, Any]]

    # Stage 3è¾“å‡º
    generated_plans: list[dict[str, Any]]

    # é”™è¯¯è®°å½•
    error: Optional[str]
```

**å­—æ®µè¯´æ˜**:
- `total=False`ï¼šå…è®¸å­—æ®µé€æ­¥å¡«å……ï¼Œå„é˜¶æ®µåªå¡«å……è‡ªå·±äº§ç”Ÿçš„å­—æ®µ
- `plan_request_id`ï¼šå…¨å±€è¿½è¸ªIDï¼Œè´¯ç©¿æ•´ä¸ªæµç¨‹
- `user_inputs`ï¼šä¿ç•™åŸå§‹è¾“å…¥ï¼Œä¾¿äºé”™è¯¯å›æº¯
- `error`ï¼šä»»ä½•é˜¶æ®µå¤±è´¥éƒ½ä¼šè®¾ç½®æ­¤å­—æ®µï¼Œworkflowæå‰ç»ˆæ­¢

### 2.3 å·¥ä½œæµæ‰§è¡Œå‡½æ•°

**æ–‡ä»¶**: `src/langgraph/workflow.py`

```python
async def run_generation_workflow(message: dict[str, Any]) -> GenerationState:
    """
    Minimal workflow that matches the detailed design phases:
    parse requirements â†’ match suppliers â†’ generate plans.

    This is intentionally a lightweight implementation that can run without LLM keys.
    """
    state: GenerationState = {
        "plan_request_id": message["plan_request_id"],
        "user_id": message["user_id"],
        "user_inputs": message,
    }

    try:
        logger.info("workflow start plan_request_id=%s", state["plan_request_id"])

        # Stage 1: è§£æéœ€æ±‚
        state["parsed_requirements"] = parse_requirements(message)
        logger.info("requirements parsed plan_request_id=%s", state["plan_request_id"])

        # Stage 2: åŒ¹é…ä¾›åº”å•†
        state["matched_suppliers"] = await match_suppliers(state["parsed_requirements"])
        logger.info(
            "suppliers matched plan_request_id=%s count=%s",
            state["plan_request_id"],
            len(state.get("matched_suppliers") or []),
        )

        # Stage 3: ç”Ÿæˆæ–¹æ¡ˆ
        state["generated_plans"] = await generate_three_plans(
            plan_request_id=state["plan_request_id"],
            user_id=state["user_id"],
            inputs=state["parsed_requirements"],
            matched_suppliers=state["matched_suppliers"],
        )
        logger.info(
            "plans generated plan_request_id=%s count=%s",
            state["plan_request_id"],
            len(state.get("generated_plans") or []),
        )

        return state

    except Exception as exc:
        logger.exception("Generation workflow failed")
        state["error"] = str(exc)
        return state
```

**æ‰§è¡Œä¿è¯**:
- âœ… å³ä½¿æŸé˜¶æ®µæŠ›å¼‚å¸¸ï¼Œä¹Ÿä¼šè¿”å›`state`ï¼ˆåŒ…å«`error`å­—æ®µï¼‰
- âœ… æ‰€æœ‰é˜¶æ®µæ—¥å¿—è®°å½•ï¼Œä¾¿äºè¿½è¸ª
- âœ… æ¯ä¸ªé˜¶æ®µéƒ½æ˜¯å¼‚æ­¥å‡½æ•°ï¼ˆæ”¯æŒI/Oå¯†é›†æ“ä½œï¼‰

### 2.4 æ—¶åºå›¾

```
MQ Consumer        â”‚  Workflow         â”‚  OpenAI API    â”‚  Java Service
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚              â”‚                   â”‚                â”‚
    â”œâ”€ æ¥æ”¶æ¶ˆæ¯     â”‚                   â”‚                â”‚
    â”‚ (plan_req_id) â”‚                   â”‚                â”‚
    â”‚              â”‚                   â”‚                â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ run_workflow()   â”‚                â”‚
    â”‚              â”‚                   â”‚                â”‚
    â”‚              â”œâ”€ Stage 1:         â”‚                â”‚
    â”‚              â”‚  parse_requirements()             â”‚
    â”‚              â”‚  (åŒæ­¥è®¡ç®—)        â”‚                â”‚
    â”‚              â”‚                   â”‚                â”‚
    â”‚              â”œâ”€ Stage 2:         â”‚                â”‚
    â”‚              â”‚  match_suppliers() â”‚               â”‚
    â”‚              â”‚  (è¿”å›stub)        â”‚                â”‚
    â”‚              â”‚                   â”‚                â”‚
    â”‚              â”œâ”€ Stage 3:         â”‚                â”‚
    â”‚              â”‚  generate_plans() â”‚                â”‚
    â”‚              â”‚                   â”‚                â”‚
    â”‚              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚ Chat Completionâ”‚
    â”‚              â”‚                   â”‚  (GPT-4)       â”‚
    â”‚              â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ JSON Response  â”‚
    â”‚              â”‚                   â”‚                â”‚
    â”‚              â”œâ”€ normalize plans  â”‚                â”‚
    â”‚              â”‚                   â”‚                â”‚
    â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ return state     â”‚                â”‚
    â”‚              â”‚  (3 plans)        â”‚                â”‚
    â”‚              â”‚                   â”‚                â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
    â”‚              â”‚                   â”‚  POST /internal/â”‚
    â”‚              â”‚                   â”‚  plans/batch   â”‚
    â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚              â”‚                   â”‚  200 OK        â”‚
    â”‚              â”‚                   â”‚                â”‚
```

---

## ç¬¬3ç«  æ ¸å¿ƒæœåŠ¡æ¨¡å—è¯¦è§£

### 3.1 éœ€æ±‚è§£ææœåŠ¡ (RequirementParser)

**æ–‡ä»¶**: `src/services/requirement_parser.py`

#### 3.1.1 åŠŸèƒ½èŒè´£

å°†JavaæœåŠ¡å‘é€çš„**ç»“æ„åŒ–JSONæ¶ˆæ¯**è½¬æ¢ä¸ºAIå¯ç†è§£çš„**éœ€æ±‚ä¸Šä¸‹æ–‡**ï¼ŒåŒ…æ‹¬ï¼š
1. **è®¡ç®—è¡ç”Ÿå­—æ®µ**ï¼š
   - `duration_days`ï¼šæ ¹æ®start_dateå’Œend_dateè®¡ç®—å¤©æ•°
   - `budget_per_person_range`ï¼šæ ¹æ®æ€»é¢„ç®—å’Œäººæ•°è®¡ç®—äººå‡é¢„ç®—èŒƒå›´
2. **æ•°æ®ç±»å‹è½¬æ¢**ï¼šç¡®ä¿å­—æ®µç±»å‹æ­£ç¡®ï¼ˆint, float, strï¼‰
3. **ç¼ºå¤±å€¼å¤„ç†**ï¼šä¸ºå¯é€‰å­—æ®µæä¾›é»˜è®¤å€¼
4. **æ—¥æœŸè§£æ**ï¼šISOæ ¼å¼å­—ç¬¦ä¸² â†’ Python dateå¯¹è±¡ â†’ è®¡ç®—å·®å€¼

#### 3.1.2 å®ç°ç»†èŠ‚

```python
def parse_requirements(message: dict[str, Any]) -> dict[str, Any]:
    """
    Rule-based parsing per detailed-design: no LLM call.
    """
    # 1. æå–åŸºç¡€å­—æ®µ
    people_count = int(message["people_count"])
    budget_min = float(message["budget_min"])
    budget_max = float(message["budget_max"])

    # 2. è§£ææ—¥æœŸå¹¶è®¡ç®—å¤©æ•°
    start_date = date.fromisoformat(message["start_date"])  # "2026-02-01" â†’ date(2026, 2, 1)
    end_date = date.fromisoformat(message["end_date"])      # "2026-02-03" â†’ date(2026, 2, 3)
    duration_days = (end_date - start_date).days + 1        # 3å¤©

    # 3. è®¡ç®—äººå‡é¢„ç®—
    budget_per_person_min = budget_min / max(people_count, 1)
    budget_per_person_max = budget_max / max(people_count, 1)

    # 4. æå–åå¥½ï¼ˆå¯é€‰ï¼‰
    preferences = message.get("preferences") or {}

    # 5. è¿”å›ç»“æ„åŒ–éœ€æ±‚
    return {
        "people_count": people_count,
        "budget_min": budget_min,
        "budget_max": budget_max,
        "budget_per_person_range": [
            round(budget_per_person_min, 2),
            round(budget_per_person_max, 2)
        ],
        "start_date": start_date.isoformat(),
        "end_date": end_date.isoformat(),
        "duration_days": duration_days,
        "departure_city": message.get("departure_city", ""),
        "preferences": preferences,
    }
```

**è¾“å…¥ç¤ºä¾‹** (MQæ¶ˆæ¯):
```json
{
  "plan_request_id": "plan_req_01ke3cnw4t5dvp8jhjvfdafq1v",
  "user_id": "user_01ke3abc123",
  "people_count": 50,
  "budget_min": 10000,
  "budget_max": 15000,
  "start_date": "2026-02-01",
  "end_date": "2026-02-03",
  "departure_city": "Beijing",
  "preferences": {
    "activity_types": ["team_building"],
    "accommodation": "standard",
    "dining": ["local"]
  }
}
```

**è¾“å‡ºç¤ºä¾‹** (parsed_requirements):
```json
{
  "people_count": 50,
  "budget_min": 10000.0,
  "budget_max": 15000.0,
  "budget_per_person_range": [200.0, 300.0],
  "start_date": "2026-02-01",
  "end_date": "2026-02-03",
  "duration_days": 3,
  "departure_city": "Beijing",
  "preferences": {
    "activity_types": ["team_building"],
    "accommodation": "standard",
    "dining": ["local"]
  }
}
```

**å…³é”®è®¾è®¡ç‚¹**:
- âœ… **æ— LLMè°ƒç”¨**ï¼šçº¯è§„åˆ™è®¡ç®—ï¼Œå¿«é€Ÿä¸”ç¡®å®šæ€§å¼º
- âœ… **é˜²é™¤é›¶**ï¼š`max(people_count, 1)` é¿å…äººæ•°ä¸º0çš„è¾¹ç•Œæƒ…å†µ
- âœ… **ç²¾åº¦æ§åˆ¶**ï¼š`round(..., 2)` ç¡®ä¿é‡‘é¢ä¸º2ä½å°æ•°
- âœ… **ISOæ—¥æœŸ**ï¼šç»Ÿä¸€ä½¿ç”¨ISOæ ¼å¼å­—ç¬¦ä¸²ï¼Œä¾¿äºJSONåºåˆ—åŒ–

### 3.2 ä¾›åº”å•†åŒ¹é…æœåŠ¡ (SupplierMatcher)

**æ–‡ä»¶**: `src/services/supplier_matcher.py`

#### 3.2.1 å½“å‰å®ç°ï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰

```python
async def match_suppliers(inputs: dict[str, Any]) -> list[dict[str, Any]]:
    """
    Demo mode: return hardcoded suppliers.
    Future: semantic matching via LLM or vector DB.
    """
    # æ¼”ç¤ºä¾›åº”å•†åˆ—è¡¨
    return [
        {
            "supplier_id": "sup_hotel_001",
            "name": "åŒ—äº¬æ€€æŸ”é›æ –æ¹–å›½é™…ä¼šå±•ä¸­å¿ƒ",
            "type": "accommodation",
            "price_range": "Â¥800-1500/é—´å¤œ",
            "rating": 4.5,
            "tags": ["ä¼šè®®å®¤", "å›¢å»ºåœºåœ°", "æ¹–æ™¯", "å¤§å‹æ´»åŠ¨"],
        },
        {
            "supplier_id": "sup_activity_001",
            "name": "å¯†äº‘å¤åŒ—æ°´é•‡æˆ·å¤–æ‹“å±•åŸºåœ°",
            "type": "activity",
            "price_range": "Â¥150-300/äºº",
            "rating": 4.7,
            "tags": ["å›¢é˜Ÿåä½œ", "æˆ·å¤–æ‹“å±•", "é•¿åŸæ™¯è§‚"],
        },
        {
            "supplier_id": "sup_dining_001",
            "name": "æ€€æŸ”å†œå®¶é™¢ç‰¹è‰²é¤é¥®",
            "type": "dining",
            "price_range": "Â¥80-150/äºº",
            "rating": 4.3,
            "tags": ["å†œå®¶èœ", "æœ‰æœºé£Ÿæ", "çƒ¤å…¨ç¾Š"],
        },
    ]
```

#### 3.2.2 æœªæ¥å¢å¼ºæ–¹å‘

**æ–¹æ¡ˆA: åŸºäºMySQLæŸ¥è¯¢**
```python
async def match_suppliers_db(inputs: dict[str, Any]) -> list[dict[str, Any]]:
    """
    Query suppliers table by city and category.
    """
    city = inputs.get("departure_city")
    budget_range = inputs.get("budget_per_person_range")

    # ä¼ªä»£ç ç¤ºä¾‹
    suppliers = await db.query(
        "SELECT * FROM suppliers WHERE city = ? AND price_min <= ? AND price_max >= ? AND status = 'ACTIVE'",
        (city, budget_range[1], budget_range[0])
    )
    return suppliers
```

**æ–¹æ¡ˆB: LLMè¯­ä¹‰åŒ¹é…**
```python
async def match_suppliers_llm(inputs: dict[str, Any]) -> list[dict[str, Any]]:
    """
    Use LLM to semantically match suppliers based on preferences.
    """
    preferences = inputs.get("preferences", {})
    prompt = f"""
    Based on these preferences: {preferences},
    rank the following suppliers by relevance:
    ...
    """
    # LLMè°ƒç”¨è¿”å›æ’åºåçš„ä¾›åº”å•†IDåˆ—è¡¨
```

**æ–¹æ¡ˆC: å‘é‡æ•°æ®åº“è¯­ä¹‰æœç´¢**
- ä½¿ç”¨Embeddingå‘é‡å­˜å‚¨ä¾›åº”å•†æè¿°
- æŸ¥è¯¢æ—¶ç”Ÿæˆéœ€æ±‚Embedding
- ä½™å¼¦ç›¸ä¼¼åº¦åŒ¹é…Top Kä¾›åº”å•†

**å½“å‰çŠ¶æ€**: æ¼”ç¤ºæ¨¡å¼æ»¡è¶³ä¸€æœŸéœ€æ±‚ï¼ŒäºŒæœŸå¯æ ¹æ®å®é™…æ•°æ®é‡é€‰æ‹©æ–¹æ¡ˆA/B/C

### 3.3 æ–¹æ¡ˆç”ŸæˆæœåŠ¡ (PlanGeneration)

**æ–‡ä»¶**: `src/services/plan_generation.py`

è¿™æ˜¯AIæœåŠ¡çš„**æœ€æ ¸å¿ƒæ¨¡å—**ï¼Œè´Ÿè´£è°ƒç”¨OpenAI GPT-4ç”Ÿæˆ3å¥—æ–¹æ¡ˆã€‚

#### 3.3.1 æ•´ä½“æµç¨‹

```python
async def generate_three_plans(
    *,
    plan_request_id: str,
    user_id: str,
    inputs: dict[str, Any],
    matched_suppliers: list[dict[str, Any]],
) -> list[dict[str, Any]]:
    """
    Generate 3 plans via LLM (preferred) with deterministic fallback.
    """
    # 1. è®¡ç®—é¢„ç®—ç›®æ ‡
    targets = _budget_targets(inputs)  # {budget: min, standard: mid, premium: max}

    # 2. æ£€æŸ¥OpenAIé…ç½®
    client = OpenAIClient()
    if not client.is_configured():
        logger.warning("OPENAI_API_KEY not configured; using stub plan generation")
        return await _generate_three_plans_stub(...)  # fallbackåˆ°æ¼”ç¤ºæ–¹æ¡ˆ

    # 3. æ„å»ºPrompt
    prompt_payload = {
        "plan_request_id": plan_request_id,
        "user_id": user_id,
        "inputs": inputs,
        "matched_suppliers": matched_suppliers,
        "constraints": {
            "people_count": people,
            "duration_days": duration_days,
            "departure_city": city,
            "budget_targets_total": targets,
        },
        "output_contract": {
            "plans_length": 3,
            "plan_types": ["budget", "standard", "premium"],
        },
    }

    prompt = f"""
    Generate exactly 3 corporate team-building plans in Chinese.
    Return JSON ONLY with this shape:
    {{
      "plans": [
        {{
          "plan_type": "budget|standard|premium",
          "plan_name": "string",
          ...
        }}
      ]
    }}
    Rules:
    - budget_total must be close to constraints.budget_targets_total for each plan.
    - budget_per_person = budget_total / people_count.

    Input JSON:
    {json.dumps(prompt_payload, ensure_ascii=False)}
    """

    # 4. è°ƒç”¨OpenAI
    raw = await client.generate_json(prompt)

    # 5. å½’ä¸€åŒ–è¾“å‡º
    return _normalize_generated_plans(
        raw=raw,
        plan_request_id=plan_request_id,
        user_id=user_id,
        duration_days=duration_days,
    )
```

#### 3.3.2 é¢„ç®—ç›®æ ‡è®¡ç®—

```python
def _budget_targets(inputs: dict[str, Any]) -> dict[str, float]:
    budget_min = float(inputs["budget_min"])
    budget_max = float(inputs["budget_max"])
    return {
        "budget": budget_min,              # ç»æµå‹ï¼šæœ€ä½é¢„ç®—
        "standard": (budget_min + budget_max) / 2.0,  # æ ‡å‡†å‹ï¼šä¸­é—´å€¼
        "premium": budget_max,             # å“è´¨å‹ï¼šæœ€é«˜é¢„ç®—
    }
```

**ç¤ºä¾‹**:
- è¾“å…¥: budget_min=10000, budget_max=15000
- è¾“å‡º: {budget: 10000, standard: 12500, premium: 15000}

#### 3.3.3 Stubæ–¹æ¡ˆç”Ÿæˆï¼ˆFallbackæ¨¡å¼ï¼‰

```python
async def _generate_three_plans_stub(...) -> list[dict[str, Any]]:
    """
    Deterministic plan generation fallback.
    Keeps the Java â†’ MQ â†’ Python â†’ Java path usable without LLM credentials.
    """
    people = int(inputs["people_count"])
    duration_days = int(inputs["duration_days"])
    city = inputs.get("departure_city") or "ç›®çš„åœ°"
    targets = _budget_targets(inputs)

    def make_plan(plan_type: str, budget_total: float) -> dict[str, Any]:
        plan_id = new_prefixed_id("plan")
        per_person = round(budget_total / max(people, 1), 2)

        return {
            "plan_id": plan_id,
            "plan_request_id": plan_request_id,
            "user_id": user_id,
            "plan_type": plan_type,
            "plan_name": f"{plan_type.upper()}Â·{city}{duration_days}å¤©å›¢å»º",
            "summary": f"äººå‡Â¥{per_person}ï¼Œ{duration_days}å¤©è¡Œç¨‹ï¼Œå«ä½å®¿/æ´»åŠ¨/é¤é¥®",
            "highlights": [f"äººå‡Â¥{per_person}", "å¯å¯¹æ¯”ä¸‰å¥—æ–¹æ¡ˆ", "ä¾›åº”å•†ä¿¡æ¯é€æ˜"],
            "itinerary": {
                "days": [
                    {
                        "day": 1,
                        "items": [
                            {"time_start": "09:00", "time_end": "11:00", "activity": "å‡ºå‘å‰å¾€ç›®çš„åœ°"},
                            {"time_start": "11:30", "time_end": "13:00", "activity": "åˆé¤"},
                            {"time_start": "14:00", "time_end": "17:00", "activity": "å›¢é˜Ÿæ´»åŠ¨"},
                        ],
                    }
                ]
            },
            "budget_breakdown": {
                "total": round(budget_total, 2),
                "per_person": per_person,
                "categories": [
                    {"category": "äº¤é€š", "subtotal": round(budget_total * 0.25, 2)},
                    {"category": "ä½å®¿", "subtotal": round(budget_total * 0.35, 2)},
                    {"category": "é¤é¥®", "subtotal": round(budget_total * 0.25, 2)},
                    {"category": "æ´»åŠ¨", "subtotal": round(budget_total * 0.15, 2)},
                ],
            },
            "supplier_snapshots": matched_suppliers[:],  # ä½¿ç”¨åŒ¹é…çš„ä¾›åº”å•†
            "budget_total": round(budget_total, 2),
            "budget_per_person": per_person,
            "duration_days": duration_days,
            "departure_city": city,
            "status": "draft",
        }

    # ç”Ÿæˆ3å¥—æ–¹æ¡ˆ
    plans = []
    for plan_type in ["budget", "standard", "premium"]:
        plans.append(make_plan(plan_type, targets[plan_type]))
    return plans
```

**Stubæ¨¡å¼çš„ä»·å€¼**:
- âœ… **æœ¬åœ°å¼€å‘å‹å¥½**ï¼šæ— éœ€é…ç½®OpenAI API Keyå³å¯è¿è¡Œ
- âœ… **å¿«é€ŸéªŒè¯**ï¼šç«¯åˆ°ç«¯æµç¨‹éªŒè¯ä¸ä¾èµ–å¤–éƒ¨API
- âœ… **æ•°æ®æ ¼å¼å‚è€ƒ**ï¼šStubè¾“å‡ºæ˜¯LLMè¾“å‡ºçš„æ ‡å‡†æ¨¡æ¿
- âœ… **é™çº§å…œåº•**ï¼šç”Ÿäº§ç¯å¢ƒOpenAIæ•…éšœæ—¶çš„ä¸´æ—¶é™çº§æ–¹æ¡ˆ

#### 3.3.4 æ–¹æ¡ˆå½’ä¸€åŒ–

```python
def _normalize_generated_plans(
    *,
    raw: dict[str, Any],
    plan_request_id: str,
    user_id: str,
    duration_days: int,
) -> list[dict[str, Any]]:
    plans = raw.get("plans")
    if not isinstance(plans, list) or len(plans) != 3:
        raise ValueError("LLM response must include plans: [..3 items..]")

    normalized = []
    for plan in plans:
        if not isinstance(plan, dict):
            raise ValueError("Each plan must be an object")

        normalized.append({
            "plan_id": new_prefixed_id("plan"),  # ç”Ÿæˆæ–°çš„ULID
            "plan_request_id": plan_request_id,
            "user_id": user_id,
            "plan_type": str(plan.get("plan_type", "")),
            "plan_name": str(plan.get("plan_name", "")),
            "summary": str(plan.get("summary", "")),
            "highlights": plan.get("highlights", []),
            "itinerary": plan.get("itinerary", {}),
            "budget_breakdown": plan.get("budget_breakdown", {}),
            "supplier_snapshots": plan.get("supplier_snapshots", []),
            "budget_total": float(plan.get("budget_total", 0.0) or 0.0),
            "budget_per_person": float(plan.get("budget_per_person", 0.0) or 0.0),
            "duration_days": duration_days,
            "departure_city": plan.get("departure_city"),
            "status": "draft",
        })
    return normalized
```

**å½’ä¸€åŒ–ç›®çš„**:
1. **å¼ºåˆ¶ç±»å‹è½¬æ¢**ï¼šç¡®ä¿JSONå­—æ®µç±»å‹æ­£ç¡®ï¼ˆstr, float, list, dictï¼‰
2. **ç”Ÿæˆplan_id**ï¼šä¸ºæ¯ä¸ªæ–¹æ¡ˆåˆ†é…å”¯ä¸€IDï¼ˆULIDæ ¼å¼ï¼‰
3. **è¡¥å……å…ƒæ•°æ®**ï¼šæ·»åŠ plan_request_id, user_id, duration_daysç­‰
4. **é»˜è®¤å€¼å¡«å……**ï¼šç¼ºå¤±å­—æ®µä½¿ç”¨ç©ºå€¼/é›¶å€¼
5. **éªŒè¯æ•°é‡**ï¼šå¿…é¡»æ°å¥½3ä¸ªæ–¹æ¡ˆï¼Œå¦åˆ™æŠ›å¼‚å¸¸

---

## ç¬¬4ç«  LLMé›†æˆä¸Promptå·¥ç¨‹

### 4.1 OpenAIå®¢æˆ·ç«¯å°è£…

**æ–‡ä»¶**: `src/integrations/openai_client.py`

#### 4.1.1 ç±»å®šä¹‰

```python
class OpenAIClient:
    """
    Minimal OpenAI client wrapper.

    Note: This repo may run without valid OPENAI_API_KEY in local dev; callers should
    gracefully fall back to deterministic stub generation when keys are missing.
    """

    def __init__(self) -> None:
        self._api_key = settings.openai_api_key
        self._model = settings.openai_model
        self._temperature = settings.openai_temperature
        self._max_tokens = settings.openai_max_tokens

    def is_configured(self) -> bool:
        """æ£€æŸ¥API Keyæ˜¯å¦æœ‰æ•ˆé…ç½®"""
        return bool(self._api_key and not self._api_key.startswith("sk-xxxx"))
```

**é…ç½®è¯»å–** (from `src/models/config.py`):
```python
class Settings(BaseSettings):
    openai_api_key: str = "sk-xxxx"  # å ä½å€¼ï¼Œæœªé…ç½®æ—¶è§¦å‘stubæ¨¡å¼
    openai_model: str = "gpt-4-turbo-preview"
    openai_temperature: float = 0.7
    openai_max_tokens: int = 4000

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
```

#### 4.1.2 JSONç”Ÿæˆæ–¹æ³•

```python
async def generate_json(self, prompt: str) -> dict[str, Any]:
    if not self.is_configured():
        raise RuntimeError("OPENAI_API_KEY is not configured")

    client = AsyncOpenAI(api_key=self._api_key)

    try:
        response = await client.chat.completions.create(
            model=self._model,                      # gpt-4-turbo-preview
            temperature=self._temperature,          # 0.7
            max_tokens=self._max_tokens,            # 4000
            response_format={"type": "json_object"},  # å¼ºåˆ¶è¿”å›JSON
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You are a careful assistant. "
                        "Return ONLY valid JSON that matches the user's requested shape. "
                        "Do not wrap in markdown."
                    ),
                },
                {"role": "user", "content": prompt},
            ],
        )
    except Exception:
        logger.exception("OpenAI call failed")
        raise

    # æå–å“åº”å†…å®¹
    content = (response.choices[0].message.content or "").strip()
    if not content:
        raise RuntimeError("OpenAI returned empty content")

    # è§£æJSON
    try:
        parsed = json.loads(content)
    except json.JSONDecodeError as exc:
        logger.error("OpenAI returned non-JSON content: %r", content[:500])
        raise RuntimeError("OpenAI returned invalid JSON") from exc

    if not isinstance(parsed, dict):
        raise RuntimeError("OpenAI JSON root must be an object")

    return parsed
```

**å…³é”®è®¾è®¡ç‚¹**:
- âœ… **å¼ºåˆ¶JSONæ¨¡å¼**ï¼š`response_format={"type": "json_object"}` ç¡®ä¿æ¨¡å‹è¾“å‡ºJSON
- âœ… **System Promptçº¦æŸ**ï¼šæ˜ç¡®è¦æ±‚è¿”å›çº¯JSONï¼Œä¸åŒ…å«markdownä»£ç å—
- âœ… **å¼‚å¸¸è¯¦ç»†è®°å½•**ï¼šè§£æå¤±è´¥æ—¶è®°å½•å‰500å­—ç¬¦ä¾¿äºè°ƒè¯•
- âœ… **ç±»å‹éªŒè¯**ï¼šç¡®ä¿æ ¹èŠ‚ç‚¹æ˜¯dictï¼ˆå¯¹è±¡ï¼‰ï¼Œè€Œéæ•°ç»„æˆ–å­—ç¬¦ä¸²

### 4.2 Promptå·¥ç¨‹ç­–ç•¥

#### 4.2.1 Promptç»“æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prompt ç»„æˆï¼ˆä¸‰æ®µå¼ï¼‰                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. ä»»åŠ¡æè¿° (Task Description)                 â”‚
â”‚     - Generate exactly 3 corporate team-buildingâ”‚
â”‚       plans in Chinese                          â”‚
â”‚     - Return JSON ONLY with this shape: ...     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. è¾“å‡ºçº¦æŸ (Output Constraints)               â”‚
â”‚     - ä¸¥æ ¼çš„JSON Schemaå®šä¹‰                     â”‚
â”‚     - å­—æ®µç±»å‹ã€å¿…å¡«æ€§ã€å€¼èŒƒå›´                   â”‚
â”‚     - ä¸šåŠ¡è§„åˆ™ (é¢„ç®—åŒ¹é…ã€äººå‡è®¡ç®—ç­‰)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. è¾“å…¥ä¸Šä¸‹æ–‡ (Input Context)                  â”‚
â”‚     - å®Œæ•´çš„ç”¨æˆ·éœ€æ±‚JSON                         â”‚
â”‚     - ä¾›åº”å•†åˆ—è¡¨                                 â”‚
â”‚     - é¢„ç®—ç›®æ ‡                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 4.2.2 å®Œæ•´Promptç¤ºä¾‹

```python
prompt = """
Generate exactly 3 corporate team-building plans in Chinese.
Return JSON ONLY with this shape:
{
  "plans": [
    {
      "plan_type": "budget|standard|premium",
      "plan_name": "string",
      "summary": "string",
      "highlights": ["string"],
      "itinerary": {
        "days": [
          {
            "day": 1,
            "items": [
              {
                "time_start": "HH:MM",
                "time_end": "HH:MM",
                "activity": "string"
              }
            ]
          }
        ]
      },
      "budget_breakdown": {
        "total": number,
        "per_person": number,
        "categories": [
          {
            "category": "string",
            "subtotal": number
          }
        ]
      },
      "supplier_snapshots": [
        {
          "supplier_id": "string",
          "name": "string",
          "type": "string",
          "price_range": "string"
        }
      ],
      "budget_total": number,
      "budget_per_person": number,
      "departure_city": "string"
    }
  ]
}

Rules:
- plans must match plan_types budget/standard/premium in order.
- budget_total must be close to constraints.budget_targets_total for each plan.
- budget_per_person = budget_total / people_count.
- Keep itinerary duration_days days.

Input JSON:
{
  "plan_request_id": "plan_req_01ke3cnw4t5dvp8jhjvfdafq1v",
  "user_id": "user_01ke3abc123",
  "inputs": {
    "people_count": 50,
    "budget_min": 10000.0,
    "budget_max": 15000.0,
    "duration_days": 3,
    "departure_city": "Beijing",
    "preferences": {
      "activity_types": ["team_building"],
      "accommodation": "standard",
      "dining": ["local"]
    }
  },
  "matched_suppliers": [
    {
      "supplier_id": "sup_hotel_001",
      "name": "åŒ—äº¬æ€€æŸ”é›æ –æ¹–å›½é™…ä¼šå±•ä¸­å¿ƒ",
      "type": "accommodation",
      "price_range": "Â¥800-1500/é—´å¤œ"
    },
    ...
  ],
  "constraints": {
    "people_count": 50,
    "duration_days": 3,
    "departure_city": "Beijing",
    "budget_targets_total": {
      "budget": 10000,
      "standard": 12500,
      "premium": 15000
    }
  }
}
"""
```

#### 4.2.3 Promptä¼˜åŒ–æŠ€å·§

**1. JSON Schemaçº¦æŸ**
- âœ… **æ˜ç¡®å­—æ®µç±»å‹**ï¼š`"budget_total": number` è€Œä¸æ˜¯ `"budget_total": "number"`
- âœ… **ç¤ºä¾‹å€¼è¯´æ˜**ï¼š`"HH:MM"` æ¯” `"æ—¶é—´æ ¼å¼"` æ›´æ˜ç¡®
- âœ… **æ•°ç»„ç¤ºä¾‹**ï¼š`["string"]` è¯´æ˜æ•°ç»„å…ƒç´ ç±»å‹

**2. ä¸šåŠ¡è§„åˆ™å¼ºè°ƒ**
- âœ… **é¢„ç®—çº¦æŸ**ï¼š`budget_total must be close to constraints.budget_targets_total`
- âœ… **è®¡ç®—å…¬å¼**ï¼š`budget_per_person = budget_total / people_count`
- âœ… **æ’åºè¦æ±‚**ï¼š`in order` ç¡®ä¿budget/standard/premiumé¡ºåº

**3. ä¸Šä¸‹æ–‡å®Œæ•´æ€§**
- âœ… **ä¾›åº”å•†åˆ—è¡¨**ï¼šæä¾›çœŸå®æ•°æ®è€Œé"è‡ªè¡Œæƒ³è±¡"
- âœ… **ç”¨æˆ·åå¥½**ï¼šactivity_types, accommodation, diningç­‰
- âœ… **çº¦æŸæ¡ä»¶**ï¼šduration_days, people_countç­‰

**4. è¾“å‡ºè´¨é‡æ§åˆ¶**
```python
# åœ¨System Promptä¸­å¼ºè°ƒ
"Return ONLY valid JSON that matches the user's requested shape."
"Do not wrap in markdown."

# åœ¨User Promptä¸­é‡ç”³
"Return JSON ONLY with this shape:"
```

#### 4.2.4 Promptè¿­ä»£å†å²

| ç‰ˆæœ¬ | ä¸»è¦æ”¹è¿› | æ•ˆæœ |
|------|---------|------|
| v0.1 | ç®€å•æè¿°ï¼š"ç”Ÿæˆ3ä¸ªæ–¹æ¡ˆ" | âŒ è¿”å›æ ¼å¼ä¸ç¨³å®š |
| v0.2 | æ·»åŠ JSON Schema | âš ï¸ ä»æœ‰å­—æ®µç¼ºå¤± |
| v0.3 | å¼ºåˆ¶`response_format=json_object` | âœ… æ ¼å¼ç¨³å®šï¼Œä½†é¢„ç®—ä¸å‡† |
| v0.4 | æ·»åŠ é¢„ç®—çº¦æŸè§„åˆ™ | âœ… é¢„ç®—åŒ¹é…åº¦æå‡ |
| v0.5 | å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆä¾›åº”å•†ã€åå¥½ï¼‰ | âœ… å½“å‰ç‰ˆæœ¬ï¼Œè´¨é‡ç¨³å®š |

### 4.3 LLMé…ç½®å‚æ•°

**æ¨¡å‹é€‰æ‹©**:
- **ç”Ÿäº§ç¯å¢ƒ**: `gpt-4-turbo-preview` (128kä¸Šä¸‹æ–‡ï¼ŒJSONæ¨¡å¼æ”¯æŒ)
- **æµ‹è¯•ç¯å¢ƒ**: `gpt-3.5-turbo` (æˆæœ¬ä¼˜åŒ–)
- **å¤‡é€‰æ¨¡å‹**: Claude 3 Opus (Anthropic)

**å‚æ•°è°ƒä¼˜**:
```python
temperature = 0.7  # å¹³è¡¡åˆ›æ„æ€§ä¸ç¨³å®šæ€§
max_tokens = 4000  # è¶³å¤Ÿç”Ÿæˆ3å¥—å®Œæ•´æ–¹æ¡ˆ
top_p = 1.0        # é»˜è®¤å€¼ï¼Œtemperatureå·²è¶³å¤Ÿ
presence_penalty = 0.0  # æ— éœ€æƒ©ç½šé‡å¤
frequency_penalty = 0.0 # æ— éœ€æƒ©ç½šé¢‘ç‡
```

**æˆæœ¬ä¼°ç®—** (ä»¥gpt-4-turboä¸ºä¾‹):
- è¾“å…¥Token: çº¦1500 tokens (prompt + ä¸Šä¸‹æ–‡)
- è¾“å‡ºToken: çº¦2000 tokens (3å¥—æ–¹æ¡ˆJSON)
- å•æ¬¡è°ƒç”¨æˆæœ¬: $0.01 * 1.5 + $0.03 * 2 = $0.075
- æ—¥è¯·æ±‚é‡1000æ¬¡: $75/å¤©

### 4.4 é™çº§ç­–ç•¥

```python
# 1. ä¼˜å…ˆçº§é™çº§é“¾
try:
    # Level 1: GPT-4 Turbo (æœ€ä½³è´¨é‡)
    plans = await generate_with_gpt4(...)
except OpenAIError:
    try:
        # Level 2: GPT-3.5 Turbo (é™çº§)
        plans = await generate_with_gpt35(...)
    except OpenAIError:
        # Level 3: Stubæ–¹æ¡ˆ (ä¿åº•)
        plans = await generate_stub(...)

# 2. è¶…æ—¶æ§åˆ¶
async with timeout(30):  # 30ç§’è¶…æ—¶
    plans = await client.generate_json(prompt)
```

**é™çº§è§¦å‘æ¡ä»¶**:
- OpenAI APIå“åº”è¶…æ—¶ï¼ˆ>30sï¼‰
- APIè¿”å›5xxé”™è¯¯
- API Keyé…é¢è€—å°½
- APIè¿”å›éJSONå†…å®¹ï¼ˆè§£æå¤±è´¥ï¼‰

---

## ç¬¬5ç«  æ¶ˆæ¯é˜Ÿåˆ—é›†æˆ

### 5.1 RabbitMQæ¶æ„

```
Java Service                    Python AI Service
     â”‚                                 â”‚
     â”‚  1. å‘å¸ƒæ¶ˆæ¯                     â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚
     â”‚  Exchange: plan-generation      â”‚
     â”‚  Routing Key: plan.request      â”‚
     â”‚  Payload: {plan_request_id, ...}â”‚
     â”‚                                 â”‚
     â”‚                                 â”‚  2. æ¶ˆè´¹æ¶ˆæ¯
     â”‚                                 â”‚  Queue: ai.generation.request
     â”‚                                 â”‚
     â”‚                                 â”œâ”€> run_workflow()
     â”‚                                 â”‚
     â”‚                                 â”‚  3. ç”Ÿæˆæ–¹æ¡ˆ
     â”‚                                 â”‚  (3 plans)
     â”‚                                 â”‚
     â”‚  4. å›è°ƒå†™å…¥                     â”‚
     â”‚ <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
     â”‚  POST /internal/plans/batch     â”‚
     â”‚  Body: [{plan_id, ...}, ...]    â”‚
     â”‚                                 â”‚
     â”‚  5. æ›´æ–°PlanRequestçŠ¶æ€         â”‚
     â”‚  status: COMPLETED              â”‚
```

### 5.2 MQæ¶ˆè´¹è€…å®ç°

**æ–‡ä»¶**: `src/services/mq_consumer.py`

#### 5.2.1 æ¶ˆè´¹è€…ç±»å®šä¹‰

```python
class MQConsumer:
    def __init__(self, rabbitmq_url: str, queue_name: str):
        self.rabbitmq_url = rabbitmq_url
        self.queue_name = queue_name
        self.connection: AbstractRobustConnection | None = None
        self.channel: AbstractRobustChannel | None = None

    async def start(self):
        """å»ºç«‹è¿æ¥å¹¶å¼€å§‹æ¶ˆè´¹"""
        self.connection = await aio_pika.connect_robust(self.rabbitmq_url)
        self.channel = await self.connection.channel()

        # è®¾ç½®QoSï¼šä¸€æ¬¡åªé¢„å–1æ¡æ¶ˆæ¯ï¼ˆé¿å…å†…å­˜å ç”¨è¿‡é«˜ï¼‰
        await self.channel.set_qos(prefetch_count=1)

        # å£°æ˜é˜Ÿåˆ—ï¼ˆå¹‚ç­‰æ“ä½œï¼‰
        queue = await self.channel.declare_queue(
            self.queue_name,
            durable=True,  # æŒä¹…åŒ–é˜Ÿåˆ—
        )

        # å¼€å§‹æ¶ˆè´¹
        await queue.consume(self._on_message, no_ack=False)
        logger.info("MQ consumer listening on queue=%s", self.queue_name)

    async def stop(self):
        """ä¼˜é›…å…³é—­è¿æ¥"""
        if self.channel:
            await self.channel.close()
        if self.connection:
            await self.connection.close()
        logger.info("MQ consumer stopped")
```

#### 5.2.2 æ¶ˆæ¯å¤„ç†å‡½æ•°

```python
async def _on_message(self, message: AbstractIncomingMessage):
    """
    å¤„ç†å•æ¡MQæ¶ˆæ¯ï¼š
    1. è§£æJSON
    2. è¿è¡Œworkflow
    3. å›è°ƒJavaæœåŠ¡
    4. ACKæ¶ˆæ¯
    """
    async with message.process():  # è‡ªåŠ¨ACK/NACK
        try:
            # 1. è§£ææ¶ˆæ¯ä½“
            body = message.body.decode("utf-8")
            payload = json.loads(body)
            logger.info("Received message plan_request_id=%s", payload.get("plan_request_id"))

            # 2. è¿è¡Œç”Ÿæˆæµç¨‹
            state = await run_generation_workflow(payload)

            # 3. æ£€æŸ¥é”™è¯¯
            if state.get("error"):
                logger.error("Workflow failed: %s", state["error"])
                # TODO: é€šçŸ¥JavaæœåŠ¡ç”Ÿæˆå¤±è´¥
                return

            # 4. å›è°ƒJavaæœåŠ¡
            plans = state.get("generated_plans", [])
            await self._callback_java_service(
                plan_request_id=payload["plan_request_id"],
                plans=plans,
            )

            logger.info("Plan generation completed plan_request_id=%s", payload["plan_request_id"])

        except Exception as exc:
            logger.exception("Message processing failed")
            # æ¶ˆæ¯ä¼šè‡ªåŠ¨NACKå¹¶é‡æ–°å…¥é˜Ÿ
```

#### 5.2.3 JavaæœåŠ¡å›è°ƒ

```python
async def _callback_java_service(self, plan_request_id: str, plans: list[dict]):
    """
    è°ƒç”¨Javaçš„/internal/plans/batchæ¥å£æ‰¹é‡å†™å…¥æ–¹æ¡ˆ
    """
    java_url = settings.java_service_url + "/internal/plans/batch"

    payload = {
        "plan_request_id": plan_request_id,
        "plans": plans,
    }

    headers = {
        "Content-Type": "application/json",
        "X-Internal-Secret": settings.internal_secret,  # å†…éƒ¨æ¥å£å¯†é’¥
    }

    async with httpx.AsyncClient() as client:
        try:
            response = await client.post(
                java_url,
                json=payload,
                headers=headers,
                timeout=30.0,
            )
            response.raise_for_status()
            logger.info("Java callback succeeded plan_request_id=%s", plan_request_id)

        except httpx.HTTPError as exc:
            logger.error("Java callback failed: %s", exc)
            raise
```

### 5.3 æ¶ˆæ¯æ ¼å¼

**å‘å¸ƒæ¶ˆæ¯** (Java â†’ RabbitMQ):
```json
{
  "plan_request_id": "plan_req_01ke3cnw4t5dvp8jhjvfdafq1v",
  "user_id": "user_01ke3abc123",
  "people_count": 50,
  "budget_min": 10000,
  "budget_max": 15000,
  "start_date": "2026-02-01",
  "end_date": "2026-02-03",
  "departure_city": "Beijing",
  "preferences": {
    "activity_types": ["team_building"],
    "accommodation": "standard",
    "dining": ["local"]
  },
  "trace_id": "trace_01ke3xyz"
}
```

**å›è°ƒæ¶ˆæ¯** (Python â†’ Java):
```json
{
  "plan_request_id": "plan_req_01ke3cnw4t5dvp8jhjvfdafq1v",
  "plans": [
    {
      "plan_id": "plan_01ke3d123",
      "plan_type": "budget",
      "plan_name": "BUDGETÂ·Beijing3å¤©å›¢å»º",
      "summary": "äººå‡Â¥200ï¼Œ3å¤©è¡Œç¨‹ï¼Œå«ä½å®¿/æ´»åŠ¨/é¤é¥®",
      "highlights": ["äººå‡Â¥200", "å¯å¯¹æ¯”ä¸‰å¥—æ–¹æ¡ˆ"],
      "itinerary": {...},
      "budget_breakdown": {...},
      "supplier_snapshots": [...],
      "budget_total": 10000.0,
      "budget_per_person": 200.0,
      "duration_days": 3,
      "status": "draft"
    },
    {/* standard plan */},
    {/* premium plan */}
  ]
}
```

### 5.4 é”™è¯¯å¤„ç†ä¸é‡è¯•

**æ¶ˆæ¯ACKç­–ç•¥**:
```python
async with message.process():
    # æˆåŠŸå¤„ç† â†’ è‡ªåŠ¨ACK
    # æŠ›å¼‚å¸¸ â†’ è‡ªåŠ¨NACK + requeue
```

**é‡è¯•é…ç½®** (RabbitMQå±‚é¢):
```yaml
# é˜Ÿåˆ—å£°æ˜æ—¶é…ç½®
x-message-ttl: 1800000  # æ¶ˆæ¯TTL 30åˆ†é’Ÿ
x-max-length: 1000      # é˜Ÿåˆ—æœ€å¤§é•¿åº¦
x-dead-letter-exchange: dlx.plan-generation  # æ­»ä¿¡äº¤æ¢æœº
x-max-delivery-count: 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
```

**å¹‚ç­‰æ€§ä¿è¯**:
- JavaæœåŠ¡çš„`/internal/plans/batch`æ¥å£æ˜¯**å¹‚ç­‰**çš„
- ä½¿ç”¨`plan_request_id`ä½œä¸ºå¹‚ç­‰é”®
- é‡å¤è°ƒç”¨ä¼šè¦†ç›–æ—§æ–¹æ¡ˆï¼ˆè€Œéæ’å…¥é‡å¤è®°å½•ï¼‰

---

## ç¬¬6ç«  æ•°æ®æ¨¡å‹ä¸éªŒè¯

### 6.1 é…ç½®æ¨¡å‹

**æ–‡ä»¶**: `src/models/config.py`

```python
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # OpenAIé…ç½®
    openai_api_key: str = "sk-xxxx"
    openai_model: str = "gpt-4-turbo-preview"
    openai_temperature: float = 0.7
    openai_max_tokens: int = 4000

    # RabbitMQé…ç½®
    rabbitmq_url: str = "amqp://guest:guest@localhost:5672/"

    # JavaæœåŠ¡é…ç½®
    java_service_url: str = "http://java-business-service:8080/api/v1"
    internal_secret: str = "change-this-in-production"

    # æœåŠ¡é…ç½®
    log_level: str = "INFO"
    environment: str = "local"

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

settings = Settings()
```

**.envæ–‡ä»¶ç¤ºä¾‹**:
```bash
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxx
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=4000

RABBITMQ_URL=amqp://teamventure:teamventure123@rabbitmq:5672/
JAVA_SERVICE_URL=http://java-business-service:8080/api/v1
INTERNAL_SECRET=super-secret-key-change-in-production

LOG_LEVEL=INFO
ENVIRONMENT=production
```

### 6.2 IDç”Ÿæˆå™¨

**æ–‡ä»¶**: `src/services/id_generator.py`

```python
import ulid

def new_prefixed_id(prefix: str) -> str:
    """
    ç”Ÿæˆå‰ç¼€+ULIDæ ¼å¼çš„åˆ†å¸ƒå¼ID

    ç¤ºä¾‹: "plan_01HZC8K9DXF6B8M9S5Z7Q2W0E3"
    """
    ulid_str = ulid.new().str
    return f"{prefix}_{ulid_str}"
```

**ULIDä¼˜åŠ¿**:
- âœ… æ—¶é—´æ’åºæ€§ï¼šæŒ‰ç”Ÿæˆæ—¶é—´è‡ªç„¶æ’åº
- âœ… åˆ†å¸ƒå¼å®‰å…¨ï¼šæ— éœ€ä¸­å¿ƒåŒ–IDç”Ÿæˆå™¨
- âœ… å¯è¯»æ€§ï¼šBase32ç¼–ç ï¼ŒURLå‹å¥½
- âœ… å”¯ä¸€æ€§ï¼š128ä½ç†µï¼Œç¢°æ’æ¦‚ç‡æä½

### 6.3 è¾“å…¥éªŒè¯

è™½ç„¶å½“å‰å®ç°æ²¡æœ‰ä½¿ç”¨Pydanticè¯·æ±‚æ¨¡å‹ï¼ˆç›´æ¥å¤„ç†dictï¼‰ï¼Œä½†æ¨èçš„æœ€ä½³å®è·µï¼š

```python
from pydantic import BaseModel, Field, validator

class PlanGenerationRequest(BaseModel):
    plan_request_id: str = Field(..., min_length=26, max_length=64)
    user_id: str = Field(..., min_length=26, max_length=64)
    people_count: int = Field(..., ge=1, le=500)
    budget_min: float = Field(..., gt=0)
    budget_max: float = Field(..., gt=0)
    start_date: str = Field(..., regex=r"^\d{4}-\d{2}-\d{2}$")
    end_date: str = Field(..., regex=r"^\d{4}-\d{2}-\d{2}$")
    departure_city: str = Field(..., min_length=1, max_length=50)
    preferences: dict = Field(default_factory=dict)

    @validator("budget_max")
    def budget_max_must_be_gte_min(cls, v, values):
        if "budget_min" in values and v < values["budget_min"]:
            raise ValueError("budget_max must be >= budget_min")
        return v

    @validator("end_date")
    def end_date_must_be_after_start(cls, v, values):
        if "start_date" in values and v <= values["start_date"]:
            raise ValueError("end_date must be after start_date")
        return v
```

---

## ç¬¬7ç«  é”™è¯¯å¤„ç†ä¸ç›‘æ§

### 7.1 æ—¥å¿—è®°å½•

**æ—¥å¿—é…ç½®**:
```python
import logging

logging.basicConfig(
    level=settings.log_level,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[
        logging.StreamHandler(),  # è¾“å‡ºåˆ°stdoutï¼ˆDockeræ—¥å¿—æ”¶é›†ï¼‰
    ],
)

logger = logging.getLogger(__name__)
```

**å…³é”®æ—¥å¿—ç‚¹**:
```python
# 1. Workflowå¼€å§‹
logger.info("workflow start plan_request_id=%s", state["plan_request_id"])

# 2. å„é˜¶æ®µå®Œæˆ
logger.info("requirements parsed plan_request_id=%s", state["plan_request_id"])
logger.info("suppliers matched plan_request_id=%s count=%s", state["plan_request_id"], len(suppliers))
logger.info("plans generated plan_request_id=%s count=%s", state["plan_request_id"], len(plans))

# 3. é”™è¯¯è®°å½•
logger.exception("Generation workflow failed")  # è‡ªåŠ¨åŒ…å«å †æ ˆè¿½è¸ª

# 4. OpenAIè°ƒç”¨
logger.error("OpenAI returned non-JSON content: %r", content[:500])
```

### 7.2 Prometheusç›‘æ§

**æš´éœ²metricsç«¯ç‚¹** (FastAPI):
```python
from prometheus_client import Counter, Histogram, generate_latest

# å®šä¹‰æŒ‡æ ‡
workflow_runs_total = Counter("workflow_runs_total", "Total workflow runs", ["status"])
workflow_duration_seconds = Histogram("workflow_duration_seconds", "Workflow duration")
openai_calls_total = Counter("openai_calls_total", "Total OpenAI calls", ["status"])

@app.get("/metrics")
async def metrics():
    return Response(generate_latest(), media_type="text/plain")
```

**è®°å½•æŒ‡æ ‡**:
```python
with workflow_duration_seconds.time():
    state = await run_generation_workflow(payload)

if state.get("error"):
    workflow_runs_total.labels(status="failed").inc()
else:
    workflow_runs_total.labels(status="success").inc()
```

### 7.3 é”™è¯¯åˆ†ç±»

| é”™è¯¯ç±»å‹ | å¤„ç†ç­–ç•¥ | é‡è¯• | å‘Šè­¦ |
|---------|---------|------|------|
| **ç½‘ç»œé”™è¯¯** (OpenAIè¶…æ—¶) | fallbackåˆ°stub | âœ… | âš ï¸ P2 |
| **APIå¯†é’¥é”™è¯¯** | fallbackåˆ°stub | âŒ | ğŸ”´ P0 |
| **JSONè§£æå¤±è´¥** | æŠ›å¼‚å¸¸ï¼ŒNACKæ¶ˆæ¯ | âœ… | âš ï¸ P2 |
| **é¢„ç®—è®¡ç®—é”™è¯¯** | æŠ›å¼‚å¸¸ï¼ŒNACKæ¶ˆæ¯ | âœ… | ğŸ”´ P1 |
| **Javaå›è°ƒå¤±è´¥** | æŠ›å¼‚å¸¸ï¼ŒNACKæ¶ˆæ¯ | âœ… | ğŸ”´ P0 |

---

## ç¬¬8ç«  éƒ¨ç½²ä¸é…ç½®ç®¡ç†

### 8.1 Dockeréƒ¨ç½²

**Dockerfile**:
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶ä»£ç 
COPY src/ ./src/

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**docker-composeé…ç½®**:
```yaml
services:
  python-ai-service:
    build: ./backend/python-ai-service
    container_name: teamventure-python
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - RABBITMQ_URL=amqp://teamventure:teamventure123@rabbitmq:5672/
      - JAVA_SERVICE_URL=http://java-business-service:8080/api/v1
    depends_on:
      rabbitmq:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 3
```

### 8.2 é…ç½®ç®¡ç†æœ€ä½³å®è·µ

**ç¯å¢ƒåˆ†ç¦»**:
```bash
# æœ¬åœ°å¼€å‘
.env.local

# æµ‹è¯•ç¯å¢ƒ
.env.test

# ç”Ÿäº§ç¯å¢ƒ
.env.production (ä¸å…¥åº“ï¼Œé€šè¿‡K8s ConfigMap/Secretæ³¨å…¥)
```

**æ•æ„Ÿä¿¡æ¯ç®¡ç†**:
- âœ… **ä½¿ç”¨ç¯å¢ƒå˜é‡**ï¼šä¸å°†API Keyç¡¬ç¼–ç 
- âœ… **Kubernetes Secret**ï¼šç”Ÿäº§ç¯å¢ƒé€šè¿‡SecretæŒ‚è½½
- âœ… **AWS Secrets Manager**ï¼šäº‘ç¯å¢ƒæ¨èæ–¹æ¡ˆ

### 8.3 æ€§èƒ½ä¼˜åŒ–

**å¹¶å‘é…ç½®**:
```bash
# Uvicornå¤šworker
uvicorn src.main:app --host 0.0.0.0 --port 8000 --workers 4

# Gunicorn + Uvicorn worker
gunicorn src.main:app -w 4 -k uvicorn.workers.UvicornWorker
```

**èµ„æºé™åˆ¶** (Kubernetes):
```yaml
resources:
  requests:
    memory: "512Mi"
    cpu: "500m"
  limits:
    memory: "1Gi"
    cpu: "1000m"
```

---

## é™„å½•A: å®Œæ•´æ–‡ä»¶æ¸…å•

```
src/
â”œâ”€â”€ main.py                        # FastAPIåº”ç”¨å…¥å£
â”œâ”€â”€ langgraph/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ workflow.py                # å·¥ä½œæµæ‰§è¡Œå‡½æ•°
â”‚   â””â”€â”€ state.py                   # çŠ¶æ€å®šä¹‰
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ requirement_parser.py      # éœ€æ±‚è§£æ
â”‚   â”œâ”€â”€ supplier_matcher.py        # ä¾›åº”å•†åŒ¹é…
â”‚   â”œâ”€â”€ plan_generation.py         # æ–¹æ¡ˆç”Ÿæˆï¼ˆæ ¸å¿ƒï¼‰
â”‚   â”œâ”€â”€ mq_consumer.py             # RabbitMQæ¶ˆè´¹è€…
â”‚   â””â”€â”€ id_generator.py            # IDç”Ÿæˆå™¨
â”œâ”€â”€ integrations/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ openai_client.py           # OpenAIå®¢æˆ·ç«¯
â”‚   â””â”€â”€ java_client.py             # JavaæœåŠ¡å›è°ƒ
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py                  # é…ç½®æ¨¡å‹
â””â”€â”€ __init__.py

requirements.txt                   # Pythonä¾èµ–
Dockerfile                         # Dockeræ„å»ºæ–‡ä»¶
.env.example                       # ç¯å¢ƒå˜é‡ç¤ºä¾‹
```

---

## é™„å½•B: APIæ¥å£æ–‡æ¡£

### B.1 å¥åº·æ£€æŸ¥

```
GET /health
```

**å“åº”**:
```json
{
  "status": "UP",
  "version": "1.0.0"
}
```

### B.2 æ‰‹åŠ¨è§¦å‘ç”Ÿæˆï¼ˆå¼€å‘è°ƒè¯•ï¼‰

```
POST /trigger-generation
Content-Type: application/json

{
  "plan_request_id": "plan_req_test_001",
  "user_id": "user_test_001",
  "people_count": 50,
  "budget_min": 10000,
  "budget_max": 15000,
  "start_date": "2026-02-01",
  "end_date": "2026-02-03",
  "departure_city": "Beijing"
}
```

**å“åº”**:
```json
{
  "status": "success",
  "plans_count": 3
}
```

---

## é™„å½•C: æ•…éšœæ’æŸ¥æŒ‡å—

### C.1 å¸¸è§é—®é¢˜

**é—®é¢˜1: OpenAIè°ƒç”¨å¤±è´¥**
```
OpenAI call failed: APIConnectionError
```
**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆæ˜¯å¦éœ€è¦ä»£ç†ï¼‰
- éªŒè¯API Keyæœ‰æ•ˆæ€§
- æ£€æŸ¥APIé…é¢æ˜¯å¦è€—å°½

**é—®é¢˜2: RabbitMQè¿æ¥å¤±è´¥**
```
Cannot connect to RabbitMQ
```
**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥RabbitMQæœåŠ¡çŠ¶æ€: `docker ps | grep rabbitmq`
- éªŒè¯URLé…ç½®: `RABBITMQ_URL=amqp://user:pass@host:5672/`
- æ£€æŸ¥ç½‘ç»œè¿é€šæ€§: `telnet rabbitmq 5672`

**é—®é¢˜3: Javaå›è°ƒå¤±è´¥**
```
Java callback failed: 500 Internal Server Error
```
**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥JavaæœåŠ¡æ—¥å¿—
- éªŒè¯å›è°ƒURLé…ç½®
- æ£€æŸ¥`X-Internal-Secret`å¯†é’¥æ˜¯å¦åŒ¹é…

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2026-01-04
**ç»´æŠ¤è€…**: TeamVentureå¼€å‘å›¢é˜Ÿ
