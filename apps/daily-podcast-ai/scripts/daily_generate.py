#!/usr/bin/env python3
"""
æ¯æ—¥æ’­å®¢ç”Ÿæˆè„šæœ¬
æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œä¸€é”®ç”Ÿæˆå®Œæ•´çš„æ’­å®¢éŸ³é¢‘
"""

import argparse
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from dotenv import load_dotenv
from news_sources.rss_fetcher import Article

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(project_root / ".env")


def filter_low_quality_news(articles: list) -> list:
    """
    è¿‡æ»¤ä½è´¨é‡æ–°é—»
    
    æ’é™¤ï¼šè‚¡ç¥¨å‡æŒ/å¢æŒã€STè‚¡ç¥¨ã€çº¯è´¢åŠ¡å…¬å‘Šç­‰
    ä¿ç•™ï¼šæœ‰å®è´¨å†…å®¹çš„ç§‘æŠ€æ–°é—»
    """
    # ä¸¥æ ¼æ’é™¤çš„å…³é”®è¯ï¼ˆæ ‡é¢˜åŒ…å«å³æ’é™¤ï¼‰
    exclude_keywords = [
        "å‡æŒ", "å¢æŒ", "*ST", "STå£°è¿…", "STè‚¡",
        "æ¶¨åœ", "è·Œåœ", "è¿æ¿",
        "å…¬å¸è‚¡ä»½", "è‚¡ä¸œå‡æŒ",
        "ä¸»åŠ›ä¹°", "ä¸»åŠ›èµ„é‡‘", "Aè‚¡ä¸»åŠ›"
    ]
    
    # ä¿ç•™å…³é”®è¯ï¼ˆå³ä½¿æœ‰å…¶ä»–å…³é”®è¯ä¹Ÿä¿ç•™ï¼‰
    keep_keywords = [
        "AI", "äººå·¥æ™ºèƒ½", "å¤§æ¨¡å‹", "GPT", "Claude",
        "è‹¹æœ", "Apple", "åº“å…‹", "Cook",
        "ç‰¹æ–¯æ‹‰", "Tesla", "é©¬æ–¯å…‹",
        "åä¸º", "å°ç±³", "å‰åˆ©",
        "å«æ˜Ÿ", "èˆªå¤©", "èŠ¯ç‰‡",
        "å‘å¸ƒ", "æ¨å‡º", "å‡çº§"
    ]
    
    filtered = []
    for article in articles:
        title = article.title if hasattr(article, 'title') else ""
        summary = article.summary if hasattr(article, 'summary') else ""
        content = title + summary
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¿ç•™å…³é”®è¯
        has_keep_keyword = any(kw in content for kw in keep_keywords)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ’é™¤å…³é”®è¯
        has_exclude_keyword = any(kw in title for kw in exclude_keywords)
        
        # å¦‚æœæœ‰ä¿ç•™å…³é”®è¯ï¼Œä¼˜å…ˆä¿ç•™ï¼›å¦åˆ™æ’é™¤ä½è´¨é‡
        if has_keep_keyword or not has_exclude_keyword:
            filtered.append(article)
    
    removed = len(articles) - len(filtered)
    if removed > 0:
        print(f"  ğŸ—‘ï¸ ç§»é™¤ {removed} ç¯‡ä½è´¨é‡æ–°é—»")
    
    return filtered


def load_articles_from_cache(date_str: str) -> list:
    """
    ä»ç¼“å­˜åŠ è½½æ–°é—»

    Args:
        date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)

    Returns:
        Article å¯¹è±¡åˆ—è¡¨
    """
    import json

    cache_path = project_root / "cache" / f"{date_str}-news.json"

    if not cache_path.exists():
        print(f"  âš ï¸ ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {cache_path}")
        return []

    with open(cache_path, "r", encoding="utf-8") as f:
        news_list = json.load(f)

    # è½¬æ¢ä¸º Article å¯¹è±¡
    articles = []
    for news in news_list:
        article = Article(
            title=news["title"],
            summary=news["summary"],
            link=news["link"],
            source=news["source"],
            category=news["category"],
            published=datetime.fromisoformat(news["published"]) if news.get("published") else None
        )
        articles.append(article)

    print(f"  ğŸ“‚ ä»ç¼“å­˜åŠ è½½ {len(articles)} ç¯‡æ–°é—»")
    return articles


def main():
    """ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description="æ¯æ—¥æ’­å®¢ç”Ÿæˆå™¨ - å°†æ–°é—»è‡ªåŠ¨è½¬æ¢ä¸ºæ’­å®¢éŸ³é¢‘",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # ç”Ÿæˆä»Šæ—¥æ’­å®¢ï¼ˆä½¿ç”¨AIæ‘˜è¦ï¼‰
  python daily_generate.py

  # ç”ŸæˆæŒ‡å®šæ—¥æœŸçš„æ’­å®¢
  python daily_generate.py --date 2026-01-07

  # é™åˆ¶æ–‡ç« æ•°é‡
  python daily_generate.py --max-articles 5

  # ä»…ç”Ÿæˆè„šæœ¬ï¼ˆä¸åˆæˆéŸ³é¢‘ï¼‰
  python daily_generate.py --script-only

  # ä½¿ç”¨ç®€å•æ‘˜è¦ï¼ˆä¸è°ƒç”¨OpenAIï¼‰
  python daily_generate.py --no-ai

  # æŒ‡å®šè¾“å‡ºç›®å½•
  python daily_generate.py --output ./my-podcasts
        """
    )

    parser.add_argument(
        "--date", "-d",
        type=str,
        default=None,
        help="æ’­å®¢æ—¥æœŸ (æ ¼å¼: YYYY-MM-DDï¼Œé»˜è®¤ä¸ºä»Šå¤©)"
    )

    parser.add_argument(
        "--max-articles", "-n",
        type=int,
        default=10,
        help="æœ€å¤§æ–‡ç« æ•°é‡ (é»˜è®¤: 10)"
    )

    parser.add_argument(
        "--output", "-o",
        type=str,
        default="output",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: output)"
    )

    parser.add_argument(
        "--script-only",
        action="store_true",
        help="ä»…ç”Ÿæˆè„šæœ¬ï¼Œä¸åˆæˆéŸ³é¢‘"
    )

    parser.add_argument(
        "--no-ai",
        action="store_true",
        help="ä½¿ç”¨ç®€å•æ‘˜è¦ï¼Œä¸è°ƒç”¨ OpenAI API"
    )

    parser.add_argument(
        "--no-tts",
        action="store_true",
        help="è·³è¿‡ TTS è¯­éŸ³åˆæˆï¼ˆéœ€è¦å·²æœ‰éŸ³é¢‘æ–‡ä»¶ï¼‰"
    )

    parser.add_argument(
        "--bgm",
        type=str,
        default=None,
        help="èƒŒæ™¯éŸ³ä¹æ–‡ä»¶è·¯å¾„"
    )

    parser.add_argument(
        "--intro-jingle",
        type=str,
        default=None,
        help="ç‰‡å¤´éŸ³æ•ˆæ–‡ä»¶è·¯å¾„"
    )

    parser.add_argument(
        "--outro-jingle",
        type=str,
        default=None,
        help="ç‰‡å°¾éŸ³æ•ˆæ–‡ä»¶è·¯å¾„"
    )

    parser.add_argument(
        "--group-by-category",
        action="store_true",
        help="æŒ‰åˆ†ç±»ç»„ç»‡æ–°é—»"
    )

    parser.add_argument(
        "--voice-id",
        type=str,
        default=None,
        help="ElevenLabs è¯­éŸ³ IDï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰"
    )

    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†è¾“å‡º"
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="æ¼”ç¤ºæ¨¡å¼ï¼Œä¸å®é™…ç”Ÿæˆæ–‡ä»¶"
    )

    parser.add_argument(
        "--from-cache",
        action="store_true",
        help="ä»ç¼“å­˜è¯»å–æ–°é—»å¹¶ä½¿ç”¨ AI ä¼˜é€‰ï¼ˆæ¯å°æ—¶æ”¶é›†æ¨¡å¼ï¼‰"
    )

    parser.add_argument(
        "--classic",
        action="store_true",
        help="ä½¿ç”¨ç»å…¸å•äººæ’­æŠ¥æ¨¡å¼ (ç¦ç”¨ Deep Dive åŒäººå¯¹è¯)"
    )

    args = parser.parse_args()

    # è§£ææ—¥æœŸ
    if args.date:
        try:
            target_date = datetime.strptime(args.date, "%Y-%m-%d")
        except ValueError:
            print(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯: {args.date}ï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
            sys.exit(1)
    else:
        target_date = datetime.now()

    date_str = target_date.strftime("%Y-%m-%d")

    # æ‰“å°æ¨ªå¹…
    print_banner(date_str)

    if args.dry_run:
        print("ğŸ” æ¼”ç¤ºæ¨¡å¼ - ä¸ä¼šç”Ÿæˆå®é™…æ–‡ä»¶")
        print("-" * 50)

    # è¿è¡Œç”Ÿæˆæµç¨‹
    try:
        result = generate_podcast(
            target_date=target_date,
            max_articles=args.max_articles,
            output_dir=args.output,
            script_only=args.script_only,
            use_ai=not args.no_ai,
            skip_tts=args.no_tts,
            bgm_path=args.bgm,
            intro_jingle_path=args.intro_jingle,
            outro_jingle_path=args.outro_jingle,
            group_by_category=args.group_by_category,
            voice_id=args.voice_id,
            verbose=args.verbose,
            dry_run=args.dry_run,
            from_cache=args.from_cache,
            deep_dive=not args.classic
        )

        if result:
            print_summary(result)
            sys.exit(0)
        else:
            print("\nâŒ æ’­å®¢ç”Ÿæˆå¤±è´¥")
            sys.exit(1)

    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


def print_banner(date_str: str):
    """æ‰“å°æ¨ªå¹…"""
    print()
    print("=" * 50)
    print("ğŸ™ï¸  æ¯æ—¥æ’­å®¢ç”Ÿæˆå™¨")
    print("=" * 50)
    print(f"ğŸ“… æ—¥æœŸ: {date_str}")
    print()


def print_summary(result: dict):
    """æ‰“å°ç”Ÿæˆæ‘˜è¦"""
    print()
    print("=" * 50)
    print("ğŸ‰ æ’­å®¢ç”Ÿæˆå®Œæˆ!")
    print("=" * 50)

    if result.get("script_path"):
        print(f"ğŸ“ è„šæœ¬æ–‡ä»¶: {result['script_path']}")

    if result.get("audio_path"):
        print(f"ğŸ§ éŸ³é¢‘æ–‡ä»¶: {result['audio_path']}")

    if result.get("duration"):
        minutes = result["duration"] / 60
        print(f"â±ï¸  æ—¶é•¿: {result['duration']:.1f} ç§’ ({minutes:.1f} åˆ†é’Ÿ)")

    if result.get("article_count"):
        print(f"ğŸ“° æ–‡ç« æ•°: {result['article_count']}")

    if result.get("categories"):
        print(f"ğŸ“‚ åˆ†ç±»: {', '.join(result['categories'])}")

    print()


def generate_podcast(
    target_date: datetime,
    max_articles: int = 10,
    output_dir: str = "output",
    script_only: bool = False,
    use_ai: bool = True,
    skip_tts: bool = False,
    bgm_path: str = None,
    intro_jingle_path: str = None,
    outro_jingle_path: str = None,
    group_by_category: bool = False,
    voice_id: str = None,
    verbose: bool = False,
    dry_run: bool = False,
    from_cache: bool = False,
    deep_dive: bool = True
) -> dict:
    """
    ç”Ÿæˆæ’­å®¢çš„ä¸»æµç¨‹

    Args:
        target_date: ç›®æ ‡æ—¥æœŸ
        max_articles: æœ€å¤§æ–‡ç« æ•°
        output_dir: è¾“å‡ºç›®å½•
        script_only: ä»…ç”Ÿæˆè„šæœ¬
        use_ai: ä½¿ç”¨AIæ‘˜è¦
        skip_tts: è·³è¿‡TTS
        bgm_path: èƒŒæ™¯éŸ³ä¹è·¯å¾„
        intro_jingle_path: ç‰‡å¤´éŸ³æ•ˆè·¯å¾„
        outro_jingle_path: ç‰‡å°¾éŸ³æ•ˆè·¯å¾„
        group_by_category: æŒ‰åˆ†ç±»åˆ†ç»„
        voice_id: è¯­éŸ³ID
        verbose: è¯¦ç»†è¾“å‡º
        dry_run: æ¼”ç¤ºæ¨¡å¼
        deep_dive: æ˜¯å¦ä½¿ç”¨æ·±åº¦å¯¹è¯æ¨¡å¼ (Deep Dive)

    Returns:
        ç»“æœå­—å…¸
    """
    from news_sources import RSSFetcher
    from processors.summarizer import ArticleSummarizer, SimpleSummarizer
    from processors.script_writer import ScriptWriter
    from processors.dialogue_writer import DialogueWriter
    from generators import TTSGenerator, AudioMixer
    import yaml

    date_str = target_date.strftime("%Y-%m-%d")
    
    # åŠ è½½é…ç½®ä»¥è·å–ä¸»æŒäººåç§°
    config_path = project_root / "config" / "voice.yaml"
    host_a_slug = "host_a"
    host_b_slug = "host_b"
    
    if config_path.exists():
        with open(config_path, "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
            hosts = config.get("hosts", {})
            
            # ç®€å•çš„ä¸­æ–‡åè½¬æ‹¼éŸ³æ˜ å°„ (é’ˆå¯¹ç‰¹å®šéœ€æ±‚)
            name_map = {
                "æ¤èŒ": "zhimeng",
                "å°é›…": "xiaoya",
                "Alex": "alex",
                "Jamie": "jamie"
            }
            
            h_a = hosts.get("host_a", {}).get("name", "HostA")
            h_b = hosts.get("host_b", {}).get("name", "HostB")
            
            host_a_slug = name_map.get(h_a, h_a.lower())
            host_b_slug = name_map.get(h_b, h_b.lower())

    # æ„å»ºæ–°çš„è¾“å‡ºè·¯å¾„ç»“æ„: output/{date}/dailytechnews/
    base_output_path = Path(output_dir)
    if deep_dive:
        output_path = base_output_path / date_str / "dailytechnews"
    else:
        output_path = base_output_path
        
    output_path.mkdir(parents=True, exist_ok=True)

    result = {
        "date": date_str,
        "script_path": None,
        "audio_path": None,
        "duration": None,
        "article_count": 0,
        "categories": []
    }

    # ========== æ­¥éª¤ 1: è·å–æ–°é—» ==========
    print("ğŸ“° æ­¥éª¤ 1/5: è·å–æ–°é—»")
    print("-" * 40)

    if from_cache:
        # ä»ç¼“å­˜è¯»å–å…¨å¤©æ”¶é›†çš„æ–°é—»
        articles = load_articles_from_cache(date_str)
        if not articles:
            print("âš ï¸ ç¼“å­˜ä¸ºç©ºï¼Œå›é€€åˆ°å®æ—¶è·å–")
            from_cache = False  # å›é€€

    if not from_cache:
        # å®æ—¶è·å–æ–°é—»
        fetcher = RSSFetcher()
        raw_articles = fetcher.fetch_all()

        if not raw_articles:
            print("âŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ–‡ç« ")
            return None

        articles = raw_articles

    print(f"ğŸ“Š å€™é€‰æ–°é—»: {len(articles)} ç¯‡")

    # è¿‡æ»¤ä½è´¨é‡æ–°é—»
    articles = filter_low_quality_news(articles)
    print(f"ğŸ“Š è¿‡æ»¤å: {len(articles)} ç¯‡")

    # ä½¿ç”¨ AI ä¼˜é€‰
    if from_cache and len(articles) > max_articles:
        print(f"ğŸ¤– æ­¥éª¤ 1.5: AI ä¼˜é€‰æ–°é—» (ä» {len(articles)} ç¯‡ä¸­é€‰å‡º {max_articles} ç¯‡)")
        print("-" * 40)
        from processors.news_ranker import NewsRanker
        ranker = NewsRanker()
        articles = ranker.rank_articles(articles, max_count=max_articles)
    else:
        # ç®€å•æˆªå–
        articles = articles[:max_articles]

    print(f"âœ… æœ€ç»ˆé€‰å®š {len(articles)} ç¯‡æ–‡ç« ")

    if dry_run:
        for i, article in enumerate(articles, 1):
            print(f"   {i}. [{article.category}] {article.title[:40]}...")
        result["article_count"] = len(articles)
        result["categories"] = list(set(a.category for a in articles))
        return result

    # ========== æ­¥éª¤ 2: å†…å®¹æ‘˜è¦ ==========
    print("\nğŸ“ æ­¥éª¤ 2/5: å†…å®¹å¤„ç†")
    print("-" * 40)

    if use_ai:
        try:
            summarizer = ArticleSummarizer()
            print("  ä½¿ç”¨ AI æ‘˜è¦ (OpenAI GPT-4o-mini)")
        except ValueError as e:
            print(f"  âš ï¸ {e}")
            print("  é™çº§ä½¿ç”¨ç®€å•æ‘˜è¦")
            summarizer = SimpleSummarizer()
    else:
        summarizer = SimpleSummarizer()
        print("  ä½¿ç”¨ç®€å•æ‘˜è¦")

    summarized = summarizer.summarize_batch(articles, show_progress=verbose)
    print(f"âœ… å¤„ç†å®Œæˆ {len(summarized)} ç¯‡æ–‡ç« ")

    # ========== æ­¥éª¤ 3: ç”Ÿæˆè„šæœ¬ ==========
    print(f"\nğŸ“œ æ­¥éª¤ 3/5: ç”Ÿæˆè„šæœ¬ ({'Deep Dive å¯¹è¯æ¨¡å¼' if deep_dive else 'å•äººæ’­æŠ¥æ¨¡å¼'})")
    print("-" * 40)

    if deep_dive:
        # ä¼˜å…ˆä½¿ç”¨ Claude å¯¹è¯ç”Ÿæˆå™¨
        try:
            from processors.claude_dialogue_writer import ClaudeDialogueWriter
            writer = ClaudeDialogueWriter()
            print("  ğŸ¤– ä½¿ç”¨ Anthropic Claude ç”Ÿæˆé«˜è´¨é‡å¯¹è¯")
        except (ImportError, ValueError) as e:
            print(f"  âš ï¸ Claude ä¸å¯ç”¨ ({e})ï¼Œå›é€€åˆ° Gemini")
            writer = DialogueWriter()
        
        script = writer.generate_dialogue(summarized, date=target_date)
        result["article_count"] = len(summarized)
    else:
        writer = ScriptWriter()
        script = writer.generate_script(
            summarized,
            date=target_date,
            group_by_category=group_by_category
        )
        result["article_count"] = script.total_articles
        result["categories"] = script.categories

    # ä¿å­˜è„šæœ¬
    script_path = script.save_to_file(str(output_path))
    result["script_path"] = script_path
    
    print(f"âœ… è„šæœ¬å·²ä¿å­˜: {script_path}")

    if script_only:
        print("\nâ­ï¸ è·³è¿‡éŸ³é¢‘ç”Ÿæˆï¼ˆ--script-only æ¨¡å¼ï¼‰")
        return result

    # ========== æ­¥éª¤ 4: è¯­éŸ³åˆæˆ ==========
    print("\nğŸ™ï¸ æ­¥éª¤ 4/5: è¯­éŸ³åˆæˆ")
    print("-" * 40)

    audio_dir = output_path / "audio"
    audio_segments = []

    if skip_tts:
        print("  â­ï¸ è·³è¿‡ TTSï¼ˆ--no-tts æ¨¡å¼ï¼‰")
        # å°è¯•æŸ¥æ‰¾å·²å­˜åœ¨çš„éŸ³é¢‘æ–‡ä»¶
        existing_files = list(audio_dir.glob(f"{date_str}_*.mp3"))
        if existing_files:
            print(f"  ğŸ“‚ æ‰¾åˆ° {len(existing_files)} ä¸ªå·²å­˜åœ¨çš„éŸ³é¢‘æ–‡ä»¶")
            # åˆ›å»ºæ¨¡æ‹Ÿçš„ AudioSegment å¯¹è±¡
            from dataclasses import dataclass

            @dataclass
            class MockSegment:
                filepath: str

            audio_segments = [MockSegment(filepath=str(f)) for f in sorted(existing_files)]
        else:
            print("  âš ï¸ æ²¡æœ‰æ‰¾åˆ°å·²å­˜åœ¨çš„éŸ³é¢‘æ–‡ä»¶ï¼Œæ— æ³•ç»§ç»­")
            return result
    else:
        try:
            tts = TTSGenerator()
            
            if deep_dive:
                # Deep Dive åŒäººå¯¹è¯æ¨¡å¼
                audio_segments = tts.generate_dialogue_audio(
                    script,
                    output_dir=str(audio_dir),
                    show_progress=True
                )
            else:
                # å•äººæ’­æŠ¥æ¨¡å¼
                if voice_id:
                    tts.voice_id = voice_id

                if not tts.voice_id:
                    print("  âŒ æœªé…ç½® voice_idï¼Œè¯·å…ˆè¿è¡Œ setup_voice.py è®¾ç½®è¯­éŸ³")
                    print("     æˆ–ä½¿ç”¨ --voice-id å‚æ•°æŒ‡å®š")
                    return result

                print(f"  ğŸ¤ ä½¿ç”¨è¯­éŸ³ ID: {tts.voice_id[:16]}...")
                audio_segments = tts.generate_podcast_audio(
                    script,
                    output_dir=str(audio_dir),
                    show_progress=True
                )

            if not audio_segments:
                print("  âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥")
                return result

            print(f"âœ… ç”Ÿæˆ {len(audio_segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µ")

        except ValueError as e:
            print(f"  âŒ TTS åˆå§‹åŒ–å¤±è´¥: {e}")
            return result

    # ========== æ­¥éª¤ 5: éŸ³é¢‘åå¤„ç† ==========
    print("\nğŸ§ æ­¥éª¤ 5/5: éŸ³é¢‘åå¤„ç†")
    print("-" * 40)

    mixer = AudioMixer()
    
    # æ„é€ æ–‡ä»¶å: podcast-{date}-{host_a}-{host_b}.mp3
    if deep_dive:
        filename = f"podcast-{date_str}-{host_a_slug}-{host_b_slug}.mp3"
    else:
        filename = f"podcast-{date_str}.mp3"
        
    final_audio_path = str(output_path / filename)

    final = mixer.create_final_podcast(
        audio_segments,
        final_audio_path,
        bgm_path=bgm_path,
        intro_jingle_path=intro_jingle_path,
        outro_jingle_path=outro_jingle_path,
        show_progress=True
    )

    if final:
        result["audio_path"] = final.filepath
        result["duration"] = final.duration_seconds
        print(f"âœ… æ’­å®¢éŸ³é¢‘ç”Ÿæˆå®Œæˆ: {final.filepath}")
    else:
        print("  âŒ éŸ³é¢‘åå¤„ç†å¤±è´¥")

    # ========== æ­¥éª¤ 6: å°é¢ç”Ÿæˆ ==========
    print("\nğŸ¨ æ­¥éª¤ 6/6: å°é¢ç”Ÿæˆ")
    print("-" * 40)
    
    try:
        # ä½¿ç”¨ PIL ç”Ÿæˆå°é¢ï¼ˆæ›´ç¨³å®šï¼Œæ— éœ€å¤–éƒ¨ APIï¼‰
        from generate_cover import generate_cover as pil_generate_cover
        
        cover_filename = f"cover-{date_str}.png"
        cover_path = str(output_path / cover_filename)
        
        podcast_title = "ä»Šæ—¥ç§‘æŠ€æ—©æŠ¥"
        if deep_dive:
            podcast_title += " Deep Dive"
            
        generated_cover = pil_generate_cover(
            date=target_date,
            output_path=cover_path,
            title=podcast_title,
            article_count=len(summarized)
        )
        
        if generated_cover:
            print(f"âœ… å°é¢ç”Ÿæˆå®Œæˆ: {generated_cover}")
            result["cover_path"] = generated_cover
        else:
            print("âŒ å°é¢ç”Ÿæˆå¤±è´¥")
            
    except Exception as e:
        print(f"âŒ å°é¢ç”Ÿæˆå‡ºé”™: {e}")
        if verbose:
            import traceback
            traceback.print_exc()

    return result


if __name__ == "__main__":
    main()
