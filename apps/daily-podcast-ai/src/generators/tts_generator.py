"""
TTS è¯­éŸ³åˆæˆæ¨¡å—
ä½¿ç”¨ ElevenLabs API å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³
"""

import os
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Optional

import yaml
from elevenlabs import ElevenLabs, VoiceSettings


@dataclass
class AudioSegment:
    """éŸ³é¢‘ç‰‡æ®µ"""
    filepath: str
    duration_seconds: float
    text: str
    segment_index: int


class TTSGenerator:
    """ElevenLabs TTS è¯­éŸ³ç”Ÿæˆå™¨"""

    def __init__(self, config_path: str = "config/voice.yaml"):
        """
        åˆå§‹åŒ– TTS ç”Ÿæˆå™¨

        Args:
            config_path: è¯­éŸ³é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.tts_config = self.config.get("tts", {})

        # åˆå§‹åŒ– ElevenLabs å®¢æˆ·ç«¯
        api_key = os.getenv("ELEVENLABS_API_KEY")
        if not api_key:
            raise ValueError("æœªè®¾ç½® ELEVENLABS_API_KEY ç¯å¢ƒå˜é‡")

        self.client = ElevenLabs(api_key=api_key)

        # è·å–é…ç½®
        self.voice_id = self.tts_config.get("voice_id", "")
        self.model_id = self.tts_config.get("model", "eleven_multilingual_v2")
        self.output_format = self.tts_config.get("output_format", "mp3_44100_128")

    def _load_config(self, config_path: str) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        path = Path(config_path)
        if not path.exists():
            project_root = Path(__file__).parent.parent.parent
            path = project_root / config_path

        if not path.exists():
            return self._default_config()

        with open(path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)

    def _default_config(self) -> dict:
        """é»˜è®¤é…ç½®"""
        return {
            "tts": {
                "model": "eleven_multilingual_v2",
                "output_format": "mp3_44100_128",
                "voice_settings": {
                    "stability": 0.5,
                    "similarity_boost": 0.75,
                    "style": 0.0,
                    "use_speaker_boost": True
                }
            }
        }

    def _get_voice_settings(self, speed: Optional[float] = None) -> VoiceSettings:
        """è·å–è¯­éŸ³è®¾ç½®"""
        settings = self.tts_config.get("voice_settings", {})
        # è·å–è¯­é€Ÿè®¾ç½®ï¼ˆèŒƒå›´ 0.7-1.2ï¼‰
        speech_speed = speed or self.tts_config.get("speed", 1.0)
        speech_speed = max(0.7, min(1.2, speech_speed))  # é™åˆ¶èŒƒå›´
        
        return VoiceSettings(
            stability=settings.get("stability", 0.5),
            similarity_boost=settings.get("similarity_boost", 0.75),
            style=settings.get("style", 0.0),
            use_speaker_boost=settings.get("use_speaker_boost", True),
            speed=speech_speed
        )

    def list_voices(self) -> list[dict]:
        """
        åˆ—å‡ºå¯ç”¨çš„è¯­éŸ³

        Returns:
            è¯­éŸ³åˆ—è¡¨
        """
        try:
            response = self.client.voices.get_all()
            voices = []
            for voice in response.voices:
                voices.append({
                    "voice_id": voice.voice_id,
                    "name": voice.name,
                    "category": voice.category,
                    "labels": voice.labels
                })
            return voices
        except Exception as e:
            print(f"âŒ è·å–è¯­éŸ³åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def get_voice_info(self, voice_id: str) -> Optional[dict]:
        """
        è·å–æŒ‡å®šè¯­éŸ³çš„è¯¦ç»†ä¿¡æ¯

        Args:
            voice_id: è¯­éŸ³ ID

        Returns:
            è¯­éŸ³ä¿¡æ¯å­—å…¸
        """
        try:
            voice = self.client.voices.get(voice_id)
            return {
                "voice_id": voice.voice_id,
                "name": voice.name,
                "category": voice.category,
                "labels": voice.labels,
                "description": voice.description
            }
        except Exception as e:
            print(f"âŒ è·å–è¯­éŸ³ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def generate_audio(
        self,
        text: str,
        output_path: str,
        voice_id: Optional[str] = None,
        speed: Optional[float] = None
    ) -> Optional[str]:
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºéŸ³é¢‘

        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            voice_id: è¯­éŸ³ IDï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„ï¼‰
            speed: è¯­é€Ÿï¼ˆ0.7-1.2ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„ï¼‰

        Returns:
            ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        voice_id = voice_id or self.voice_id
        if not voice_id:
            print("âŒ æœªæŒ‡å®š voice_id")
            return None

        try:
            # è°ƒç”¨ ElevenLabs APIï¼ˆè¯­é€Ÿé€šè¿‡ VoiceSettings ä¼ é€’ï¼‰
            audio = self.client.text_to_speech.convert(
                voice_id=voice_id,
                text=text,
                model_id=self.model_id,
                output_format=self.output_format,
                voice_settings=self._get_voice_settings(speed)
            )

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            output_file = Path(output_path)
            output_file.parent.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜éŸ³é¢‘
            with open(output_file, "wb") as f:
                for chunk in audio:
                    f.write(chunk)

            return str(output_file)

        except Exception as e:
            print(f"âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            return None

    def generate_podcast_audio(
        self,
        script,
        output_dir: str = "output/audio",
        show_progress: bool = True
    ) -> list[AudioSegment]:
        """
        ä¸ºæ•´ä¸ªæ’­å®¢è„šæœ¬ç”ŸæˆéŸ³é¢‘

        Args:
            script: PodcastScript å¯¹è±¡
            output_dir: è¾“å‡ºç›®å½•
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦

        Returns:
            AudioSegment åˆ—è¡¨
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        segments = []

        # æ”¶é›†æ‰€æœ‰éœ€è¦è½¬æ¢çš„æ–‡æœ¬
        texts = []

        # å¼€åœºç™½
        texts.append(("intro", script.intro))

        # æ–°é—»ç‰‡æ®µ
        for i, segment in enumerate(script.segments):
            texts.append((f"segment_{i}", segment["text"]))
            if segment.get("transition"):
                texts.append((f"transition_{i}", segment["transition"]))

        # ç»“æŸè¯­
        texts.append(("outro", script.outro))

        if show_progress:
            print(f"\nğŸ™ï¸ å¼€å§‹ç”ŸæˆéŸ³é¢‘ï¼Œå…± {len(texts)} ä¸ªç‰‡æ®µ")
            print("-" * 40)

        rate_limit_delay = self.tts_config.get("rate_limit_delay", 1.0)

        for i, (name, text) in enumerate(texts):
            if show_progress:
                print(f"  [{i + 1}/{len(texts)}] ç”Ÿæˆ: {name}...")

            filename = f"{script.date}_{name}.mp3"
            filepath = output_path / filename

            result = self.generate_audio(text, str(filepath))

            if result:
                # è·å–éŸ³é¢‘æ—¶é•¿ï¼ˆç®€å•ä¼°ç®—ï¼Œå®é™…å¯ç”¨ pydub è®¡ç®—ï¼‰
                # ä¸­æ–‡è¯­é€Ÿçº¦ 3-4 å­—/ç§’
                estimated_duration = len(text) / 3.5

                segments.append(AudioSegment(
                    filepath=result,
                    duration_seconds=estimated_duration,
                    text=text,
                    segment_index=i
                ))

                if show_progress:
                    print(f"    âœ… å®Œæˆ")
            else:
                if show_progress:
                    print(f"    âŒ å¤±è´¥")

            # é€Ÿç‡é™åˆ¶
            if i < len(texts) - 1:
                time.sleep(rate_limit_delay)

        if show_progress:
            print("-" * 40)
            print(f"âœ… éŸ³é¢‘ç”Ÿæˆå®Œæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ")

        return segments

    def generate_dialogue_audio(
        self,
        dialogue_script,  # DialogueScript object
        output_dir: str = "output/dialogue_audio",
        show_progress: bool = True
    ) -> list[AudioSegment]:
        """
        ç”ŸæˆåŒäººå¯¹è¯éŸ³é¢‘
        
        Args:
            dialogue_script: DialogueScript å¯¹è±¡ (æ¥è‡ª dialogue_writer.py)
            output_dir: è¾“å‡ºç›®å½•
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            AudioSegment åˆ—è¡¨
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        segments = []
        
        # è·å–ä¸»æŒäººé…ç½®
        host_config = self.config.get("hosts", {})
        voice_map = {
            "Host A": host_config.get("host_a", {}).get("voice_id", self.voice_id),
            "Host B": host_config.get("host_b", {}).get("voice_id", "")
        }
        
        # å¦‚æœæ²¡æœ‰é…ç½® Host Bï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨ä¸­çš„å¤‡é€‰æˆ– fallback
        if not voice_map["Host B"]:
            print("âš ï¸ æœªé…ç½® Host B å£°éŸ³ IDï¼Œå°è¯•ä½¿ç”¨é»˜è®¤å¤‡é€‰ 'Adam'...")
            voice_map["Host B"] = "pNInz6obpgDQGcFmaJgB" # Default Adam
            
        rate_limit_delay = self.tts_config.get("rate_limit_delay", 0.5)
        
        if show_progress:
            print(f"\nğŸ™ï¸ å¼€å§‹ç”ŸæˆåŒäººå¯¹è¯éŸ³é¢‘ï¼Œå…± {len(dialogue_script.lines)} å¥å¯¹è¯")
            print(f"   Host A Voice: {voice_map['Host A']}")
            print(f"   Host B Voice: {voice_map['Host B']}")
            print("-" * 40)
            
        for i, line in enumerate(dialogue_script.lines):
            speaker = line.speaker
            text = line.text
            voice_id = voice_map.get(speaker, voice_map["Host A"])
            
            # ç®€å•çš„è¡¨æƒ…å¤„ç† (å¯ä»¥é€šè¿‡ stability è°ƒæ•´ï¼Œæš‚æœªæ·±åº¦å®ç°)
            # emotion = line.emotion 
            
            filename = f"{dialogue_script.date}_line_{i:03d}_{speaker.replace(' ', '')}.mp3"
            filepath = output_path / filename
            
            if show_progress:
                speaker_icon = "ğŸ—£ï¸" if speaker == "Host A" else "ğŸ¤–"
                print(f"  [{i+1}/{len(dialogue_script.lines)}] {speaker_icon} {speaker}: {text[:20]}...")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ (é¿å…é‡å¤ç”ŸæˆèŠ‚çœ Credit)
            if filepath.exists():
                if show_progress:
                    print("    â© è·³è¿‡ (å·²å­˜åœ¨)")
                segments.append(AudioSegment(
                    filepath=str(filepath),
                    duration_seconds=0, # éœ€é‡æ–°è®¡ç®—ï¼Œæˆ–è¯»å–æ–‡ä»¶å…ƒæ•°æ®
                    text=text,
                    segment_index=i
                ))
                continue

            result = self.generate_audio(text, str(filepath), voice_id=voice_id)
            
            if result:
                segments.append(AudioSegment(
                    filepath=result,
                    duration_seconds=len(text)/3.5, # ä¼°ç®—
                    text=text,
                    segment_index=i
                ))
            else:
                print(f"    âŒ ç”Ÿæˆå¤±è´¥")
                
            time.sleep(rate_limit_delay)
            
        return segments


def main():
    """æµ‹è¯•å…¥å£"""
    from dotenv import load_dotenv
    load_dotenv()

    print("ğŸ™ï¸ TTS Generator æµ‹è¯•")
    print("=" * 50)

    generator = TTSGenerator()

    # åˆ—å‡ºå¯ç”¨è¯­éŸ³
    print("\nğŸ“‹ å¯ç”¨è¯­éŸ³åˆ—è¡¨:")
    voices = generator.list_voices()
    for voice in voices[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"  - {voice['name']} ({voice['voice_id'][:8]}...)")

    # æµ‹è¯•ç”Ÿæˆ
    if generator.voice_id:
        print(f"\nğŸ¤ ä½¿ç”¨è¯­éŸ³ ID: {generator.voice_id}")

        test_text = "å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ä»Šæ—¥ç§‘æŠ€æ—©æŠ¥ã€‚ä»Šå¤©æˆ‘ä»¬ä¸ºå¤§å®¶å¸¦æ¥æœ€æ–°çš„ç§‘æŠ€èµ„è®¯ã€‚"
        output_path = "output/test_audio.mp3"

        print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {test_text}")
        print(f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}")

        result = generator.generate_audio(test_text, output_path)

        if result:
            print(f"âœ… éŸ³é¢‘ç”ŸæˆæˆåŠŸ: {result}")
        else:
            print("âŒ éŸ³é¢‘ç”Ÿæˆå¤±è´¥")
    else:
        print("\nâš ï¸ æœªé…ç½® voice_idï¼Œè¯·å…ˆåœ¨ config/voice.yaml ä¸­è®¾ç½®")


if __name__ == "__main__":
    main()
