"""
å·¥å…·å‡½æ•°æ¨¡å—

æä¾›æ—¥å¿—ã€ç¼“å­˜ã€æŠ¥å‘Šç”Ÿæˆç­‰é€šç”¨åŠŸèƒ½
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Set, Dict


class Logger:
    """æ—¥å¿—å·¥å…·ç±»"""

    @staticmethod
    def setup(log_dir: str, log_file: str = None) -> logging.Logger:
        """
        è®¾ç½®æ—¥å¿—è®°å½•å™¨

        Args:
            log_dir: æ—¥å¿—ç›®å½•
            log_file: æ—¥å¿—æ–‡ä»¶åï¼ˆé»˜è®¤ä½¿ç”¨å½“å‰æ—¥æœŸï¼‰

        Returns:
            Loggerå¯¹è±¡
        """
        log_dir_path = Path(log_dir)
        log_dir_path.mkdir(parents=True, exist_ok=True)

        if log_file is None:
            today = datetime.now().strftime("%Y-%m-%d")
            log_file = f"daily-{today}.log"

        log_path = log_dir_path / log_file

        # é…ç½®æ—¥å¿—æ ¼å¼
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s [%(levelname)s] %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            handlers=[
                logging.FileHandler(log_path, encoding="utf-8"),
                logging.StreamHandler()
            ]
        )

        return logging.getLogger("GMailHelper")


class CacheManager:
    """ç¼“å­˜ç®¡ç†ç±»ï¼ˆç”¨äºå¹‚ç­‰æ€§ä¿è¯ï¼‰"""

    def __init__(self, cache_dir: str):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨

        Args:
            cache_dir: ç¼“å­˜ç›®å½•
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def load_processed_ids(self, date: str = None) -> Set[str]:
        """
        åŠ è½½ä»Šæ—¥å·²å¤„ç†çš„é‚®ä»¶ID

        Args:
            date: æ—¥æœŸï¼ˆYYYY-MM-DDï¼Œé»˜è®¤ä»Šå¤©ï¼‰

        Returns:
            å·²å¤„ç†é‚®ä»¶IDé›†åˆ
        """
        if date is None:
            date = datetime.now().strftime("%Y-%m-%d")

        cache_file = self.cache_dir / f"{date}-processed.json"

        if not cache_file.exists():
            return set()

        try:
            with open(cache_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                return set(data.get("processed_ids", []))
        except (json.JSONDecodeError, IOError):
            return set()

    def save_processed_ids(self, processed_ids: Set[str], date: str = None):
        """
        ä¿å­˜ä»Šæ—¥å·²å¤„ç†çš„é‚®ä»¶ID

        Args:
            processed_ids: å·²å¤„ç†é‚®ä»¶IDé›†åˆ
            date: æ—¥æœŸï¼ˆYYYY-MM-DDï¼Œé»˜è®¤ä»Šå¤©ï¼‰
        """
        if date is None:
            date = datetime.now().strftime("%Y-%m-%d")

        cache_file = self.cache_dir / f"{date}-processed.json"

        data = {
            "date": date,
            "processed_ids": list(processed_ids),
            "last_updated": datetime.now().isoformat()
        }

        with open(cache_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""

    @staticmethod
    def generate_markdown_report(stats: Dict, details: Dict) -> str:
        """
        ç”ŸæˆMarkdownæ ¼å¼çš„å¤„ç†æŠ¥å‘Š

        Args:
            stats: ç»Ÿè®¡æ•°æ®
            details: è¯¦ç»†ä¿¡æ¯

        Returns:
            MarkdownæŠ¥å‘Šå†…å®¹
        """
        today = datetime.now().strftime("%Y-%m-%d")
        time_now = datetime.now().strftime("%H:%M:%S")

        report = f"""# GMailHelper æ‰§è¡ŒæŠ¥å‘Š

**æ‰§è¡Œæ—¥æœŸ**: {today}
**æ‰§è¡Œæ—¶é—´**: {time_now}
**æ‰§è¡Œæ¨¡å¼**: {"æ¨¡æ‹Ÿè¿è¡Œï¼ˆDry Runï¼‰" if stats.get('dry_run') else "å®é™…æ‰§è¡Œ"}

---

## ğŸ“Š ç»Ÿè®¡æ‘˜è¦

| æŒ‡æ ‡ | æ•°é‡ | å æ¯” |
|------|------|------|
| æ€»é‚®ä»¶æ•° | {stats['total']} | 100% |
| ç™½åå•é‚®ä»¶ | {stats['whitelisted']} | {stats['whitelisted']/max(stats['total'],1)*100:.1f}% |
| åŒ¹é…è§„åˆ™ | {stats['matched']} | {stats['matched']/max(stats['total'],1)*100:.1f}% |
| AIåˆ†ç±» | {stats.get('ai_classified', 0)} | {stats.get('ai_classified', 0)/max(stats['total'],1)*100:.1f}% |
| å·²å¤„ç† | {stats['processed']} | {stats['processed']/max(stats['total'],1)*100:.1f}% |
| å¤„ç†å¤±è´¥ | {stats.get('errors', 0)} | {stats.get('errors', 0)/max(stats['total'],1)*100:.1f}% |

---

## ğŸ“‹ å¤„ç†è¯¦æƒ…

### è¥é”€é‚®ä»¶ï¼ˆ{details.get('marketing', {}).get('count', 0)}å°ï¼‰
"""

        marketing = details.get('marketing', {})
        if marketing.get('senders'):
            for sender, count in sorted(
                marketing['senders'].items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]:
                report += f"- {sender}: {count}å°\n"

        report += f"\n**æ‰§è¡ŒåŠ¨ä½œ**: {', '.join(marketing.get('actions', []))}\n\n"

        report += f"""### é€šçŸ¥é‚®ä»¶ï¼ˆ{details.get('notification', {}).get('count', 0)}å°ï¼‰
"""

        notification = details.get('notification', {})
        if notification.get('senders'):
            for sender, count in sorted(
                notification['senders'].items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]:
                report += f"- {sender}: {count}å°\n"

        report += f"\n**æ‰§è¡ŒåŠ¨ä½œ**: {', '.join(notification.get('actions', []))}\n\n"

        report += f"""### è®ºå›é‚®ä»¶ï¼ˆ{details.get('forum', {}).get('count', 0)}å°ï¼‰
"""

        forum = details.get('forum', {})
        if forum.get('senders'):
            for sender, count in sorted(
                forum['senders'].items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]:
                report += f"- {sender}: {count}å°\n"

        report += f"\n**æ‰§è¡ŒåŠ¨ä½œ**: {', '.join(forum.get('actions', []))}\n\n"

        # AIåˆ†ç±»ç»“æœ
        if stats.get('ai_classified', 0) > 0:
            report += f"""### AIåˆ†ç±»é‚®ä»¶ï¼ˆ{stats.get('ai_classified', 0)}å°ï¼‰

"""
            ai_details = details.get('ai_classification', {})
            for category, count in ai_details.items():
                report += f"- {category}: {count}å°\n"

            report += "\n"

        # æœªåŒ¹é…é‚®ä»¶
        if stats.get('unmatched', 0) > 0:
            report += f"""### æœªåŒ¹é…é‚®ä»¶ï¼ˆ{stats['unmatched']}å°ï¼‰

ä¿ç•™åœ¨æ”¶ä»¶ç®±ï¼Œå»ºè®®äººå·¥å¤„ç†

"""

        report += f"""---

## âœ… æ‰§è¡Œç»“æœ

- **æ€»å¤„ç†æ•°**: {stats['processed']} å°é‚®ä»¶
- **æˆåŠŸç‡**: {(stats['processed'] - stats.get('errors', 0)) / max(stats['processed'], 1) * 100:.1f}%
- **æ”¶ä»¶ç®±æ¸…ç†ç‡**: {stats['processed'] / max(stats['total'], 1) * 100:.1f}%

---

## ğŸ“ å»ºè®®

"""

        if stats['processed'] / max(stats['total'], 1) > 0.7:
            report += "- âœ… æ”¶ä»¶ç®±æ¸…ç†æ•ˆæœè‰¯å¥½\n"
        else:
            report += "- âš ï¸ æ¸…ç†ç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–è§„åˆ™é…ç½®\n"

        if stats.get('unmatched', 0) > 10:
            report += f"- â„¹ï¸ æœ‰ {stats['unmatched']} å°æœªåˆ†ç±»é‚®ä»¶ï¼Œå»ºè®®æ·»åŠ æ–°è§„åˆ™\n"

        if stats.get('errors', 0) > 0:
            report += f"- âš ï¸ æœ‰ {stats['errors']} ä¸ªé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—\n"

        report += "\n---\n\n*æœ¬æŠ¥å‘Šç”± GMailHelper è‡ªåŠ¨ç”Ÿæˆ*\n"

        return report

    @staticmethod
    def save_report(content: str, output_path: str):
        """
        ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶

        Args:
            content: æŠ¥å‘Šå†…å®¹
            output_path: è¾“å‡ºè·¯å¾„
        """
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, "w", encoding="utf-8") as f:
            f.write(content)
