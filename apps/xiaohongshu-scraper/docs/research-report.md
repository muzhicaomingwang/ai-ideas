# 小红书内容抓取调研报告

> 调研日期: 2026-01-05
> 目标: 输入小红书链接，输出图片/视频/文档/评论内容

---

## 一、小红书反爬机制分析

### 1.1 主要防护措施

| 防护类型 | 具体实现 | 绕过难度 |
|---------|---------|---------|
| **登录墙** | 未登录用户无法查看详情页 | 中 |
| **签名验证** | `x-s`、`x-t` 参数加密 | 高 |
| **Token 校验** | `xsec_token` 动态生成 | 高 |
| **请求频率限制** | IP/账号级别限流 | 中 |
| **设备指纹** | Canvas/WebGL 指纹检测 | 中 |
| **行为检测** | 鼠标轨迹、滑动验证 | 高 |

### 1.2 实测结果

```
测试时间: 2026-01-05 13:00
测试方式: Playwright 无头浏览器

1. 首页 /explore - ✅ 可访问，显示内容卡片列表
2. 详情页 /explore/{id} - ❌ 跳转404，提示"当前笔记暂时无法浏览"
3. 需要有效 xsec_token 才能访问详情页
```

---

## 二、技术方案对比

### 2.1 开源项目调研

| 项目 | Star | 技术栈 | 功能完整度 | 维护状态 |
|------|------|--------|-----------|---------|
| [MediaCrawler](https://github.com/NanmiCoder/MediaCrawler) | 30K+ | Python + Playwright | ⭐⭐⭐⭐⭐ | 活跃 |
| [XHS-Downloader](https://github.com/JoeanAmier/XHS-Downloader) | 10K+ | Python | ⭐⭐⭐⭐ | 活跃 |
| [Spider_XHS](https://github.com/cv-cat/Spider_XHS) | 5K+ | Python | ⭐⭐⭐⭐ | 活跃 |
| [xhscrawl](https://github.com/submato/xhscrawl) | 1K+ | Python | ⭐⭐⭐ | 中等 |

### 2.2 推荐方案: MediaCrawler

**选择理由:**
1. 社区活跃度最高（30K+ Star）
2. 多平台支持（小红书/抖音/B站/微博等）
3. 功能完整（笔记/评论/用户信息/视频下载）
4. 技术方案成熟（Playwright + 签名提取）

**核心特性:**
- ✅ 关键词搜索采集
- ✅ 指定笔记 ID 采集
- ✅ 评论数据采集（含二级评论）
- ✅ 博主主页作品采集
- ✅ 登录态缓存
- ✅ IP 代理池
- ✅ 多格式导出（CSV/JSON/Excel/SQLite/MySQL）

---

## 三、技术架构设计

### 3.1 系统架构

```
┌─────────────────────────────────────────────────────────┐
│                    用户输入层                            │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  │
│  │   CLI 命令    │  │   Web API    │  │  Claude Skill │  │
│  └──────────────┘  └──────────────┘  └──────────────┘  │
└─────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────┐
│                    核心处理层                            │
│  ┌──────────────────────────────────────────────────┐  │
│  │                 URL 解析器                        │  │
│  │  • 提取笔记 ID                                    │  │
│  │  • 识别内容类型（图文/视频）                       │  │
│  └──────────────────────────────────────────────────┘  │
│                            │                            │
│                            ▼                            │
│  ┌──────────────────────────────────────────────────┐  │
│  │              MediaCrawler 适配器                  │  │
│  │  • 登录态管理                                     │  │
│  │  • 签名参数生成                                   │  │
│  │  • 请求频率控制                                   │  │
│  └──────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────┐
│                    数据提取层                            │
│  ┌────────────┐ ┌────────────┐ ┌────────────┐          │
│  │  图片提取   │ │  视频提取   │ │  文本提取   │          │
│  │  • 无水印   │ │  • 无水印   │ │  • 标题    │          │
│  │  • 原图质量 │ │  • 最高清晰 │ │  • 正文    │          │
│  └────────────┘ └────────────┘ │  • 标签    │          │
│                                └────────────┘          │
│                                                        │
│  ┌────────────────────────────────────────────────┐   │
│  │                  评论提取                       │   │
│  │  • 一级评论  • 二级评论  • 点赞数  • 用户信息  │   │
│  └────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────┐
│                    输出层                               │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  │
│  │  JSON 格式   │  │  本地文件    │  │  数据库存储  │  │
│  └──────────────┘  └──────────────┘  └──────────────┘  │
└─────────────────────────────────────────────────────────┘
```

### 3.2 输出数据结构

```json
{
  "note_id": "6479d6470000000013008e22",
  "url": "https://www.xiaohongshu.com/explore/6479d6470000000013008e22",
  "type": "image",  // "image" | "video"
  "title": "不要怀疑你自己，你值得拥有最好的！",
  "content": "正文内容...",
  "tags": ["励志", "心灵鸡汤"],
  "author": {
    "id": "61f2bf910000000010008216",
    "name": "小青椒的客厅",
    "avatar": "https://..."
  },
  "stats": {
    "likes": 1200,
    "collects": 340,
    "comments": 89,
    "shares": 23
  },
  "media": {
    "images": [
      {
        "url": "https://...",
        "width": 1080,
        "height": 1440,
        "local_path": "./output/images/xxx.jpg"
      }
    ],
    "video": null
  },
  "comments": [
    {
      "id": "comment_001",
      "user": "用户A",
      "content": "太棒了！",
      "likes": 23,
      "time": "2023-06-01 12:00:00",
      "replies": [
        {
          "id": "reply_001",
          "user": "作者",
          "content": "谢谢支持！",
          "likes": 5,
          "time": "2023-06-01 12:30:00"
        }
      ]
    }
  ],
  "crawled_at": "2026-01-05T13:00:00Z"
}
```

---

## 四、实现方案

### 4.1 方案 A: 集成 MediaCrawler（推荐）

**优点:**
- 开箱即用，功能完整
- 社区维护，持续更新
- 文档完善

**缺点:**
- 依赖较重（需要完整 Python 环境）
- 需要处理登录态

**实现步骤:**
```bash
# 1. 克隆项目
git clone https://github.com/NanmiCoder/MediaCrawler.git

# 2. 安装依赖
cd MediaCrawler
uv sync
uv run playwright install

# 3. 配置参数
cp config/base_config.py config/local_config.py
# 编辑 local_config.py 设置 Cookie 等

# 4. 运行采集
uv run main.py --platform xhs --lt qrcode
```

### 4.2 方案 B: 集成 XHS-Downloader（轻量）

**优点:**
- 轻量级，专注小红书
- 支持 API/MCP 调用
- 支持剪贴板监听

**缺点:**
- 仅支持小红书
- 评论功能相对较弱

**实现步骤:**
```bash
# 1. 安装
pip install xhs-downloader

# 2. 运行 API 服务
xhs-downloader --server

# 3. 调用接口
curl http://localhost:8000/download?url=小红书链接
```

### 4.3 方案 C: 自研 Playwright 方案（完全可控）

**优点:**
- 完全可控
- 可定制化程度高

**缺点:**
- 开发成本高
- 需要持续维护签名算法

**不推荐**：小红书反爬更新频繁，自研维护成本过高。

---

## 五、风险与合规

### 5.1 法律风险

| 风险类型 | 说明 | 建议 |
|---------|------|------|
| **数据隐私** | 用户生成内容受隐私保护 | 仅用于个人学习研究 |
| **版权问题** | 图片/视频可能有版权 | 不用于商业用途 |
| **服务条款** | 违反小红书用户协议 | 控制请求频率 |
| **反不正当竞争** | 大规模采集可能构成侵权 | 避免批量商业化 |

### 5.2 技术风险

| 风险 | 影响 | 缓解措施 |
|------|------|---------|
| 账号封禁 | 登录态失效 | 使用备用账号、降低频率 |
| IP 封禁 | 无法访问 | 使用代理池 |
| 签名算法更新 | 采集失败 | 关注开源项目更新 |

---

## 六、推荐实施路径

### Phase 1: 快速验证（1-2 天）
1. 部署 MediaCrawler
2. 完成登录态配置
3. 测试单个链接采集

### Phase 2: 集成封装（2-3 天）
1. 编写 Python 封装脚本
2. 实现 CLI 命令行工具
3. 支持 JSON 输出

### Phase 3: Claude Code 集成（1 天）
1. 创建 Skill 配置
2. 实现链接解析 → 调用脚本 → 返回结果

---

## 七、参考资源

- [MediaCrawler](https://github.com/NanmiCoder/MediaCrawler) - 多平台爬虫框架
- [XHS-Downloader](https://github.com/JoeanAmier/XHS-Downloader) - 小红书下载工具
- [Spider_XHS](https://github.com/cv-cat/Spider_XHS) - 小红书全域运营方案
- [小红书 API 逆向分析](https://github.com/submato/xhscrawl) - x-s 签名逆向
