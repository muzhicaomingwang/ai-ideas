#!/usr/bin/env python3
"""
æ¯æ—¥å°çº¢ä¹¦ç ”ç©¶æ’­å®¢ç”Ÿæˆè„šæœ¬
æ•´åˆæ‰€æœ‰æ¨¡å—ï¼Œä¸€é”®ç”Ÿæˆå®Œæ•´çš„æ’­å®¢å†…å®¹
"""
import argparse
import json
import sys
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(project_root / ".env")

# å¯¼å…¥æ¨¡å—
from scrapers.newrank_scraper import NewrankScraper
from analyzers.topic_analyzer import TopicAnalyzer
from analyzers.trend_analyzer import TrendAnalyzer
from analyzers.insight_generator import InsightGenerator
from processors.dialogue_writer import DialogueWriter, PodcastScript
from generators.tts_generator import TTSGenerator
from generators.audio_mixer import AudioMixer
from generators.cover_generator import CoverGenerator
from generators.report_generator import ReportGenerator
from utils.logger import get_logger
from utils.cache import CacheManager

logger = get_logger()


def main():
    """ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description="æ¯æ—¥å°çº¢ä¹¦ç ”ç©¶æ’­å®¢ç”Ÿæˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # ç”Ÿæˆä»Šæ—¥æ’­å®¢ï¼ˆå®Œæ•´æµç¨‹ï¼‰
  python scripts/daily_generate.py

  # ç”ŸæˆæŒ‡å®šæ—¥æœŸ
  python scripts/daily_generate.py --date 2026-01-15

  # ä»…ç”ŸæˆæŠ¥å‘Šå’Œå°é¢ï¼ˆè·³è¿‡éŸ³é¢‘ï¼‰
  python scripts/daily_generate.py --skip-audio

  # ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼ˆè·³è¿‡æ•°æ®æŠ“å–ï¼‰
  python scripts/daily_generate.py --skip-scrape

  # æŒ‡å®šè¾“å‡ºç›®å½•
  python scripts/daily_generate.py --output ./custom-output
        """,
    )

    # å‚æ•°å®šä¹‰
    parser.add_argument(
        "--date",
        "-d",
        type=str,
        default=None,
        help="æŒ‡å®šæ—¥æœŸ (æ ¼å¼: YYYY-MM-DDï¼Œé»˜è®¤ä¸ºä»Šå¤©)",
    )

    parser.add_argument(
        "--output",
        "-o",
        type=str,
        default="output",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: output)",
    )

    parser.add_argument(
        "--skip-scrape",
        action="store_true",
        help="è·³è¿‡æ•°æ®æŠ“å–ï¼Œä½¿ç”¨ç¼“å­˜æ•°æ®",
    )

    parser.add_argument(
        "--skip-audio",
        action="store_true",
        help="è·³è¿‡éŸ³é¢‘ç”Ÿæˆï¼ˆä»…ç”ŸæˆæŠ¥å‘Šå’Œå°é¢ï¼‰",
    )

    parser.add_argument(
        "--skip-report",
        action="store_true",
        help="è·³è¿‡æŠ¥å‘Šç”Ÿæˆ",
    )

    parser.add_argument(
        "--skip-cover",
        action="store_true",
        help="è·³è¿‡å°é¢ç”Ÿæˆ",
    )

    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—",
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="æ¼”ç¤ºæ¨¡å¼ï¼ˆä¸å®é™…ç”Ÿæˆæ–‡ä»¶ï¼‰",
    )

    args = parser.parse_args()

    # è§£ææ—¥æœŸ
    if args.date:
        try:
            target_date = datetime.strptime(args.date, "%Y-%m-%d")
        except ValueError:
            print(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯: {args.date}ï¼ˆåº”ä¸º YYYY-MM-DDï¼‰")
            sys.exit(1)
    else:
        target_date = datetime.now()

    date_str = target_date.strftime("%Y-%m-%d")

    # æ‰“å°æ¨ªå¹…
    print_banner(date_str, args.dry_run)

    # è¿è¡Œç”Ÿæˆæµç¨‹
    try:
        result = generate_podcast(
            target_date=target_date,
            output_dir=args.output,
            skip_scrape=args.skip_scrape,
            skip_audio=args.skip_audio,
            skip_report=args.skip_report,
            skip_cover=args.skip_cover,
            verbose=args.verbose,
            dry_run=args.dry_run,
        )

        if result:
            print_summary(result)
            sys.exit(0)
        else:
            print("\nâŒ æ’­å®¢ç”Ÿæˆå¤±è´¥")
            sys.exit(1)

    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(130)
    except Exception as e:
        logger.exception(f"å‘ç”Ÿé”™è¯¯: {e}")
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)


def generate_podcast(
    target_date: datetime,
    output_dir: str = "output",
    skip_scrape: bool = False,
    skip_audio: bool = False,
    skip_report: bool = False,
    skip_cover: bool = False,
    verbose: bool = False,
    dry_run: bool = False,
) -> dict:
    """
    ç”Ÿæˆæ’­å®¢çš„ä¸»æµç¨‹

    Args:
        target_date: ç›®æ ‡æ—¥æœŸ
        output_dir: è¾“å‡ºç›®å½•
        skip_scrape: è·³è¿‡æ•°æ®æŠ“å–
        skip_audio: è·³è¿‡éŸ³é¢‘ç”Ÿæˆ
        skip_report: è·³è¿‡æŠ¥å‘Šç”Ÿæˆ
        skip_cover: è·³è¿‡å°é¢ç”Ÿæˆ
        verbose: è¯¦ç»†æ—¥å¿—
        dry_run: æ¼”ç¤ºæ¨¡å¼

    Returns:
        ç”Ÿæˆç»“æœå­—å…¸
    """
    date_str = target_date.strftime("%Y-%m-%d")
    output_path = Path(output_dir) / date_str
    output_path.mkdir(parents=True, exist_ok=True)

    result = {
        "date": date_str,
        "success": False,
        "outputs": {},
    }

    # æ­¥éª¤1: æ•°æ®æŠ“å–
    print("\n[æ­¥éª¤ 1/7] æ•°æ®æŠ“å–")
    print("-" * 50)

    cache_manager = CacheManager(project_root / "cache")

    if skip_scrape:
        logger.info("  è·³è¿‡æ•°æ®æŠ“å–ï¼Œä»ç¼“å­˜åŠ è½½...")
        topics = cache_manager.load_topics(date_str)

        if not topics:
            print(f"  âŒ ç¼“å­˜ä¸­æ²¡æœ‰ {date_str} çš„æ•°æ®")
            print(f"  æç¤ºï¼šç§»é™¤ --skip-scrape å‚æ•°é‡æ–°æŠ“å–")
            return None
    else:
        logger.info("  å¼€å§‹æŠ“å–æ–°æ¦œæ•°æ®...")
        if dry_run:
            print("  ğŸ” æ¼”ç¤ºæ¨¡å¼ï¼šè·³è¿‡å®é™…æŠ“å–")
            topics = []
        else:
            scraper = NewrankScraper()
            topics = scraper.fetch_hot_topics(max_count=50)

            if not topics:
                print("  âŒ æœªæŠ“å–åˆ°æ•°æ®")
                return None

            # ä¿å­˜åˆ°ç¼“å­˜
            cache_manager.save_topics(topics, date_str)

    print(f"  âœ“ è·å– {len(topics)} ä¸ªçƒ­é—¨è¯é¢˜")

    # æ­¥éª¤2: è¯é¢˜åˆ†æ
    print("\n[æ­¥éª¤ 2/7] è¯é¢˜åˆ†æ")
    print("-" * 50)

    analyzer = TopicAnalyzer()
    analysis_result = analyzer.analyze(topics, date_str)

    print(f"  âœ“ æ€»çƒ­åº¦: {analysis_result.total_heat / 10000:.1f}ä¸‡")
    print(f"  âœ“ æå–çƒ­è¯: {len(analysis_result.top_keywords)}ä¸ª")
    print(f"  âœ“ åˆ†ç±»ç»Ÿè®¡: {len(analysis_result.category_stats)}ä¸ªåˆ†ç±»")

    # æ­¥éª¤3: è¶‹åŠ¿åˆ†æ
    print("\n[æ­¥éª¤ 3/7] è¶‹åŠ¿åˆ†æ")
    print("-" * 50)

    trend_analyzer = TrendAnalyzer(cache_dir=project_root / "cache")
    trend_result = trend_analyzer.analyze_trends(topics, date_str)

    # åˆå¹¶è¶‹åŠ¿æ•°æ®åˆ°åˆ†æç»“æœ
    analysis_result.rising_topics = trend_result.get("rising", [])
    analysis_result.new_topics = trend_result.get("new", [])

    print(f"  âœ“ çƒ­åº¦ä¸Šå‡: {len(analysis_result.rising_topics)}ä¸ª")
    print(f"  âœ“ æ–°è¯é¢˜: {len(analysis_result.new_topics)}ä¸ª")

    # æ­¥éª¤4: AIæ´å¯Ÿç”Ÿæˆ
    print("\n[æ­¥éª¤ 4/7] AIæ´å¯Ÿç”Ÿæˆ")
    print("-" * 50)

    insight_generator = InsightGenerator()
    ai_insight = insight_generator.generate(analysis_result, topics)

    print(f"  âœ“ ç”¨æˆ·è¡Œä¸ºæ´å¯Ÿ: {len(ai_insight.user_behavior)}æ¡")
    print(f"  âœ“ è¶‹åŠ¿é¢„æµ‹: {len(ai_insight.trend_predictions)}æ¡")
    print(f"  âœ“ åˆ›ä½œè€…å»ºè®®: {len(ai_insight.creator_tips)}æ¡")

    # æ­¥éª¤5: ç”Ÿæˆå¯¹è¯è„šæœ¬
    print("\n[æ­¥éª¤ 5/7] ç”Ÿæˆæ’­å®¢è„šæœ¬")
    print("-" * 50)

    dialogue_writer = DialogueWriter()
    script = dialogue_writer.generate(
        analysis_result=analysis_result,
        ai_insight=ai_insight,
        target_duration=540,  # 9åˆ†é’Ÿ
    )

    # ä¿å­˜è„šæœ¬
    if not dry_run:
        json_path, md_path = script.save_to_file(output_path)
        result["outputs"]["script_json"] = str(json_path)
        result["outputs"]["script_md"] = str(md_path)
        print(f"  âœ“ è„šæœ¬å·²ä¿å­˜")
        print(f"    - JSON: {json_path.name}")
        print(f"    - Markdown: {md_path.name}")
        print(f"  âœ“ å¯¹è¯è¡Œæ•°: {len(script.lines)}")

    # æ­¥éª¤6: ç”ŸæˆéŸ³é¢‘ï¼ˆå¯é€‰ï¼‰
    if not skip_audio and not dry_run:
        print("\n[æ­¥éª¤ 6/7] ç”Ÿæˆæ’­å®¢éŸ³é¢‘")
        print("-" * 50)

        try:
            # 6.1 TTSè¯­éŸ³åˆæˆ
            print("  [6.1] è¯­éŸ³åˆæˆ...")
            tts_generator = TTSGenerator(config_path=project_root / "config/voice.yaml")

            audio_segments = tts_generator.generate_dialogue_audio(
                script=script, output_dir=output_path / "audio_segments"
            )

            print(f"    âœ“ ç”Ÿæˆ {len(audio_segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µ")

            # 6.2 éŸ³é¢‘æ··éŸ³
            print("  [6.2] éŸ³é¢‘æ··éŸ³...")
            audio_mixer = AudioMixer()

            # åˆæˆæœ€ç»ˆéŸ³é¢‘
            final_audio_path = output_path / f"podcast-{date_str}.mp3"
            mixed_audio = audio_mixer.mix_dialogue_podcast(
                audio_segments=audio_segments,
                output_path=final_audio_path,
                bgm_path=None,  # å¯é€‰ï¼šæ·»åŠ èƒŒæ™¯éŸ³ä¹
                intro_jingle_path=None,  # å¯é€‰ï¼šç‰‡å¤´éŸ³æ•ˆ
                outro_jingle_path=None,  # å¯é€‰ï¼šç‰‡å°¾éŸ³æ•ˆ
            )

            result["outputs"]["audio"] = str(final_audio_path)
            print(f"    âœ“ éŸ³é¢‘å·²ä¿å­˜: {final_audio_path.name}")
            print(f"    âœ“ æ—¶é•¿: {mixed_audio.duration_seconds:.1f}ç§’")

        except Exception as e:
            logger.error(f"éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
            print(f"  âš ï¸ éŸ³é¢‘ç”Ÿæˆå¤±è´¥: {e}")
    else:
        print("\n[æ­¥éª¤ 6/7] éŸ³é¢‘ç”Ÿæˆ - å·²è·³è¿‡")

    # æ­¥éª¤7: ç”Ÿæˆé™„ä»¶ï¼ˆæŠ¥å‘Šå’Œå°é¢ï¼‰
    print("\n[æ­¥éª¤ 7/7] ç”Ÿæˆé™„ä»¶")
    print("-" * 50)

    # 7.1 MarkdownæŠ¥å‘Š
    if not skip_report and not dry_run:
        print("  [7.1] ç”ŸæˆMarkdownæŠ¥å‘Š...")
        report_generator = ReportGenerator()
        report_path = output_path / f"report-{date_str}.md"

        report_generator.generate(
            analysis_result=analysis_result,
            ai_insight=ai_insight,
            output_path=report_path,
        )

        result["outputs"]["report"] = str(report_path)
        print(f"    âœ“ æŠ¥å‘Šå·²ä¿å­˜: {report_path.name}")
    else:
        print("  [7.1] MarkdownæŠ¥å‘Š - å·²è·³è¿‡")

    # 7.2 æ’­å®¢å°é¢
    if not skip_cover and not dry_run:
        print("  [7.2] ç”Ÿæˆæ’­å®¢å°é¢...")
        cover_generator = CoverGenerator()
        cover_path = output_path / f"cover-{date_str}.png"

        cover_generator.generate(
            date=date_str,
            title="æ¯æ—¥å°çº¢ä¹¦ç ”ç©¶",
            stats_text=f"{analysis_result.total_topics}ä¸ªè¯é¢˜ Â· {analysis_result.total_heat / 10000:.0f}ä¸‡çƒ­åº¦",
            output_path=cover_path,
        )

        result["outputs"]["cover"] = str(cover_path)
        print(f"    âœ“ å°é¢å·²ä¿å­˜: {cover_path.name}")
    else:
        print("  [7.2] æ’­å®¢å°é¢ - å·²è·³è¿‡")

    result["success"] = True
    return result


def print_banner(date_str: str, dry_run: bool = False):
    """æ‰“å°æ¨ªå¹…"""
    mode_tag = " [æ¼”ç¤ºæ¨¡å¼]" if dry_run else ""
    print()
    print("=" * 60)
    print(f"ğŸ™ï¸  æ¯æ—¥å°çº¢ä¹¦ç ”ç©¶æ’­å®¢ç”Ÿæˆå™¨{mode_tag}")
    print("=" * 60)
    print(f"ğŸ“… æ—¥æœŸ: {date_str}")
    print()


def print_summary(result: dict):
    """æ‰“å°ç”Ÿæˆæ‘˜è¦"""
    print()
    print("=" * 60)
    print("ğŸ‰ æ’­å®¢ç”Ÿæˆå®Œæˆï¼")
    print("=" * 60)
    print()

    outputs = result.get("outputs", {})

    if "script_json" in outputs:
        print(f"ğŸ“ è„šæœ¬æ–‡ä»¶:")
        print(f"   - JSON: {Path(outputs['script_json']).name}")
        if "script_md" in outputs:
            print(f"   - Markdown: {Path(outputs['script_md']).name}")

    if "audio" in outputs:
        print(f"ğŸ§ éŸ³é¢‘æ–‡ä»¶: {Path(outputs['audio']).name}")

    if "report" in outputs:
        print(f"ğŸ“„ ç ”ç©¶æŠ¥å‘Š: {Path(outputs['report']).name}")

    if "cover" in outputs:
        print(f"ğŸ¨ æ’­å®¢å°é¢: {Path(outputs['cover']).name}")

    print()
    print("æŸ¥çœ‹è¾“å‡ºç›®å½•:")
    print(f"  ls {Path(outputs.get('audio', 'output')).parent}")
    print()


if __name__ == "__main__":
    main()
