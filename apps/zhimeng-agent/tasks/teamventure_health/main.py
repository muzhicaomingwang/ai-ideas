"""TeamVentureç³»ç»Ÿå¥åº·åº¦ç›‘æ§

æ¯å°æ—¶æ‰§è¡Œï¼Œæ”¶é›†Prometheusç›‘æ§æŒ‡æ ‡ï¼Œåˆ†æç³»ç»Ÿå¥åº·çŠ¶å†µå¹¶é€šè¿‡é£ä¹¦å‘é€æŠ¥å‘Šã€‚

ç›‘æ§èŒƒå›´ï¼š
1. æœåŠ¡çŠ¶æ€ï¼ˆJava/PythonæœåŠ¡ã€MySQLã€Redisã€RabbitMQï¼‰
2. HTTPæ€§èƒ½æŒ‡æ ‡ï¼ˆè¯·æ±‚é‡ã€é”™è¯¯ç‡ã€å“åº”æ—¶é—´ï¼‰
3. LLMä½¿ç”¨æƒ…å†µï¼ˆè¯·æ±‚æ•°ã€Tokenæ¶ˆè€—ã€æˆæœ¬ä¼°ç®—ï¼‰
4. MySQLå¥åº·åº¦ï¼ˆè¿æ¥æ•°ã€æ…¢æŸ¥è¯¢ã€QPSï¼‰
5. JVMå¥åº·åº¦ï¼ˆå †å†…å­˜ã€GCæ¬¡æ•°ï¼‰
6. å®¹å™¨èµ„æºï¼ˆCPUã€å†…å­˜ä½¿ç”¨ç‡ï¼‰
"""

import asyncio
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

import httpx

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from tasks.config import config
from src.feishu_bot import get_feishu_bot

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class TeamVentureHealthMonitor:
    """TeamVentureå¥åº·åº¦ç›‘æ§å™¨"""

    def __init__(self, prometheus_url: str = "http://localhost:9090"):
        """
        Args:
            prometheus_url: PrometheusæœåŠ¡åœ°å€
        """
        self.prometheus_url = prometheus_url
        self.timestamp = datetime.now()
        self.time_str = self.timestamp.strftime("%Y-%m-%d %H:%M")

    async def query_prometheus(self, query: str) -> Optional[Dict]:
        """æ‰§è¡ŒPromQLæŸ¥è¯¢

        Args:
            query: PromQLæŸ¥è¯¢è¯­å¥

        Returns:
            æŸ¥è¯¢ç»“æœï¼Œå¤±è´¥è¿”å›None
        """
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(
                    f"{self.prometheus_url}/api/v1/query",
                    params={"query": query},
                )
                data = response.json()

                if data.get("status") != "success":
                    logger.error(f"PrometheusæŸ¥è¯¢å¤±è´¥: {data}")
                    return None

                return data.get("data", {})

        except Exception as e:
            logger.error(f"PrometheusæŸ¥è¯¢å¼‚å¸¸ [{query}]: {e}")
            return None

    async def collect_service_status(self) -> Dict[str, Any]:
        """æ”¶é›†æœåŠ¡çŠ¶æ€"""
        status_map = {}

        # æŸ¥è¯¢æ‰€æœ‰æœåŠ¡çš„upçŠ¶æ€
        result = await self.query_prometheus('up')

        if result and result.get("result"):
            for item in result["result"]:
                job = item["metric"].get("job", "unknown")
                value = int(item["value"][1])
                status_map[job] = "âœ… UP" if value == 1 else "âŒ DOWN"

        return status_map

    async def collect_http_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†HTTPæ€§èƒ½æŒ‡æ ‡"""
        metrics = {}

        # è¯·æ±‚é€Ÿç‡ï¼ˆæœ€è¿‘5åˆ†é’Ÿï¼‰
        result = await self.query_prometheus(
            'sum(rate(http_requests_total[5m])) by (service)'
        )
        if result and result.get("result"):
            metrics["request_rate"] = {
                item["metric"].get("service", "unknown"): f"{float(item['value'][1]):.2f} req/s"
                for item in result["result"]
            }

        # é”™è¯¯ç‡ï¼ˆæœ€è¿‘5åˆ†é’Ÿï¼‰
        result = await self.query_prometheus(
            'sum(rate(http_requests_total{status=~"5.."}[5m])) by (service) / '
            'sum(rate(http_requests_total[5m])) by (service) * 100'
        )
        if result and result.get("result"):
            metrics["error_rate"] = {
                item["metric"].get("service", "unknown"): f"{float(item['value'][1]):.2f}%"
                for item in result["result"]
            }

        # P95å“åº”æ—¶é—´ï¼ˆæœ€è¿‘5åˆ†é’Ÿï¼‰
        result = await self.query_prometheus(
            'histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (service, le)) * 1000'
        )
        if result and result.get("result"):
            metrics["p95_latency"] = {
                item["metric"].get("service", "unknown"): f"{float(item['value'][1]):.0f}ms"
                for item in result["result"]
            }

        return metrics

    async def collect_llm_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†LLMä½¿ç”¨æŒ‡æ ‡"""
        metrics = {}

        # è¯·æ±‚æ€»æ•°ï¼ˆæœ€è¿‘1å°æ—¶ï¼‰
        result = await self.query_prometheus(
            'increase(llm_requests_total[1h])'
        )
        if result and result.get("result"):
            total = sum(float(item["value"][1]) for item in result["result"])
            metrics["requests"] = f"{int(total)} æ¬¡"

        # Tokenæ¶ˆè€—ï¼ˆæœ€è¿‘1å°æ—¶ï¼‰
        result = await self.query_prometheus(
            'increase(llm_tokens_total[1h])'
        )
        if result and result.get("result"):
            prompt_tokens = 0
            completion_tokens = 0
            for item in result["result"]:
                token_type = item["metric"].get("type", "")
                value = float(item["value"][1])
                if token_type == "prompt":
                    prompt_tokens += value
                elif token_type == "completion":
                    completion_tokens += value
            metrics["tokens"] = f"è¾“å…¥: {int(prompt_tokens):,} / è¾“å‡º: {int(completion_tokens):,}"

        # æˆæœ¬ä¼°ç®—ï¼ˆæœ€è¿‘1å°æ—¶ï¼‰
        result = await self.query_prometheus(
            'increase(llm_estimated_cost_usd[1h])'
        )
        if result and result.get("result"):
            total_cost = sum(float(item["value"][1]) for item in result["result"])
            metrics["cost"] = f"${total_cost:.2f}"

        return metrics

    async def collect_mysql_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†MySQLå¥åº·æŒ‡æ ‡"""
        metrics = {}

        # è¿æ¥æ•°
        result = await self.query_prometheus(
            'mysql_global_status_threads_connected'
        )
        if result and result.get("result"):
            for item in result["result"]:
                instance = item["metric"].get("instance", "unknown")
                value = int(float(item["value"][1]))
                metrics[f"connections_{instance}"] = f"{value} ä¸ª"

        # æ…¢æŸ¥è¯¢ï¼ˆæœ€è¿‘1å°æ—¶ï¼‰
        result = await self.query_prometheus(
            'increase(mysql_global_status_slow_queries[1h])'
        )
        if result and result.get("result"):
            for item in result["result"]:
                instance = item["metric"].get("instance", "unknown")
                value = int(float(item["value"][1]))
                metrics[f"slow_queries_{instance}"] = f"{value} æ¬¡"

        # QPSï¼ˆæœ€è¿‘5åˆ†é’Ÿå¹³å‡ï¼‰
        result = await self.query_prometheus(
            'rate(mysql_global_status_queries[5m])'
        )
        if result and result.get("result"):
            for item in result["result"]:
                instance = item["metric"].get("instance", "unknown")
                value = float(item["value"][1])
                metrics[f"qps_{instance}"] = f"{value:.2f} q/s"

        return metrics

    async def collect_jvm_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†JVMå¥åº·æŒ‡æ ‡"""
        metrics = {}

        # å †å†…å­˜ä½¿ç”¨ç‡
        result = await self.query_prometheus(
            'jvm_memory_used_bytes{area="heap"} / jvm_memory_max_bytes{area="heap"} * 100'
        )
        if result and result.get("result"):
            for item in result["result"]:
                value = float(item["value"][1])
                metrics["heap_usage"] = f"{value:.1f}%"

        # GCæ¬¡æ•°ï¼ˆæœ€è¿‘1å°æ—¶ï¼‰
        result = await self.query_prometheus(
            'increase(jvm_gc_pause_seconds_count[1h])'
        )
        if result and result.get("result"):
            total_gc = sum(float(item["value"][1]) for item in result["result"])
            metrics["gc_count"] = f"{int(total_gc)} æ¬¡"

        return metrics

    async def collect_container_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†å®¹å™¨èµ„æºä½¿ç”¨æƒ…å†µ"""
        metrics = {}

        # å®¹å™¨CPUä½¿ç”¨ç‡ï¼ˆæœ€è¿‘5åˆ†é’Ÿå¹³å‡ï¼‰
        result = await self.query_prometheus(
            'rate(container_cpu_usage_seconds_total{name=~"teamventure.*"}[5m]) * 100'
        )
        if result and result.get("result"):
            for item in result["result"]:
                name = item["metric"].get("name", "unknown")
                value = float(item["value"][1])
                metrics[f"cpu_{name}"] = f"{value:.1f}%"

        # å®¹å™¨å†…å­˜ä½¿ç”¨ç‡
        result = await self.query_prometheus(
            'container_memory_usage_bytes{name=~"teamventure.*"} / '
            'container_spec_memory_limit_bytes{name=~"teamventure.*"} * 100'
        )
        if result and result.get("result"):
            for item in result["result"]:
                name = item["metric"].get("name", "unknown")
                value = float(item["value"][1])
                metrics[f"memory_{name}"] = f"{value:.1f}%"

        return metrics

    def determine_health_status(
        self,
        service_status: Dict,
        http_metrics: Dict,
        llm_metrics: Dict,
        mysql_metrics: Dict,
    ) -> tuple[str, List[str]]:
        """åˆ†ææŒ‡æ ‡ï¼Œåˆ¤å®šå¥åº·çŠ¶æ€

        Returns:
            (çŠ¶æ€, å‘Šè­¦åˆ—è¡¨): çŠ¶æ€ä¸º healthy/degraded/critical
        """
        alerts = []

        # æ£€æŸ¥æœåŠ¡çŠ¶æ€
        down_services = [
            name for name, status in service_status.items()
            if "DOWN" in status
        ]
        if down_services:
            alerts.append(f"æœåŠ¡å®•æœº: {', '.join(down_services)}")

        # æ£€æŸ¥é”™è¯¯ç‡
        error_rates = http_metrics.get("error_rate", {})
        for service, rate_str in error_rates.items():
            rate = float(rate_str.rstrip("%"))
            if rate > 5.0:
                alerts.append(f"{service} é”™è¯¯ç‡è¿‡é«˜: {rate_str}")

        # æ£€æŸ¥å“åº”æ—¶é—´
        latencies = http_metrics.get("p95_latency", {})
        for service, latency_str in latencies.items():
            latency = float(latency_str.rstrip("ms"))
            if latency > 1000:
                alerts.append(f"{service} å“åº”æ—¶é—´è¿‡é•¿: {latency_str}")

        # æ£€æŸ¥MySQLæ…¢æŸ¥è¯¢
        for key, value in mysql_metrics.items():
            if "slow_queries" in key:
                count = int(value.split()[0])
                if count > 100:
                    alerts.append(f"MySQLæ…¢æŸ¥è¯¢è¾ƒå¤š: {value}")

        # åˆ¤å®šæ€»ä½“çŠ¶æ€
        if down_services or any("é”™è¯¯ç‡è¿‡é«˜" in a for a in alerts):
            return "critical", alerts
        elif alerts:
            return "degraded", alerts
        else:
            return "healthy", []

    def generate_report(
        self,
        service_status: Dict,
        http_metrics: Dict,
        llm_metrics: Dict,
        mysql_metrics: Dict,
        jvm_metrics: Dict,
        container_metrics: Dict,
        health_status: str,
        alerts: List[str],
    ) -> str:
        """ç”Ÿæˆå¥åº·åº¦æŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰"""

        # çŠ¶æ€å›¾æ ‡
        status_icon = {
            "healthy": "âœ…",
            "degraded": "âš ï¸",
            "critical": "ğŸš¨",
        }.get(health_status, "â“")

        lines = [
            f"## {status_icon} ç³»ç»Ÿå¥åº·åº¦: {health_status.upper()}",
            "",
            f"**æ—¶é—´**: {self.time_str}",
            "",
        ]

        # å‘Šè­¦ä¿¡æ¯
        if alerts:
            lines.extend([
                "### ğŸ”” å‘Šè­¦",
                "",
            ])
            for alert in alerts:
                lines.append(f"- {alert}")
            lines.append("")

        # æœåŠ¡çŠ¶æ€
        if service_status:
            lines.extend([
                "### ğŸ“Š æœåŠ¡çŠ¶æ€",
                "",
            ])
            for service, status in service_status.items():
                lines.append(f"- **{service}**: {status}")
            lines.append("")

        # HTTPæ€§èƒ½
        if http_metrics:
            lines.extend([
                "### ğŸŒ HTTPæ€§èƒ½",
                "",
            ])

            if "request_rate" in http_metrics:
                lines.append("**è¯·æ±‚é€Ÿç‡ï¼ˆ5åˆ†é’Ÿï¼‰**:")
                for service, rate in http_metrics["request_rate"].items():
                    lines.append(f"- {service}: {rate}")
                lines.append("")

            if "error_rate" in http_metrics:
                lines.append("**é”™è¯¯ç‡ï¼ˆ5åˆ†é’Ÿï¼‰**:")
                for service, rate in http_metrics["error_rate"].items():
                    lines.append(f"- {service}: {rate}")
                lines.append("")

            if "p95_latency" in http_metrics:
                lines.append("**P95å“åº”æ—¶é—´ï¼ˆ5åˆ†é’Ÿï¼‰**:")
                for service, latency in http_metrics["p95_latency"].items():
                    lines.append(f"- {service}: {latency}")
                lines.append("")

        # LLMä½¿ç”¨æƒ…å†µ
        if llm_metrics:
            lines.extend([
                "### ğŸ¤– LLMä½¿ç”¨ï¼ˆ1å°æ—¶ï¼‰",
                "",
            ])
            if "requests" in llm_metrics:
                lines.append(f"- **è¯·æ±‚æ•°**: {llm_metrics['requests']}")
            if "tokens" in llm_metrics:
                lines.append(f"- **Tokenæ¶ˆè€—**: {llm_metrics['tokens']}")
            if "cost" in llm_metrics:
                lines.append(f"- **æˆæœ¬ä¼°ç®—**: {llm_metrics['cost']}")
            lines.append("")

        # MySQLå¥åº·åº¦
        if mysql_metrics:
            lines.extend([
                "### ğŸ—„ï¸ MySQL",
                "",
            ])
            for key, value in mysql_metrics.items():
                label = key.replace("_", " ").title()
                lines.append(f"- **{label}**: {value}")
            lines.append("")

        # JVMå¥åº·åº¦
        if jvm_metrics:
            lines.extend([
                "### â˜• JVM",
                "",
            ])
            for key, value in jvm_metrics.items():
                label = key.replace("_", " ").title()
                lines.append(f"- **{label}**: {value}")
            lines.append("")

        # å®¹å™¨èµ„æº
        if container_metrics:
            lines.extend([
                "### ğŸ³ å®¹å™¨èµ„æº",
                "",
            ])
            # æŒ‰å®¹å™¨åˆ†ç»„æ˜¾ç¤º
            containers = set(
                k.split("_", 1)[1] for k in container_metrics.keys()
            )
            for container in sorted(containers):
                cpu_key = f"cpu_{container}"
                mem_key = f"memory_{container}"
                lines.append(f"**{container}**:")
                if cpu_key in container_metrics:
                    lines.append(f"- CPU: {container_metrics[cpu_key]}")
                if mem_key in container_metrics:
                    lines.append(f"- å†…å­˜: {container_metrics[mem_key]}")
                lines.append("")

        return "\n".join(lines)

    async def send_to_feishu(self, report: str, health_status: str):
        """å‘é€æŠ¥å‘Šåˆ°é£ä¹¦

        Args:
            report: æŠ¥å‘Šå†…å®¹ï¼ˆMarkdownï¼‰
            health_status: å¥åº·çŠ¶æ€ï¼ˆhealthy/degraded/criticalï¼‰
        """
        try:
            bot = get_feishu_bot()

            # æ ¹æ®å¥åº·çŠ¶æ€é€‰æ‹©å¡ç‰‡é¢œè‰²
            template_map = {
                "healthy": "green",
                "degraded": "yellow",
                "critical": "red",
            }
            template = template_map.get(health_status, "blue")

            # å‘é€å¡ç‰‡æ¶ˆæ¯
            result = await bot.send_card(
                receive_id=config.FEISHU_RECIPIENT_OPEN_ID,
                title="TeamVenture ç³»ç»Ÿå¥åº·åº¦æŠ¥å‘Š",
                content=report,
                template=template,
            )

            logger.info(f"é£ä¹¦æ¶ˆæ¯å‘é€ç»“æœ: {result}")

        except Exception as e:
            logger.error(f"å‘é€é£ä¹¦æ¶ˆæ¯å¤±è´¥: {e}")
            raise

    async def run(self) -> bool:
        """æ‰§è¡Œå¥åº·åº¦æ£€æŸ¥å’ŒæŠ¥å‘Š"""
        logger.info(f"å¼€å§‹æ‰§è¡Œ TeamVenture å¥åº·åº¦æ£€æŸ¥ - {self.time_str}")

        try:
            # å¹¶è¡Œæ”¶é›†æ‰€æœ‰æŒ‡æ ‡
            service_status, http_metrics, llm_metrics, mysql_metrics, jvm_metrics, container_metrics = await asyncio.gather(
                self.collect_service_status(),
                self.collect_http_metrics(),
                self.collect_llm_metrics(),
                self.collect_mysql_metrics(),
                self.collect_jvm_metrics(),
                self.collect_container_metrics(),
            )

            logger.info("æŒ‡æ ‡æ”¶é›†å®Œæˆ")

            # åˆ†æå¥åº·çŠ¶æ€
            health_status, alerts = self.determine_health_status(
                service_status,
                http_metrics,
                llm_metrics,
                mysql_metrics,
            )

            logger.info(f"å¥åº·çŠ¶æ€: {health_status}, å‘Šè­¦æ•°: {len(alerts)}")

            # ç”ŸæˆæŠ¥å‘Š
            report = self.generate_report(
                service_status,
                http_metrics,
                llm_metrics,
                mysql_metrics,
                jvm_metrics,
                container_metrics,
                health_status,
                alerts,
            )

            # å‘é€åˆ°é£ä¹¦
            await self.send_to_feishu(report, health_status)

            logger.info("å¥åº·åº¦æŠ¥å‘Šå‘é€æˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"å¥åº·åº¦æ£€æŸ¥å¤±è´¥: {e}", exc_info=True)
            return False


async def main_async():
    """å¼‚æ­¥ä¸»å…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description="TeamVentureç³»ç»Ÿå¥åº·åº¦ç›‘æ§")
    parser.add_argument(
        "--prometheus-url",
        type=str,
        default="http://localhost:9090",
        help="PrometheusæœåŠ¡åœ°å€",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ä»…ç”ŸæˆæŠ¥å‘Šï¼Œä¸å‘é€é£ä¹¦æ¶ˆæ¯",
    )

    args = parser.parse_args()

    # åˆ›å»ºç›‘æ§å™¨
    monitor = TeamVentureHealthMonitor(prometheus_url=args.prometheus_url)

    if args.dry_run:
        # æ”¶é›†æŒ‡æ ‡å¹¶æ‰“å°æŠ¥å‘Š
        service_status, http_metrics, llm_metrics, mysql_metrics, jvm_metrics, container_metrics = await asyncio.gather(
            monitor.collect_service_status(),
            monitor.collect_http_metrics(),
            monitor.collect_llm_metrics(),
            monitor.collect_mysql_metrics(),
            monitor.collect_jvm_metrics(),
            monitor.collect_container_metrics(),
        )

        health_status, alerts = monitor.determine_health_status(
            service_status,
            http_metrics,
            llm_metrics,
            mysql_metrics,
        )

        report = monitor.generate_report(
            service_status,
            http_metrics,
            llm_metrics,
            mysql_metrics,
            jvm_metrics,
            container_metrics,
            health_status,
            alerts,
        )

        print(report)
    else:
        # æ‰§è¡Œå®Œæ•´æµç¨‹
        success = await monitor.run()
        sys.exit(0 if success else 1)


def main():
    """åŒæ­¥ä¸»å…¥å£ï¼ˆç”¨äºlaunchdè°ƒåº¦ï¼‰"""
    asyncio.run(main_async())


if __name__ == "__main__":
    main()
