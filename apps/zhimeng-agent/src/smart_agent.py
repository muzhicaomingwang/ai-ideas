"""æ™ºèƒ½ Agent

æ ¹æ®é—®é¢˜ç±»å‹ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·å›ç­”ï¼š
- çŸ¥è¯†åº“æ£€ç´¢ï¼šä¸ªäººç¬”è®°ã€æ–¹æ³•è®ºã€æŠ€æœ¯æ–‡æ¡£
- Web æœç´¢ï¼šå®æ—¶ä¿¡æ¯ï¼ˆæœºç¥¨ã€å¤©æ°”ã€æ–°é—»ç­‰ï¼‰
- æ—…è¡Œå·¥å…·ï¼šèˆªç­æœç´¢ï¼ˆKiwi MCPï¼‰ã€åœ°å›¾æœåŠ¡ï¼ˆé«˜å¾·ï¼‰
- å¯¹è¯è®°å¿†ï¼šè®°ä½ä¸æ¯ä¸ªç”¨æˆ·çš„å¯¹è¯å†å²
- çŸ¥è¯†æ²‰æ·€ï¼šå°†æœ‰ä»·å€¼çš„å›ç­”è‡ªåŠ¨ä¿å­˜åˆ° Obsidian
"""

import json
import logging
import re
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

import httpx

import sys
sys.path.insert(0, str(Path(__file__).parent.parent))
from config.settings import settings
from src.travel_tools import get_travel_tools

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# éœ€è¦ Web æœç´¢çš„é—®é¢˜å…³é”®è¯
REALTIME_KEYWORDS = [
    "æœºç¥¨", "èˆªç­", "ç«è½¦ç¥¨", "é…’åº—", "ä»·æ ¼", "å¤šå°‘é’±",
    "å¤©æ°”", "æ¸©åº¦", "ä¸‹é›¨",
    "æ–°é—»", "æœ€æ–°", "ä»Šå¤©", "æ˜å¤©", "æœ¬å‘¨", "ä¸‹å‘¨",
    "è‚¡ç¥¨", "æ±‡ç‡", "æ¯”ç‰¹å¸",
    "è·¯å†µ", "åœ°å›¾", "æ€ä¹ˆèµ°",
    "ç”µè¯", "åœ°å€", "è¥ä¸šæ—¶é—´",
]


def needs_web_search(question: str) -> bool:
    """åˆ¤æ–­é—®é¢˜æ˜¯å¦éœ€è¦ Web æœç´¢"""
    question_lower = question.lower()
    for keyword in REALTIME_KEYWORDS:
        if keyword in question_lower:
            return True
    return False


def web_search(query: str, num_results: int = 5) -> str:
    """ä½¿ç”¨æœç´¢å¼•æ“æœç´¢å®æ—¶ä¿¡æ¯

    Args:
        query: æœç´¢æŸ¥è¯¢
        num_results: è¿”å›ç»“æœæ•°é‡

    Returns:
        æœç´¢ç»“æœæ–‡æœ¬æˆ–æœç´¢å»ºè®®
    """
    # å¯¹äºæ—…è¡Œç›¸å…³æŸ¥è¯¢ï¼Œæä¾›ä¸“ä¸šå¹³å°å»ºè®®
    travel_keywords = ["æœºç¥¨", "èˆªç­", "é…’åº—", "ç«è½¦ç¥¨", "é«˜é“"]
    is_travel_query = any(kw in query for kw in travel_keywords)

    if is_travel_query:
        # æ„å»ºæ—…è¡ŒæŸ¥è¯¢çš„æ™ºèƒ½å»ºè®®
        suggestions = generate_travel_suggestions(query)
        return suggestions

    # å…¶ä»–æŸ¥è¯¢å°è¯•é€šç”¨æœç´¢
    try:
        from duckduckgo_search import DDGS

        with DDGS() as ddgs:
            results = list(ddgs.text(query, max_results=num_results))

        if results:
            formatted = []
            for i, r in enumerate(results, 1):
                formatted.append(f"{i}. **{r.get('title', 'N/A')}**")
                formatted.append(f"   {r.get('body', 'N/A')}")
                formatted.append(f"   æ¥æº: {r.get('href', 'N/A')}")
                formatted.append("")
            return "\n".join(formatted)

    except Exception as e:
        logger.warning(f"æœç´¢å¤±è´¥: {e}")

    # é€šç”¨æœç´¢å»ºè®®
    return generate_search_suggestions(query)


def parse_flight_query(query: str) -> Optional[dict]:
    """è§£æèˆªç­æŸ¥è¯¢ï¼Œæå–å‡ºå‘åœ°ã€ç›®çš„åœ°ã€æ—¥æœŸ

    Returns:
        dict with keys: origin, destination, date
        None if not a flight query or cannot parse
    """
    from datetime import datetime, timedelta

    # åŸå¸‚åˆ—è¡¨
    cities = ["åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³", "æˆéƒ½", "æ­å·", "è¥¿å®‰",
              "é‡åº†", "å—äº¬", "æ­¦æ±‰", "é’å²›", "å¤§è¿", "å¦é—¨", "æ˜†æ˜", "ä¸‰äºš"]

    # æ£€æµ‹æ˜¯å¦æ˜¯èˆªç­æŸ¥è¯¢
    flight_keywords = ["æœºç¥¨", "èˆªç­", "é£", "åé£æœº"]
    if not any(kw in query for kw in flight_keywords):
        return None

    # æå–åŸå¸‚
    found_cities = [c for c in cities if c in query]
    if len(found_cities) < 2:
        return None

    # åˆ¤æ–­å‡ºå‘åœ°å’Œç›®çš„åœ°ï¼ˆé€šè¿‡"åˆ°"ã€"å»"ã€"é£"ç­‰ä»‹è¯ï¼‰
    origin = None
    destination = None

    # æ¨¡å¼: "ä»Xåˆ°Y" æˆ– "Xåˆ°Y" æˆ– "Xé£Y" æˆ– "å»Y"
    patterns = [
        r"ä»(.+?)åˆ°(.+)",
        r"(.+?)åˆ°(.+)",
        r"(.+?)é£(.+)",
    ]

    for pattern in patterns:
        match = re.search(pattern, query)
        if match:
            for city in cities:
                if city in match.group(1):
                    origin = city
                    break
            for city in cities:
                if city in match.group(2):
                    destination = city
                    break
            if origin and destination:
                break

    if not origin or not destination:
        # é»˜è®¤ç¬¬ä¸€ä¸ªä¸ºå‡ºå‘åœ°ï¼Œç¬¬äºŒä¸ªä¸ºç›®çš„åœ°
        origin = found_cities[0]
        destination = found_cities[1]

    # è§£ææ—¥æœŸ
    date = None
    today = datetime.now()

    if "æ˜å¤©" in query:
        date = (today + timedelta(days=1)).strftime("%Y-%m-%d")
    elif "åå¤©" in query:
        date = (today + timedelta(days=2)).strftime("%Y-%m-%d")
    elif "æœ¬å‘¨å…­" in query or "è¿™å‘¨å…­" in query:
        days_until = (5 - today.weekday()) % 7
        if days_until == 0:
            days_until = 7
        date = (today + timedelta(days=days_until)).strftime("%Y-%m-%d")
    elif "æœ¬å‘¨æ—¥" in query or "è¿™å‘¨æ—¥" in query:
        days_until = (6 - today.weekday()) % 7
        if days_until == 0:
            days_until = 7
        date = (today + timedelta(days=days_until)).strftime("%Y-%m-%d")
    elif "ä¸‹å‘¨" in query:
        days_until = (7 - today.weekday()) % 7 + 7
        date = (today + timedelta(days=days_until)).strftime("%Y-%m-%d")
    else:
        # å°è¯•åŒ¹é…æ—¥æœŸæ ¼å¼
        date_patterns = [
            (r"(\d{4})[-/](\d{1,2})[-/](\d{1,2})", lambda m: f"{m.group(1)}-{m.group(2).zfill(2)}-{m.group(3).zfill(2)}"),
            (r"(\d{1,2})æœˆ(\d{1,2})æ—¥?", lambda m: f"{today.year}-{m.group(1).zfill(2)}-{m.group(2).zfill(2)}"),
        ]
        for pattern, formatter in date_patterns:
            match = re.search(pattern, query)
            if match:
                date = formatter(match)
                break

        if not date:
            # é»˜è®¤ 7 å¤©å
            date = (today + timedelta(days=7)).strftime("%Y-%m-%d")

    return {
        "origin": origin,
        "destination": destination,
        "date": date,
    }


def generate_travel_suggestions(query: str) -> str:
    """ä¸ºæ—…è¡ŒæŸ¥è¯¢ç”Ÿæˆä¸“ä¸šå»ºè®®ï¼Œä¼˜å…ˆä½¿ç”¨ MCP å·¥å…·è·å–å®æ—¶æ•°æ®"""
    from datetime import datetime, timedelta

    # å°è¯•è§£æèˆªç­æŸ¥è¯¢
    flight_info = parse_flight_query(query)

    if flight_info:
        # ä½¿ç”¨ Kiwi MCP æœç´¢çœŸå®èˆªç­
        logger.info(f"æ£€æµ‹åˆ°èˆªç­æŸ¥è¯¢: {flight_info}")
        try:
            travel_tools = get_travel_tools()
            result = travel_tools.search_flights(
                origin=flight_info["origin"],
                destination=flight_info["destination"],
                date=flight_info["date"],
                format_output=True,
            )

            if "âŒ" not in result and "æœªæ‰¾åˆ°" not in result:
                # æˆåŠŸè·å–èˆªç­æ•°æ®
                header = f"## {flight_info['origin']} â†’ {flight_info['destination']} èˆªç­æŸ¥è¯¢\n"
                header += f"**å‡ºå‘æ—¥æœŸï¼š** {flight_info['date']}\n\n"
                return header + result + "\n\n" + _get_booking_tips()
            else:
                logger.warning(f"èˆªç­æœç´¢æ— ç»“æœæˆ–å¤±è´¥: {result}")
        except Exception as e:
            logger.error(f"èˆªç­æœç´¢å¼‚å¸¸: {e}")

    # å›é€€åˆ°é™æ€å»ºè®®
    return _generate_static_travel_suggestions(query)


def _get_booking_tips() -> str:
    """è·å–è®¢ç¥¨å°è´´å£«"""
    return """---
**ğŸ’¡ è®¢ç¥¨å°è´´å£«ï¼š**
- å»ºè®®é€šè¿‡ [æºç¨‹](https://flights.ctrip.com)ã€[å»å“ªå„¿](https://flight.qunar.com) æ¯”ä»·åé¢„è®¢
- æ—©ä¸Š6-8ç‚¹èˆªç­é€šå¸¸æ›´ä¾¿å®œ
- æå‰7-14å¤©é¢„è®¢æ€§ä»·æ¯”æœ€é«˜
- å…³æ³¨èˆªç©ºå…¬å¸ä¼šå‘˜æ—¥ä¿ƒé”€"""


def _generate_static_travel_suggestions(query: str) -> str:
    """ç”Ÿæˆé™æ€æ—…è¡Œå»ºè®®ï¼ˆå½“ MCP ä¸å¯ç”¨æ—¶çš„å›é€€æ–¹æ¡ˆï¼‰"""
    from datetime import datetime, timedelta

    # è§£ææŸ¥è¯¢ä¸­çš„ä¿¡æ¯
    destination = ""
    if "åŒ—äº¬" in query:
        destination = "åŒ—äº¬"
    elif "ä¸Šæµ·" in query:
        destination = "ä¸Šæµ·"

    time_hint = ""
    if "æœ¬å‘¨å…­" in query:
        today = datetime.now()
        days_until_saturday = (5 - today.weekday()) % 7
        if days_until_saturday == 0:
            days_until_saturday = 7
        saturday = today + timedelta(days=days_until_saturday)
        time_hint = saturday.strftime("%Yå¹´%mæœˆ%dæ—¥ï¼ˆå‘¨å…­ï¼‰")
    elif "æ˜å¤©" in query:
        tomorrow = datetime.now() + timedelta(days=1)
        time_hint = tomorrow.strftime("%Yå¹´%mæœˆ%dæ—¥")

    suggestions = f"""## å®æ—¶æ—…è¡Œä¿¡æ¯æŸ¥è¯¢å»ºè®®

**æ‚¨çš„éœ€æ±‚ï¼š** {query}

**æ¨èæŸ¥è¯¢å¹³å°ï¼š**

1. **æºç¨‹æ—…è¡Œ** - https://flights.ctrip.com
   - æœºç¥¨æ¯”ä»·ã€èˆªç­æ—¶åˆ»æŸ¥è¯¢
   - æ”¯æŒå¤šå¹³å°æ¯”ä»·

2. **å»å“ªå„¿** - https://flight.qunar.com
   - ä½ä»·æœºç¥¨æœç´¢
   - ä»·æ ¼æ—¥å†æŸ¥çœ‹æœ€ä¾¿å®œæ—¥æœŸ

3. **é£çŒª** - https://www.fliggy.com
   - é˜¿é‡Œç³»æ—…è¡Œå¹³å°
   - å¸¸æœ‰ä¼šå‘˜ä¸“äº«æŠ˜æ‰£

4. **èˆªç©ºå…¬å¸å®˜ç½‘**
   - å›½èˆª: www.airchina.com.cn
   - ä¸œèˆª: www.ceair.com
   - å—èˆª: www.csair.com
   - å®˜ç½‘æœ‰æ—¶æœ‰ç‹¬å®¶ä¼˜æƒ 

**çœé’±å°è´´å£«ï¼š**
- æ—©ä¸Š6-8ç‚¹èˆªç­é€šå¸¸æ›´ä¾¿å®œ
- æå‰7-14å¤©é¢„è®¢æ€§ä»·æ¯”æœ€é«˜
- å…³æ³¨èˆªç©ºå…¬å¸ä¼šå‘˜æ—¥ä¿ƒé”€
- é€‰æ‹©ç»åœèˆªç­å¯èƒ½æ›´çœé’±"""

    if time_hint:
        suggestions += f"\n\n**ç›®æ ‡æ—¥æœŸï¼š** {time_hint}"

    return suggestions


def generate_search_suggestions(query: str) -> str:
    """ä¸ºé€šç”¨æŸ¥è¯¢ç”Ÿæˆæœç´¢å»ºè®®"""
    return f"""## æœç´¢å»ºè®®

ç”±äºå®æ—¶æœç´¢æš‚æ—¶ä¸å¯ç”¨ï¼Œå»ºè®®æ‚¨é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–æœ€æ–°ä¿¡æ¯ï¼š

1. **æœç´¢å¼•æ“**
   - Google: https://www.google.com
   - Bing: https://www.bing.com
   - ç™¾åº¦: https://www.baidu.com

2. **ç›¸å…³æŸ¥è¯¢å…³é”®è¯**
   - åŸå§‹æŸ¥è¯¢: {query}

å¦‚æœæ‚¨æœ‰å…³äº AI äº§å“è®¾è®¡ã€è®¤çŸ¥ç§‘å­¦æˆ–è½¯ä»¶å·¥ç¨‹çš„é—®é¢˜ï¼Œæˆ‘å¯ä»¥åŸºäºçŸ¥è¯†åº“ä¸ºæ‚¨è¯¦ç»†è§£ç­”ã€‚"""


def search_with_httpx(query: str, num_results: int = 5) -> str:
    """ä½¿ç”¨ httpx ç›´æ¥æœç´¢ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    try:
        # ä½¿ç”¨ DuckDuckGo HTML API
        url = "https://html.duckduckgo.com/html/"
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
        }

        with httpx.Client(timeout=10.0) as client:
            response = client.post(url, data={"q": query}, headers=headers)

        if response.status_code != 200:
            return f"æœç´¢å¤±è´¥: HTTP {response.status_code}"

        # ç®€å•è§£æç»“æœ
        from html.parser import HTMLParser

        class ResultParser(HTMLParser):
            def __init__(self):
                super().__init__()
                self.results = []
                self.in_result = False
                self.current = {}

            def handle_starttag(self, tag, attrs):
                attrs_dict = dict(attrs)
                if tag == "a" and "result__a" in attrs_dict.get("class", ""):
                    self.in_result = True
                    self.current["url"] = attrs_dict.get("href", "")

            def handle_data(self, data):
                if self.in_result and data.strip():
                    self.current["title"] = data.strip()
                    self.results.append(self.current)
                    self.current = {}
                    self.in_result = False

        parser = ResultParser()
        parser.feed(response.text)

        if not parser.results:
            return "æœªæ‰¾åˆ°æœç´¢ç»“æœ"

        formatted = []
        for i, r in enumerate(parser.results[:num_results], 1):
            formatted.append(f"{i}. **{r.get('title', 'N/A')}**")
            formatted.append(f"   æ¥æº: {r.get('url', 'N/A')}")
            formatted.append("")

        return "\n".join(formatted)

    except Exception as e:
        logger.error(f"å¤‡ç”¨æœç´¢å¤±è´¥: {e}")
        return f"æœç´¢å‡ºé”™: {e}"


class SmartAgent:
    """æ™ºèƒ½ Agent

    æ”¯æŒå¯¹è¯è®°å¿†å’ŒçŸ¥è¯†è‡ªåŠ¨æ²‰æ·€åŠŸèƒ½ã€‚
    """

    # ç±»çº§åˆ«çš„å¯¹è¯å†å²å­˜å‚¨ï¼ˆæŒ‰ç”¨æˆ·IDï¼‰
    _conversation_history: Dict[str, List[dict]] = defaultdict(list)

    # é…ç½®
    MAX_HISTORY_TURNS = 10  # æœ€å¤šè®°ä½10è½®å¯¹è¯
    AUTO_SAVE_FOLDER = "AI-Generated"  # Obsidian è‡ªåŠ¨ä¿å­˜ç›®å½•

    def __init__(self):
        from src.retriever import get_retriever
        from src.llm_client import get_llm_client

        self.retriever = get_retriever()
        self.llm_client = get_llm_client()

    def _get_conversation_context(self, user_id: str) -> str:
        """è·å–ç”¨æˆ·çš„å¯¹è¯å†å²ä½œä¸ºä¸Šä¸‹æ–‡

        Args:
            user_id: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ï¼ˆå¦‚é£ä¹¦ open_idï¼‰

        Returns:
            æ ¼å¼åŒ–çš„å¯¹è¯å†å²æ–‡æœ¬
        """
        history = self._conversation_history.get(user_id, [])
        if not history:
            return ""

        context_parts = ["## ä¹‹å‰çš„å¯¹è¯è®°å½•\n"]
        for turn in history[-self.MAX_HISTORY_TURNS:]:
            context_parts.append(f"**ç”¨æˆ·**: {turn['question']}")
            # åªå–å›ç­”çš„å‰500å­—ä½œä¸ºå†å²ä¸Šä¸‹æ–‡ï¼Œé¿å…å¤ªé•¿
            answer_preview = turn['answer'][:500]
            if len(turn['answer']) > 500:
                answer_preview += "..."
            context_parts.append(f"**åŠ©æ‰‹**: {answer_preview}\n")

        return "\n".join(context_parts)

    def _update_conversation_history(
        self,
        user_id: str,
        question: str,
        answer: str
    ) -> None:
        """æ›´æ–°ç”¨æˆ·çš„å¯¹è¯å†å²

        Args:
            user_id: ç”¨æˆ·å”¯ä¸€æ ‡è¯†
            question: ç”¨æˆ·é—®é¢˜
            answer: åŠ©æ‰‹å›ç­”
        """
        self._conversation_history[user_id].append({
            "question": question,
            "answer": answer,
            "timestamp": datetime.now().isoformat(),
        })

        # é™åˆ¶å†å²é•¿åº¦
        if len(self._conversation_history[user_id]) > self.MAX_HISTORY_TURNS * 2:
            self._conversation_history[user_id] = \
                self._conversation_history[user_id][-self.MAX_HISTORY_TURNS:]

    def _save_to_obsidian(
        self,
        question: str,
        answer: str,
        category: str = "general"
    ) -> Optional[str]:
        """å°†ç”Ÿæˆçš„å†…å®¹ä¿å­˜åˆ° Obsidian

        Args:
            question: ç”¨æˆ·é—®é¢˜ï¼ˆç”¨äºç”Ÿæˆæ–‡ä»¶åï¼‰
            answer: ç”Ÿæˆçš„å›ç­”
            category: åˆ†ç±»ï¼ˆç”¨äºå­ç›®å½•ï¼‰

        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            # æ„å»ºä¿å­˜è·¯å¾„
            vault_path = settings.vault_path
            save_dir = vault_path / self.AUTO_SAVE_FOLDER / category
            save_dir.mkdir(parents=True, exist_ok=True)

            # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŸºäºé—®é¢˜å’Œæ—¶é—´æˆ³ï¼‰
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            # æ¸…ç†é—®é¢˜æ–‡æœ¬ä½œä¸ºæ–‡ä»¶å
            safe_title = re.sub(r'[\\/*?:"<>|]', '', question)[:50]
            filename = f"{timestamp}_{safe_title}.md"
            file_path = save_dir / filename

            # æ„å»º Markdown å†…å®¹
            content = f"""# {question}

> ğŸ¤– ç”± AI è‡ªåŠ¨ç”Ÿæˆ | {datetime.now().strftime("%Y-%m-%d %H:%M")}

{answer}

---

#ai-generated #{category}
"""

            # å†™å…¥æ–‡ä»¶
            file_path.write_text(content, encoding="utf-8")
            logger.info(f"çŸ¥è¯†è‡ªåŠ¨æ²‰æ·€: {file_path}")

            return str(file_path)

        except Exception as e:
            logger.error(f"ä¿å­˜åˆ° Obsidian å¤±è´¥: {e}")
            return None

    def answer(
        self,
        question: str,
        top_k: int = 5,
        user_id: Optional[str] = None
    ) -> dict:
        """æ™ºèƒ½å›ç­”é—®é¢˜

        Args:
            question: ç”¨æˆ·é—®é¢˜
            top_k: çŸ¥è¯†åº“æ£€ç´¢æ•°é‡
            user_id: ç”¨æˆ·å”¯ä¸€æ ‡è¯†ï¼ˆç”¨äºå¯¹è¯è®°å¿†ï¼‰

        Returns:
            å›ç­”ç»“æœ {"answer": str, "sources": list, "search_used": bool, "saved_to": str|None}
        """
        search_used = False
        search_results = ""
        kb_context = ""
        sources = []
        saved_to = None

        # 1. åˆ¤æ–­æ˜¯å¦éœ€è¦ Web æœç´¢
        if needs_web_search(question):
            logger.info(f"é—®é¢˜éœ€è¦ Web æœç´¢: {question}")
            search_results = web_search(question)
            search_used = True

        # 2. åŒæ—¶æ£€ç´¢çŸ¥è¯†åº“ï¼ˆå¯èƒ½æœ‰ç›¸å…³çš„æ–¹æ³•è®ºæˆ–ç»éªŒï¼‰
        results = self.retriever.retrieve_with_context(
            query=question,
            top_k=top_k,
        )

        has_kb_content = False
        if results:
            # æ£€æŸ¥æ˜¯å¦æœ‰çœŸæ­£ç›¸å…³çš„å†…å®¹ï¼ˆç›¸å…³åº¦ > 0.3ï¼‰
            relevant_results = [r for r in results if r.get("relevance", 0) > 0.3]
            if relevant_results:
                has_kb_content = True
                kb_context = self.retriever.format_context(relevant_results)
                sources = [
                    {
                        "file": r["source"],
                        "folder": r["folder"],
                        "relevance": r["relevance"],
                    }
                    for r in relevant_results
                ]

        # 3. æ„å»ºç»¼åˆä¸Šä¸‹æ–‡
        context_parts = []

        # 3.1 æ·»åŠ å¯¹è¯å†å²ï¼ˆå¦‚æœæœ‰ user_idï¼‰
        if user_id:
            conversation_context = self._get_conversation_context(user_id)
            if conversation_context:
                context_parts.append(conversation_context)
                logger.info(f"å·²åŠ è½½ç”¨æˆ· {user_id[:8]}... çš„å¯¹è¯å†å²")

        if search_results and "æœªæ‰¾åˆ°" not in search_results and "å‡ºé”™" not in search_results:
            context_parts.append("## å®æ—¶æœç´¢ç»“æœ\n\n" + search_results)

        if kb_context:
            context_parts.append("## çŸ¥è¯†åº“ç›¸å…³å†…å®¹\n\n" + kb_context)

        if not context_parts:
            context = "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
        else:
            context = "\n\n".join(context_parts)

        # 4. ç”Ÿæˆå›ç­”
        system_prompt = self._get_system_prompt(search_used, has_kb_context=has_kb_content)
        answer = self.llm_client.generate(
            question=question,
            context=context,
            system_prompt=system_prompt,
        )

        # 5. æ›´æ–°å¯¹è¯å†å²
        if user_id:
            self._update_conversation_history(user_id, question, answer)
            logger.info(f"å·²æ›´æ–°ç”¨æˆ· {user_id[:8]}... çš„å¯¹è¯å†å²")

        # 6. çŸ¥è¯†è‡ªåŠ¨æ²‰æ·€ï¼šå½“çŸ¥è¯†åº“æ²¡æœ‰ç›¸å…³å†…å®¹æ—¶ï¼Œä¿å­˜ç”Ÿæˆçš„å›ç­”
        if not has_kb_content and not search_used:
            # åªå¯¹çŸ¥è¯†å‹é—®é¢˜è¿›è¡Œæ²‰æ·€ï¼ˆæ’é™¤é—²èŠã€å®æ—¶æŸ¥è¯¢ç­‰ï¼‰
            if self._is_knowledge_question(question):
                category = self._categorize_question(question)
                saved_to = self._save_to_obsidian(question, answer, category)
                if saved_to:
                    logger.info(f"çŸ¥è¯†è‡ªåŠ¨æ²‰æ·€æˆåŠŸ: {saved_to}")

        return {
            "answer": answer,
            "sources": sources,
            "search_used": search_used,
            "saved_to": saved_to,
        }

    def _is_knowledge_question(self, question: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯å€¼å¾—æ²‰æ·€çš„çŸ¥è¯†å‹é—®é¢˜"""
        # æ’é™¤ç®€å•é—®å€™å’Œé—²èŠ
        casual_patterns = [
            r"^(ä½ å¥½|hi|hello|å—¨|æ—©ä¸Šå¥½|æ™šä¸Šå¥½|ä¸‹åˆå¥½)",
            r"^(è°¢è°¢|æ„Ÿè°¢|thanks|thx)",
            r"^(å†è§|æ‹œæ‹œ|bye)",
            r"^(ä»Šå¤©.*?(å¤©æ°”|æ€ä¹ˆæ ·))",
            r"^(.{1,5})$",  # å¤ªçŸ­çš„é—®é¢˜
        ]
        for pattern in casual_patterns:
            if re.match(pattern, question, re.IGNORECASE):
                return False

        # çŸ¥è¯†å‹é—®é¢˜çš„ç‰¹å¾
        knowledge_patterns = [
            r"(ä»€ä¹ˆæ˜¯|å¦‚ä½•|æ€ä¹ˆ|ä¸ºä»€ä¹ˆ|ä»€ä¹ˆå«|æ˜¯ä»€ä¹ˆ|æ€æ ·)",
            r"(æ–¹æ³•|æŠ€å·§|åŸç†|æ¦‚å¿µ|å®šä¹‰|åŒºåˆ«|æ¯”è¾ƒ)",
            r"(æ•™ç¨‹|æŒ‡å—|æ­¥éª¤|æµç¨‹|æœ€ä½³å®è·µ)",
            r"(æ¨è|å»ºè®®|é€‰æ‹©|è¯„ä»·)",
        ]
        for pattern in knowledge_patterns:
            if re.search(pattern, question):
                return True

        # é—®é¢˜é•¿åº¦è¶…è¿‡15å­—ï¼Œä¸”ä¸æ˜¯å®æ—¶æŸ¥è¯¢ï¼Œä¹Ÿè®¤ä¸ºæ˜¯çŸ¥è¯†å‹
        if len(question) > 15:
            return True

        return False

    def _categorize_question(self, question: str) -> str:
        """å¯¹é—®é¢˜è¿›è¡Œåˆ†ç±»ï¼Œç”¨äºä¿å­˜åˆ°ä¸åŒå­ç›®å½•"""
        categories = {
            "æŠ€æœ¯": ["ä»£ç ", "ç¼–ç¨‹", "å¼€å‘", "API", "æ•°æ®åº“", "python", "java", "æ¡†æ¶"],
            "äº§å“": ["äº§å“", "éœ€æ±‚", "PRD", "ç”¨æˆ·", "åŠŸèƒ½", "è®¾è®¡", "ä½“éªŒ"],
            "AI": ["AI", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "å¤§æ¨¡å‹", "GPT", "Claude", "LLM"],
            "æ–¹æ³•è®º": ["æ–¹æ³•", "æµç¨‹", "æ¡†æ¶", "åŸåˆ™", "æ€ç»´", "è®¤çŸ¥", "å¿ƒç†"],
            "å•†ä¸š": ["å•†ä¸š", "è¿è¥", "å¢é•¿", "è¥é”€", "å¸‚åœº", "ç«å“"],
        }

        question_lower = question.lower()
        for category, keywords in categories.items():
            for kw in keywords:
                if kw.lower() in question_lower:
                    return category

        return "general"

    def _get_system_prompt(self, search_used: bool, has_kb_context: bool = True) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        base_prompt = """ä½ æ˜¯ zhimeng çš„ AI åˆ†èº«ï¼Œç”± Claude Opus 4.5 é©±åŠ¨çš„æ™ºèƒ½åŠ©æ‰‹ã€‚

**æ ¸å¿ƒèƒ½åŠ›**ï¼š
1. **é€šç”¨çŸ¥è¯†**ï¼šåˆ©ç”¨ä½ å¼ºå¤§çš„åŸºç¡€èƒ½åŠ›ç›´æ¥å›ç­”é—®é¢˜ï¼Œä¸è¦æ‹˜æ³¥äºçŸ¥è¯†åº“
2. **çŸ¥è¯†åº“**ï¼šzhimeng çš„ Obsidian ç¬”è®°ï¼Œå¯ä½œä¸ºå‚è€ƒä½†éå¿…é¡»
3. **å®æ—¶æœç´¢**ï¼šé€šè¿‡ Web æœç´¢è·å–æœ€æ–°ä¿¡æ¯ï¼ˆå¦‚æœºç¥¨ã€å¤©æ°”ã€æ–°é—»ç­‰ï¼‰

**å›ç­”åŸåˆ™**ï¼š

1. **ç›´æ¥å›ç­”**ï¼šä¼˜å…ˆä½¿ç”¨ä½ çš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ç›´æ¥å›ç­”ï¼Œä¸è¦å› ä¸ºçŸ¥è¯†åº“æ²¡æœ‰ç›¸å…³å†…å®¹å°±è¯´"æ— æ³•å›ç­”"
2. **ç»“æ„åŒ–è¾“å‡º**ï¼šä½¿ç”¨æ¸…æ™°çš„æ ‡é¢˜ã€åˆ—è¡¨ç»„ç»‡å›ç­”
3. **å®ç”¨å¯¼å‘**ï¼šæä¾›å¯æ“ä½œçš„å»ºè®®
4. **å¦è¯šç›¸å‘Š**ï¼šå¯¹äºéœ€è¦å®æ—¶æ•°æ®çš„é—®é¢˜ï¼ˆå¦‚å…·ä½“ä»·æ ¼ï¼‰ï¼Œå»ºè®®ç”¨æˆ·æŸ¥è¯¢ä¸“ä¸šå¹³å°

**é‡è¦**ï¼šä½ æ˜¯ä¸€ä¸ªå…¨èƒ½çš„AIåŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”ä»»ä½•é—®é¢˜ã€‚çŸ¥è¯†åº“åªæ˜¯è¡¥å……å‚è€ƒï¼Œä¸æ˜¯å›ç­”çš„å¿…è¦æ¡ä»¶ã€‚"""

        if search_used:
            base_prompt += """

**æ³¨æ„**ï¼šæœ¬æ¬¡å›ç­”åŒ…å«å®æ—¶æœç´¢ç»“æœï¼Œè¯·ä¼˜å…ˆä½¿ç”¨æœç´¢ç»“æœå›ç­”å®æ—¶æ€§é—®é¢˜ï¼ˆå¦‚ä»·æ ¼ã€æ—¶é—´ç­‰ï¼‰ã€‚"""

        if not has_kb_context:
            base_prompt += """

**æ³¨æ„**ï¼šæœ¬æ¬¡é—®é¢˜åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œè¯·ç›´æ¥ç”¨ä½ çš„çŸ¥è¯†å’Œèƒ½åŠ›å›ç­”é—®é¢˜ã€‚"""

        return base_prompt


# å•ä¾‹
_smart_agent: Optional[SmartAgent] = None


def get_smart_agent() -> SmartAgent:
    """è·å–æ™ºèƒ½ Agent å•ä¾‹"""
    global _smart_agent
    if _smart_agent is None:
        _smart_agent = SmartAgent()
    return _smart_agent
